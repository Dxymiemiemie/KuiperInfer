7767517
2202 2201
pnnx.Input               pnnx_input_0             0 1 x.3 #x.3=(1,1,500,128)f32
prim::Constant           pnnx_0                   0 1 165 value=2
prim::Constant           pnnx_1                   0 1 166 value=3
prim::Constant           pnnx_5                   0 1 257 value=None
prim::Constant           pnnx_6                   0 1 258 value=2
prim::Constant           pnnx_7                   0 1 259 value=0
prim::Constant           pnnx_8                   0 1 260 value=1
pnnx.Attribute           effnet._conv_stem        0 1 weight.3 @data=(32,1,3,3)f32 #weight.3=(32,1,3,3)f32
torch.transpose          torch.transpose_227      3 1 x.3 165 166 input.3 $input=x.3 $dim0=165 $dim1=166 #x.3=(1,1,500,128)f32 #input.3=(1,1,128,500)f32
nn.ZeroPad2d             effnet._conv_stem.static_padding 1 1 input.3 263 padding=(0,1,0,1) #input.3=(1,1,128,500)f32 #263=(1,1,129,501)f32
prim::Constant           pnnx_9                   0 1 2372 value=2
prim::ListConstruct      pnnx_10                  2 1 258 2372 264
prim::Constant           pnnx_11                  0 1 2373 value=0
prim::ListConstruct      pnnx_12                  2 1 259 2373 265
prim::Constant           pnnx_13                  0 1 2374 value=1
prim::ListConstruct      pnnx_14                  2 1 260 2374 266
prim::Constant           pnnx_18                  0 1 2377 value=1
F.conv2d                 F.conv2d_23              7 1 263 weight.3 257 264 265 266 2377 input0.1 $input=263 $weight=weight.3 $bias=257 $stride=264 $padding=265 $dilation=266 $groups=2377 #263=(1,1,129,501)f32 #weight.3=(32,1,3,3)f32 #input0.1=(1,32,64,250)f32
nn.BatchNorm2d           effnet._bn0              1 1 input0.1 172 affine=True eps=1.000000e-03 num_features=32 @bias=(32)f32 @running_mean=(32)f32 @running_var=(32)f32 @weight=(32)f32 #input0.1=(1,32,64,250)f32 #172=(1,32,64,250)f32
nn.SiLU                  effnet._swish            1 1 172 176 #172=(1,32,64,250)f32 #176=(1,32,64,250)f32
prim::Constant           pnnx_23                  0 1 269 value=1
prim::Constant           pnnx_26                  0 1 279 value=None
prim::Constant           pnnx_27                  0 1 280 value=1
prim::Constant           pnnx_28                  0 1 281 value=0
prim::Constant           pnnx_29                  0 1 282 value=32
pnnx.Attribute           effnet._blocks.0._depthwise_conv 0 1 weight.5 @data=(32,1,3,3)f32 #weight.5=(32,1,3,3)f32
nn.ZeroPad2d             effnet._blocks.0._depthwise_conv.static_padding 1 1 176 285 padding=(1,1,1,1) #176=(1,32,64,250)f32 #285=(1,32,66,252)f32
prim::Constant           pnnx_30                  0 1 2381 value=1
prim::ListConstruct      pnnx_31                  2 1 280 2381 286
prim::Constant           pnnx_32                  0 1 2382 value=0
prim::ListConstruct      pnnx_33                  2 1 281 2382 287
prim::Constant           pnnx_34                  0 1 2383 value=1
prim::Constant           pnnx_35                  0 1 2384 value=1
prim::ListConstruct      pnnx_36                  2 1 2383 2384 288
F.conv2d                 F.conv2d_24              7 1 285 weight.5 279 286 287 288 282 input.5 $input=285 $weight=weight.5 $bias=279 $stride=286 $padding=287 $dilation=288 $groups=282 #285=(1,32,66,252)f32 #weight.5=(32,1,3,3)f32 #input.5=(1,32,64,250)f32
nn.BatchNorm2d           effnet._blocks.0._bn1    1 1 input.5 291 affine=True eps=1.000000e-03 num_features=32 @bias=(32)f32 @running_mean=(32)f32 @running_var=(32)f32 @weight=(32)f32 #input.5=(1,32,64,250)f32 #291=(1,32,64,250)f32
nn.SiLU                  effnet._blocks.0._swish  1 1 291 292 #291=(1,32,64,250)f32 #292=(1,32,64,250)f32
prim::Constant           pnnx_44                  0 1 2390 value=1
prim::ListConstruct      pnnx_45                  2 1 269 2390 293
prim::Constant           pnnx_49                  0 1 297 value=1
prim::Constant           pnnx_50                  0 1 298 value=0
pnnx.Attribute           effnet._blocks.0._se_reduce 0 1 bias.3 @data=(8)f32 #bias.3=(8)f32
pnnx.Attribute           effnet._blocks.0._se_reduce 0 1 weight.7 @data=(8,32,1,1)f32 #weight.7=(8,32,1,1)f32
prim::Constant           pnnx_51                  0 1 302 value=None
prim::Constant           pnnx_52                  0 1 2391 value=1
prim::ListConstruct      pnnx_53                  2 1 297 2391 303
prim::Constant           pnnx_54                  0 1 2392 value=0
prim::ListConstruct      pnnx_55                  2 1 298 2392 304
prim::Constant           pnnx_56                  0 1 2393 value=1
prim::Constant           pnnx_57                  0 1 2394 value=1
prim::ListConstruct      pnnx_58                  2 1 2393 2394 305
prim::Constant           pnnx_62                  0 1 2397 value=1
F.adaptive_avg_pool2d    F.adaptive_avg_pool2d_0  2 1 292 293 x.5 $input=292 $output_size=293 #292=(1,32,64,250)f32 #x.5=(1,32,1,1)f32
F.conv2d                 F.conv2d_25              7 1 x.5 weight.7 bias.3 303 304 305 2397 input.7 $input=x.5 $weight=weight.7 $bias=bias.3 $stride=303 $padding=304 $dilation=305 $groups=2397 #x.5=(1,32,1,1)f32 #weight.7=(8,32,1,1)f32 #bias.3=(8)f32 #input.7=(1,8,1,1)f32
nn.SiLU                  effnet._blocks.0._swish  1 1 input.7 308 #input.7=(1,8,1,1)f32 #308=(1,8,1,1)f32
prim::Constant           pnnx_69                  0 1 311 value=1
prim::Constant           pnnx_70                  0 1 312 value=0
pnnx.Attribute           effnet._blocks.0._se_expand 0 1 bias.5 @data=(32)f32 #bias.5=(32)f32
pnnx.Attribute           effnet._blocks.0._se_expand 0 1 weight.9 @data=(32,8,1,1)f32 #weight.9=(32,8,1,1)f32
prim::Constant           pnnx_71                  0 1 316 value=None
prim::Constant           pnnx_72                  0 1 2401 value=1
prim::ListConstruct      pnnx_73                  2 1 311 2401 317
prim::Constant           pnnx_74                  0 1 2402 value=0
prim::ListConstruct      pnnx_75                  2 1 312 2402 318
prim::Constant           pnnx_76                  0 1 2403 value=1
prim::Constant           pnnx_77                  0 1 2404 value=1
prim::ListConstruct      pnnx_78                  2 1 2403 2404 319
prim::Constant           pnnx_82                  0 1 2407 value=1
F.conv2d                 F.conv2d_26              7 1 308 weight.9 bias.5 317 318 319 2407 x_squeezed.2 $input=308 $weight=weight.9 $bias=bias.5 $stride=317 $padding=318 $dilation=319 $groups=2407 #308=(1,8,1,1)f32 #weight.9=(32,8,1,1)f32 #bias.5=(32)f32 #x_squeezed.2=(1,32,1,1)f32
F.sigmoid                F.sigmoid_138            1 1 x_squeezed.2 322 $input=x_squeezed.2 #x_squeezed.2=(1,32,1,1)f32 #322=(1,32,1,1)f32
aten::mul                pnnx_88                  2 1 322 292 x0.2 #322=(1,32,1,1)f32 #292=(1,32,64,250)f32 #x0.2=(1,32,64,250)f32
prim::Constant           pnnx_91                  0 1 326 value=None
prim::Constant           pnnx_92                  0 1 327 value=1
prim::Constant           pnnx_93                  0 1 328 value=0
pnnx.Attribute           effnet._blocks.0._project_conv 0 1 weight.11 @data=(16,32,1,1)f32 #weight.11=(16,32,1,1)f32
prim::Constant           pnnx_94                  0 1 331 value=None
prim::Constant           pnnx_95                  0 1 2411 value=1
prim::ListConstruct      pnnx_96                  2 1 327 2411 332
prim::Constant           pnnx_97                  0 1 2412 value=0
prim::ListConstruct      pnnx_98                  2 1 328 2412 333
prim::Constant           pnnx_99                  0 1 2413 value=1
prim::Constant           pnnx_100                 0 1 2414 value=1
prim::ListConstruct      pnnx_101                 2 1 2413 2414 334
prim::Constant           pnnx_105                 0 1 2417 value=1
F.conv2d                 F.conv2d_27              7 1 x0.2 weight.11 326 332 333 334 2417 input.9 $input=x0.2 $weight=weight.11 $bias=326 $stride=332 $padding=333 $dilation=334 $groups=2417 #x0.2=(1,32,64,250)f32 #weight.11=(16,32,1,1)f32 #input.9=(1,16,64,250)f32
nn.BatchNorm2d           effnet._blocks.0._bn2    1 1 input.9 337 affine=True eps=1.000000e-03 num_features=16 @bias=(16)f32 @running_mean=(16)f32 @running_var=(16)f32 @weight=(16)f32 #input.9=(1,16,64,250)f32 #337=(1,16,64,250)f32
prim::Constant           pnnx_110                 0 1 338 value=1
prim::Constant           pnnx_113                 0 1 348 value=None
prim::Constant           pnnx_114                 0 1 349 value=1
prim::Constant           pnnx_115                 0 1 350 value=0
prim::Constant           pnnx_116                 0 1 351 value=16
pnnx.Attribute           effnet._blocks.1._depthwise_conv 0 1 weight.13 @data=(16,1,3,3)f32 #weight.13=(16,1,3,3)f32
nn.ZeroPad2d             effnet._blocks.1._depthwise_conv.static_padding 1 1 337 354 padding=(1,1,1,1) #337=(1,16,64,250)f32 #354=(1,16,66,252)f32
prim::Constant           pnnx_117                 0 1 2421 value=1
prim::ListConstruct      pnnx_118                 2 1 349 2421 355
prim::Constant           pnnx_119                 0 1 2422 value=0
prim::ListConstruct      pnnx_120                 2 1 350 2422 356
prim::Constant           pnnx_121                 0 1 2423 value=1
prim::Constant           pnnx_122                 0 1 2424 value=1
prim::ListConstruct      pnnx_123                 2 1 2423 2424 357
F.conv2d                 F.conv2d_28              7 1 354 weight.13 348 355 356 357 351 input.11 $input=354 $weight=weight.13 $bias=348 $stride=355 $padding=356 $dilation=357 $groups=351 #354=(1,16,66,252)f32 #weight.13=(16,1,3,3)f32 #input.11=(1,16,64,250)f32
nn.BatchNorm2d           effnet._blocks.1._bn1    1 1 input.11 360 affine=True eps=1.000000e-03 num_features=16 @bias=(16)f32 @running_mean=(16)f32 @running_var=(16)f32 @weight=(16)f32 #input.11=(1,16,64,250)f32 #360=(1,16,64,250)f32
nn.SiLU                  effnet._blocks.1._swish  1 1 360 361 #360=(1,16,64,250)f32 #361=(1,16,64,250)f32
prim::Constant           pnnx_131                 0 1 2430 value=1
prim::ListConstruct      pnnx_132                 2 1 338 2430 362
prim::Constant           pnnx_136                 0 1 366 value=1
prim::Constant           pnnx_137                 0 1 367 value=0
pnnx.Attribute           effnet._blocks.1._se_reduce 0 1 bias.7 @data=(4)f32 #bias.7=(4)f32
pnnx.Attribute           effnet._blocks.1._se_reduce 0 1 weight.15 @data=(4,16,1,1)f32 #weight.15=(4,16,1,1)f32
prim::Constant           pnnx_138                 0 1 371 value=None
prim::Constant           pnnx_139                 0 1 2431 value=1
prim::ListConstruct      pnnx_140                 2 1 366 2431 372
prim::Constant           pnnx_141                 0 1 2432 value=0
prim::ListConstruct      pnnx_142                 2 1 367 2432 373
prim::Constant           pnnx_143                 0 1 2433 value=1
prim::Constant           pnnx_144                 0 1 2434 value=1
prim::ListConstruct      pnnx_145                 2 1 2433 2434 374
prim::Constant           pnnx_149                 0 1 2437 value=1
F.adaptive_avg_pool2d    F.adaptive_avg_pool2d_1  2 1 361 362 x.7 $input=361 $output_size=362 #361=(1,16,64,250)f32 #x.7=(1,16,1,1)f32
F.conv2d                 F.conv2d_29              7 1 x.7 weight.15 bias.7 372 373 374 2437 input.13 $input=x.7 $weight=weight.15 $bias=bias.7 $stride=372 $padding=373 $dilation=374 $groups=2437 #x.7=(1,16,1,1)f32 #weight.15=(4,16,1,1)f32 #bias.7=(4)f32 #input.13=(1,4,1,1)f32
nn.SiLU                  effnet._blocks.1._swish  1 1 input.13 377 #input.13=(1,4,1,1)f32 #377=(1,4,1,1)f32
prim::Constant           pnnx_156                 0 1 380 value=1
prim::Constant           pnnx_157                 0 1 381 value=0
pnnx.Attribute           effnet._blocks.1._se_expand 0 1 bias.9 @data=(16)f32 #bias.9=(16)f32
pnnx.Attribute           effnet._blocks.1._se_expand 0 1 weight.17 @data=(16,4,1,1)f32 #weight.17=(16,4,1,1)f32
prim::Constant           pnnx_158                 0 1 385 value=None
prim::Constant           pnnx_159                 0 1 2441 value=1
prim::ListConstruct      pnnx_160                 2 1 380 2441 386
prim::Constant           pnnx_161                 0 1 2442 value=0
prim::ListConstruct      pnnx_162                 2 1 381 2442 387
prim::Constant           pnnx_163                 0 1 2443 value=1
prim::Constant           pnnx_164                 0 1 2444 value=1
prim::ListConstruct      pnnx_165                 2 1 2443 2444 388
prim::Constant           pnnx_169                 0 1 2447 value=1
F.conv2d                 F.conv2d_30              7 1 377 weight.17 bias.9 386 387 388 2447 x_squeezed.4 $input=377 $weight=weight.17 $bias=bias.9 $stride=386 $padding=387 $dilation=388 $groups=2447 #377=(1,4,1,1)f32 #weight.17=(16,4,1,1)f32 #bias.9=(16)f32 #x_squeezed.4=(1,16,1,1)f32
F.sigmoid                F.sigmoid_139            1 1 x_squeezed.4 391 $input=x_squeezed.4 #x_squeezed.4=(1,16,1,1)f32 #391=(1,16,1,1)f32
aten::mul                pnnx_175                 2 1 391 361 x0.4 #391=(1,16,1,1)f32 #361=(1,16,64,250)f32 #x0.4=(1,16,64,250)f32
prim::Constant           pnnx_178                 0 1 395 value=None
prim::Constant           pnnx_179                 0 1 396 value=1
prim::Constant           pnnx_180                 0 1 397 value=0
pnnx.Attribute           effnet._blocks.1._project_conv 0 1 weight.19 @data=(16,16,1,1)f32 #weight.19=(16,16,1,1)f32
prim::Constant           pnnx_181                 0 1 400 value=None
prim::Constant           pnnx_182                 0 1 2451 value=1
prim::ListConstruct      pnnx_183                 2 1 396 2451 401
prim::Constant           pnnx_184                 0 1 2452 value=0
prim::ListConstruct      pnnx_185                 2 1 397 2452 402
prim::Constant           pnnx_186                 0 1 2453 value=1
prim::Constant           pnnx_187                 0 1 2454 value=1
prim::ListConstruct      pnnx_188                 2 1 2453 2454 403
prim::Constant           pnnx_192                 0 1 2457 value=1
F.conv2d                 F.conv2d_31              7 1 x0.4 weight.19 395 401 402 403 2457 input.15 $input=x0.4 $weight=weight.19 $bias=395 $stride=401 $padding=402 $dilation=403 $groups=2457 #x0.4=(1,16,64,250)f32 #weight.19=(16,16,1,1)f32 #input.15=(1,16,64,250)f32
nn.BatchNorm2d           effnet._blocks.1._bn2    1 1 input.15 406 affine=True eps=1.000000e-03 num_features=16 @bias=(16)f32 @running_mean=(16)f32 @running_var=(16)f32 @weight=(16)f32 #input.15=(1,16,64,250)f32 #406=(1,16,64,250)f32
prim::Constant           pnnx_197                 0 1 2461 value=1
aten::add                pnnx_198                 3 1 406 337 2461 407 #406=(1,16,64,250)f32 #337=(1,16,64,250)f32 #407=(1,16,64,250)f32
prim::Constant           pnnx_199                 0 1 408 value=1
prim::Constant           pnnx_202                 0 1 420 value=None
prim::Constant           pnnx_203                 0 1 421 value=1
prim::Constant           pnnx_204                 0 1 422 value=0
pnnx.Attribute           effnet._blocks.2._expand_conv 0 1 weight.21 @data=(96,16,1,1)f32 #weight.21=(96,16,1,1)f32
prim::Constant           pnnx_205                 0 1 425 value=None
prim::Constant           pnnx_206                 0 1 2462 value=1
prim::ListConstruct      pnnx_207                 2 1 421 2462 426
prim::Constant           pnnx_208                 0 1 2463 value=0
prim::ListConstruct      pnnx_209                 2 1 422 2463 427
prim::Constant           pnnx_210                 0 1 2464 value=1
prim::Constant           pnnx_211                 0 1 2465 value=1
prim::ListConstruct      pnnx_212                 2 1 2464 2465 428
prim::Constant           pnnx_216                 0 1 2468 value=1
F.conv2d                 F.conv2d_32              7 1 407 weight.21 420 426 427 428 2468 input.17 $input=407 $weight=weight.21 $bias=420 $stride=426 $padding=427 $dilation=428 $groups=2468 #407=(1,16,64,250)f32 #weight.21=(96,16,1,1)f32 #input.17=(1,96,64,250)f32
nn.BatchNorm2d           effnet._blocks.2._bn0    1 1 input.17 431 affine=True eps=1.000000e-03 num_features=96 @bias=(96)f32 @running_mean=(96)f32 @running_var=(96)f32 @weight=(96)f32 #input.17=(1,96,64,250)f32 #431=(1,96,64,250)f32
nn.SiLU                  effnet._blocks.2._swish  1 1 431 432 #431=(1,96,64,250)f32 #432=(1,96,64,250)f32
prim::Constant           pnnx_223                 0 1 435 value=None
prim::Constant           pnnx_224                 0 1 436 value=2
prim::Constant           pnnx_225                 0 1 437 value=0
prim::Constant           pnnx_226                 0 1 438 value=1
prim::Constant           pnnx_227                 0 1 439 value=96
pnnx.Attribute           effnet._blocks.2._depthwise_conv 0 1 weight.23 @data=(96,1,3,3)f32 #weight.23=(96,1,3,3)f32
nn.ZeroPad2d             effnet._blocks.2._depthwise_conv.static_padding 1 1 432 442 padding=(0,1,0,1) #432=(1,96,64,250)f32 #442=(1,96,65,251)f32
prim::Constant           pnnx_228                 0 1 2472 value=2
prim::ListConstruct      pnnx_229                 2 1 436 2472 443
prim::Constant           pnnx_230                 0 1 2473 value=0
prim::ListConstruct      pnnx_231                 2 1 437 2473 444
prim::Constant           pnnx_232                 0 1 2474 value=1
prim::ListConstruct      pnnx_233                 2 1 438 2474 445
F.conv2d                 F.conv2d_33              7 1 442 weight.23 435 443 444 445 439 input.19 $input=442 $weight=weight.23 $bias=435 $stride=443 $padding=444 $dilation=445 $groups=439 #442=(1,96,65,251)f32 #weight.23=(96,1,3,3)f32 #input.19=(1,96,32,125)f32
nn.BatchNorm2d           effnet._blocks.2._bn1    1 1 input.19 448 affine=True eps=1.000000e-03 num_features=96 @bias=(96)f32 @running_mean=(96)f32 @running_var=(96)f32 @weight=(96)f32 #input.19=(1,96,32,125)f32 #448=(1,96,32,125)f32
nn.SiLU                  effnet._blocks.2._swish  1 1 448 449 #448=(1,96,32,125)f32 #449=(1,96,32,125)f32
prim::Constant           pnnx_241                 0 1 2480 value=1
prim::ListConstruct      pnnx_242                 2 1 408 2480 450
prim::Constant           pnnx_246                 0 1 454 value=1
prim::Constant           pnnx_247                 0 1 455 value=0
pnnx.Attribute           effnet._blocks.2._se_reduce 0 1 bias.11 @data=(4)f32 #bias.11=(4)f32
pnnx.Attribute           effnet._blocks.2._se_reduce 0 1 weight.25 @data=(4,96,1,1)f32 #weight.25=(4,96,1,1)f32
prim::Constant           pnnx_248                 0 1 459 value=None
prim::Constant           pnnx_249                 0 1 2481 value=1
prim::ListConstruct      pnnx_250                 2 1 454 2481 460
prim::Constant           pnnx_251                 0 1 2482 value=0
prim::ListConstruct      pnnx_252                 2 1 455 2482 461
prim::Constant           pnnx_253                 0 1 2483 value=1
prim::Constant           pnnx_254                 0 1 2484 value=1
prim::ListConstruct      pnnx_255                 2 1 2483 2484 462
prim::Constant           pnnx_259                 0 1 2487 value=1
F.adaptive_avg_pool2d    F.adaptive_avg_pool2d_2  2 1 449 450 x.9 $input=449 $output_size=450 #449=(1,96,32,125)f32 #x.9=(1,96,1,1)f32
F.conv2d                 F.conv2d_34              7 1 x.9 weight.25 bias.11 460 461 462 2487 input.21 $input=x.9 $weight=weight.25 $bias=bias.11 $stride=460 $padding=461 $dilation=462 $groups=2487 #x.9=(1,96,1,1)f32 #weight.25=(4,96,1,1)f32 #bias.11=(4)f32 #input.21=(1,4,1,1)f32
nn.SiLU                  effnet._blocks.2._swish  1 1 input.21 465 #input.21=(1,4,1,1)f32 #465=(1,4,1,1)f32
prim::Constant           pnnx_266                 0 1 468 value=1
prim::Constant           pnnx_267                 0 1 469 value=0
pnnx.Attribute           effnet._blocks.2._se_expand 0 1 bias.13 @data=(96)f32 #bias.13=(96)f32
pnnx.Attribute           effnet._blocks.2._se_expand 0 1 weight.27 @data=(96,4,1,1)f32 #weight.27=(96,4,1,1)f32
prim::Constant           pnnx_268                 0 1 473 value=None
prim::Constant           pnnx_269                 0 1 2491 value=1
prim::ListConstruct      pnnx_270                 2 1 468 2491 474
prim::Constant           pnnx_271                 0 1 2492 value=0
prim::ListConstruct      pnnx_272                 2 1 469 2492 475
prim::Constant           pnnx_273                 0 1 2493 value=1
prim::Constant           pnnx_274                 0 1 2494 value=1
prim::ListConstruct      pnnx_275                 2 1 2493 2494 476
prim::Constant           pnnx_279                 0 1 2497 value=1
F.conv2d                 F.conv2d_35              7 1 465 weight.27 bias.13 474 475 476 2497 x_squeezed.6 $input=465 $weight=weight.27 $bias=bias.13 $stride=474 $padding=475 $dilation=476 $groups=2497 #465=(1,4,1,1)f32 #weight.27=(96,4,1,1)f32 #bias.13=(96)f32 #x_squeezed.6=(1,96,1,1)f32
F.sigmoid                F.sigmoid_140            1 1 x_squeezed.6 479 $input=x_squeezed.6 #x_squeezed.6=(1,96,1,1)f32 #479=(1,96,1,1)f32
aten::mul                pnnx_285                 2 1 479 449 x0.6 #479=(1,96,1,1)f32 #449=(1,96,32,125)f32 #x0.6=(1,96,32,125)f32
prim::Constant           pnnx_288                 0 1 483 value=None
prim::Constant           pnnx_289                 0 1 484 value=1
prim::Constant           pnnx_290                 0 1 485 value=0
pnnx.Attribute           effnet._blocks.2._project_conv 0 1 weight.29 @data=(24,96,1,1)f32 #weight.29=(24,96,1,1)f32
prim::Constant           pnnx_291                 0 1 488 value=None
prim::Constant           pnnx_292                 0 1 2501 value=1
prim::ListConstruct      pnnx_293                 2 1 484 2501 489
prim::Constant           pnnx_294                 0 1 2502 value=0
prim::ListConstruct      pnnx_295                 2 1 485 2502 490
prim::Constant           pnnx_296                 0 1 2503 value=1
prim::Constant           pnnx_297                 0 1 2504 value=1
prim::ListConstruct      pnnx_298                 2 1 2503 2504 491
prim::Constant           pnnx_302                 0 1 2507 value=1
F.conv2d                 F.conv2d_36              7 1 x0.6 weight.29 483 489 490 491 2507 input.23 $input=x0.6 $weight=weight.29 $bias=483 $stride=489 $padding=490 $dilation=491 $groups=2507 #x0.6=(1,96,32,125)f32 #weight.29=(24,96,1,1)f32 #input.23=(1,24,32,125)f32
nn.BatchNorm2d           effnet._blocks.2._bn2    1 1 input.23 494 affine=True eps=1.000000e-03 num_features=24 @bias=(24)f32 @running_mean=(24)f32 @running_var=(24)f32 @weight=(24)f32 #input.23=(1,24,32,125)f32 #494=(1,24,32,125)f32
prim::Constant           pnnx_307                 0 1 495 value=1
prim::Constant           pnnx_310                 0 1 507 value=None
prim::Constant           pnnx_311                 0 1 508 value=1
prim::Constant           pnnx_312                 0 1 509 value=0
pnnx.Attribute           effnet._blocks.3._expand_conv 0 1 weight.31 @data=(144,24,1,1)f32 #weight.31=(144,24,1,1)f32
prim::Constant           pnnx_313                 0 1 512 value=None
prim::Constant           pnnx_314                 0 1 2511 value=1
prim::ListConstruct      pnnx_315                 2 1 508 2511 513
prim::Constant           pnnx_316                 0 1 2512 value=0
prim::ListConstruct      pnnx_317                 2 1 509 2512 514
prim::Constant           pnnx_318                 0 1 2513 value=1
prim::Constant           pnnx_319                 0 1 2514 value=1
prim::ListConstruct      pnnx_320                 2 1 2513 2514 515
prim::Constant           pnnx_324                 0 1 2517 value=1
F.conv2d                 F.conv2d_37              7 1 494 weight.31 507 513 514 515 2517 input.25 $input=494 $weight=weight.31 $bias=507 $stride=513 $padding=514 $dilation=515 $groups=2517 #494=(1,24,32,125)f32 #weight.31=(144,24,1,1)f32 #input.25=(1,144,32,125)f32
nn.BatchNorm2d           effnet._blocks.3._bn0    1 1 input.25 518 affine=True eps=1.000000e-03 num_features=144 @bias=(144)f32 @running_mean=(144)f32 @running_var=(144)f32 @weight=(144)f32 #input.25=(1,144,32,125)f32 #518=(1,144,32,125)f32
nn.SiLU                  effnet._blocks.3._swish  1 1 518 519 #518=(1,144,32,125)f32 #519=(1,144,32,125)f32
prim::Constant           pnnx_331                 0 1 522 value=None
prim::Constant           pnnx_332                 0 1 523 value=1
prim::Constant           pnnx_333                 0 1 524 value=0
prim::Constant           pnnx_334                 0 1 525 value=144
pnnx.Attribute           effnet._blocks.3._depthwise_conv 0 1 weight.33 @data=(144,1,3,3)f32 #weight.33=(144,1,3,3)f32
nn.ZeroPad2d             effnet._blocks.3._depthwise_conv.static_padding 1 1 519 528 padding=(1,1,1,1) #519=(1,144,32,125)f32 #528=(1,144,34,127)f32
prim::Constant           pnnx_335                 0 1 2521 value=1
prim::ListConstruct      pnnx_336                 2 1 523 2521 529
prim::Constant           pnnx_337                 0 1 2522 value=0
prim::ListConstruct      pnnx_338                 2 1 524 2522 530
prim::Constant           pnnx_339                 0 1 2523 value=1
prim::Constant           pnnx_340                 0 1 2524 value=1
prim::ListConstruct      pnnx_341                 2 1 2523 2524 531
F.conv2d                 F.conv2d_38              7 1 528 weight.33 522 529 530 531 525 input.27 $input=528 $weight=weight.33 $bias=522 $stride=529 $padding=530 $dilation=531 $groups=525 #528=(1,144,34,127)f32 #weight.33=(144,1,3,3)f32 #input.27=(1,144,32,125)f32
nn.BatchNorm2d           effnet._blocks.3._bn1    1 1 input.27 534 affine=True eps=1.000000e-03 num_features=144 @bias=(144)f32 @running_mean=(144)f32 @running_var=(144)f32 @weight=(144)f32 #input.27=(1,144,32,125)f32 #534=(1,144,32,125)f32
nn.SiLU                  effnet._blocks.3._swish  1 1 534 535 #534=(1,144,32,125)f32 #535=(1,144,32,125)f32
prim::Constant           pnnx_349                 0 1 2530 value=1
prim::ListConstruct      pnnx_350                 2 1 495 2530 536
prim::Constant           pnnx_354                 0 1 540 value=1
prim::Constant           pnnx_355                 0 1 541 value=0
pnnx.Attribute           effnet._blocks.3._se_reduce 0 1 bias.15 @data=(6)f32 #bias.15=(6)f32
pnnx.Attribute           effnet._blocks.3._se_reduce 0 1 weight.35 @data=(6,144,1,1)f32 #weight.35=(6,144,1,1)f32
prim::Constant           pnnx_356                 0 1 545 value=None
prim::Constant           pnnx_357                 0 1 2531 value=1
prim::ListConstruct      pnnx_358                 2 1 540 2531 546
prim::Constant           pnnx_359                 0 1 2532 value=0
prim::ListConstruct      pnnx_360                 2 1 541 2532 547
prim::Constant           pnnx_361                 0 1 2533 value=1
prim::Constant           pnnx_362                 0 1 2534 value=1
prim::ListConstruct      pnnx_363                 2 1 2533 2534 548
prim::Constant           pnnx_367                 0 1 2537 value=1
F.adaptive_avg_pool2d    F.adaptive_avg_pool2d_3  2 1 535 536 x.11 $input=535 $output_size=536 #535=(1,144,32,125)f32 #x.11=(1,144,1,1)f32
F.conv2d                 F.conv2d_39              7 1 x.11 weight.35 bias.15 546 547 548 2537 input.29 $input=x.11 $weight=weight.35 $bias=bias.15 $stride=546 $padding=547 $dilation=548 $groups=2537 #x.11=(1,144,1,1)f32 #weight.35=(6,144,1,1)f32 #bias.15=(6)f32 #input.29=(1,6,1,1)f32
nn.SiLU                  effnet._blocks.3._swish  1 1 input.29 551 #input.29=(1,6,1,1)f32 #551=(1,6,1,1)f32
prim::Constant           pnnx_374                 0 1 554 value=1
prim::Constant           pnnx_375                 0 1 555 value=0
pnnx.Attribute           effnet._blocks.3._se_expand 0 1 bias.17 @data=(144)f32 #bias.17=(144)f32
pnnx.Attribute           effnet._blocks.3._se_expand 0 1 weight.37 @data=(144,6,1,1)f32 #weight.37=(144,6,1,1)f32
prim::Constant           pnnx_376                 0 1 559 value=None
prim::Constant           pnnx_377                 0 1 2541 value=1
prim::ListConstruct      pnnx_378                 2 1 554 2541 560
prim::Constant           pnnx_379                 0 1 2542 value=0
prim::ListConstruct      pnnx_380                 2 1 555 2542 561
prim::Constant           pnnx_381                 0 1 2543 value=1
prim::Constant           pnnx_382                 0 1 2544 value=1
prim::ListConstruct      pnnx_383                 2 1 2543 2544 562
prim::Constant           pnnx_387                 0 1 2547 value=1
F.conv2d                 F.conv2d_40              7 1 551 weight.37 bias.17 560 561 562 2547 x_squeezed.8 $input=551 $weight=weight.37 $bias=bias.17 $stride=560 $padding=561 $dilation=562 $groups=2547 #551=(1,6,1,1)f32 #weight.37=(144,6,1,1)f32 #bias.17=(144)f32 #x_squeezed.8=(1,144,1,1)f32
F.sigmoid                F.sigmoid_141            1 1 x_squeezed.8 565 $input=x_squeezed.8 #x_squeezed.8=(1,144,1,1)f32 #565=(1,144,1,1)f32
aten::mul                pnnx_393                 2 1 565 535 x0.8 #565=(1,144,1,1)f32 #535=(1,144,32,125)f32 #x0.8=(1,144,32,125)f32
prim::Constant           pnnx_396                 0 1 569 value=None
prim::Constant           pnnx_397                 0 1 570 value=1
prim::Constant           pnnx_398                 0 1 571 value=0
pnnx.Attribute           effnet._blocks.3._project_conv 0 1 weight.39 @data=(24,144,1,1)f32 #weight.39=(24,144,1,1)f32
prim::Constant           pnnx_399                 0 1 574 value=None
prim::Constant           pnnx_400                 0 1 2551 value=1
prim::ListConstruct      pnnx_401                 2 1 570 2551 575
prim::Constant           pnnx_402                 0 1 2552 value=0
prim::ListConstruct      pnnx_403                 2 1 571 2552 576
prim::Constant           pnnx_404                 0 1 2553 value=1
prim::Constant           pnnx_405                 0 1 2554 value=1
prim::ListConstruct      pnnx_406                 2 1 2553 2554 577
prim::Constant           pnnx_410                 0 1 2557 value=1
F.conv2d                 F.conv2d_41              7 1 x0.8 weight.39 569 575 576 577 2557 input.31 $input=x0.8 $weight=weight.39 $bias=569 $stride=575 $padding=576 $dilation=577 $groups=2557 #x0.8=(1,144,32,125)f32 #weight.39=(24,144,1,1)f32 #input.31=(1,24,32,125)f32
nn.BatchNorm2d           effnet._blocks.3._bn2    1 1 input.31 580 affine=True eps=1.000000e-03 num_features=24 @bias=(24)f32 @running_mean=(24)f32 @running_var=(24)f32 @weight=(24)f32 #input.31=(1,24,32,125)f32 #580=(1,24,32,125)f32
prim::Constant           pnnx_415                 0 1 2561 value=1
aten::add                pnnx_416                 3 1 580 494 2561 581 #580=(1,24,32,125)f32 #494=(1,24,32,125)f32 #581=(1,24,32,125)f32
prim::Constant           pnnx_417                 0 1 582 value=1
prim::Constant           pnnx_420                 0 1 594 value=None
prim::Constant           pnnx_421                 0 1 595 value=1
prim::Constant           pnnx_422                 0 1 596 value=0
pnnx.Attribute           effnet._blocks.4._expand_conv 0 1 weight.41 @data=(144,24,1,1)f32 #weight.41=(144,24,1,1)f32
prim::Constant           pnnx_423                 0 1 599 value=None
prim::Constant           pnnx_424                 0 1 2562 value=1
prim::ListConstruct      pnnx_425                 2 1 595 2562 600
prim::Constant           pnnx_426                 0 1 2563 value=0
prim::ListConstruct      pnnx_427                 2 1 596 2563 601
prim::Constant           pnnx_428                 0 1 2564 value=1
prim::Constant           pnnx_429                 0 1 2565 value=1
prim::ListConstruct      pnnx_430                 2 1 2564 2565 602
prim::Constant           pnnx_434                 0 1 2568 value=1
F.conv2d                 F.conv2d_42              7 1 581 weight.41 594 600 601 602 2568 input.33 $input=581 $weight=weight.41 $bias=594 $stride=600 $padding=601 $dilation=602 $groups=2568 #581=(1,24,32,125)f32 #weight.41=(144,24,1,1)f32 #input.33=(1,144,32,125)f32
nn.BatchNorm2d           effnet._blocks.4._bn0    1 1 input.33 605 affine=True eps=1.000000e-03 num_features=144 @bias=(144)f32 @running_mean=(144)f32 @running_var=(144)f32 @weight=(144)f32 #input.33=(1,144,32,125)f32 #605=(1,144,32,125)f32
nn.SiLU                  effnet._blocks.4._swish  1 1 605 606 #605=(1,144,32,125)f32 #606=(1,144,32,125)f32
prim::Constant           pnnx_441                 0 1 609 value=None
prim::Constant           pnnx_442                 0 1 610 value=1
prim::Constant           pnnx_443                 0 1 611 value=0
prim::Constant           pnnx_444                 0 1 612 value=144
pnnx.Attribute           effnet._blocks.4._depthwise_conv 0 1 weight.43 @data=(144,1,3,3)f32 #weight.43=(144,1,3,3)f32
nn.ZeroPad2d             effnet._blocks.4._depthwise_conv.static_padding 1 1 606 615 padding=(1,1,1,1) #606=(1,144,32,125)f32 #615=(1,144,34,127)f32
prim::Constant           pnnx_445                 0 1 2572 value=1
prim::ListConstruct      pnnx_446                 2 1 610 2572 616
prim::Constant           pnnx_447                 0 1 2573 value=0
prim::ListConstruct      pnnx_448                 2 1 611 2573 617
prim::Constant           pnnx_449                 0 1 2574 value=1
prim::Constant           pnnx_450                 0 1 2575 value=1
prim::ListConstruct      pnnx_451                 2 1 2574 2575 618
F.conv2d                 F.conv2d_43              7 1 615 weight.43 609 616 617 618 612 input.35 $input=615 $weight=weight.43 $bias=609 $stride=616 $padding=617 $dilation=618 $groups=612 #615=(1,144,34,127)f32 #weight.43=(144,1,3,3)f32 #input.35=(1,144,32,125)f32
nn.BatchNorm2d           effnet._blocks.4._bn1    1 1 input.35 621 affine=True eps=1.000000e-03 num_features=144 @bias=(144)f32 @running_mean=(144)f32 @running_var=(144)f32 @weight=(144)f32 #input.35=(1,144,32,125)f32 #621=(1,144,32,125)f32
nn.SiLU                  effnet._blocks.4._swish  1 1 621 622 #621=(1,144,32,125)f32 #622=(1,144,32,125)f32
prim::Constant           pnnx_459                 0 1 2581 value=1
prim::ListConstruct      pnnx_460                 2 1 582 2581 623
prim::Constant           pnnx_464                 0 1 627 value=1
prim::Constant           pnnx_465                 0 1 628 value=0
pnnx.Attribute           effnet._blocks.4._se_reduce 0 1 bias.19 @data=(6)f32 #bias.19=(6)f32
pnnx.Attribute           effnet._blocks.4._se_reduce 0 1 weight.45 @data=(6,144,1,1)f32 #weight.45=(6,144,1,1)f32
prim::Constant           pnnx_466                 0 1 632 value=None
prim::Constant           pnnx_467                 0 1 2582 value=1
prim::ListConstruct      pnnx_468                 2 1 627 2582 633
prim::Constant           pnnx_469                 0 1 2583 value=0
prim::ListConstruct      pnnx_470                 2 1 628 2583 634
prim::Constant           pnnx_471                 0 1 2584 value=1
prim::Constant           pnnx_472                 0 1 2585 value=1
prim::ListConstruct      pnnx_473                 2 1 2584 2585 635
prim::Constant           pnnx_477                 0 1 2588 value=1
F.adaptive_avg_pool2d    F.adaptive_avg_pool2d_4  2 1 622 623 x.13 $input=622 $output_size=623 #622=(1,144,32,125)f32 #x.13=(1,144,1,1)f32
F.conv2d                 F.conv2d_44              7 1 x.13 weight.45 bias.19 633 634 635 2588 input.37 $input=x.13 $weight=weight.45 $bias=bias.19 $stride=633 $padding=634 $dilation=635 $groups=2588 #x.13=(1,144,1,1)f32 #weight.45=(6,144,1,1)f32 #bias.19=(6)f32 #input.37=(1,6,1,1)f32
nn.SiLU                  effnet._blocks.4._swish  1 1 input.37 638 #input.37=(1,6,1,1)f32 #638=(1,6,1,1)f32
prim::Constant           pnnx_484                 0 1 641 value=1
prim::Constant           pnnx_485                 0 1 642 value=0
pnnx.Attribute           effnet._blocks.4._se_expand 0 1 bias.21 @data=(144)f32 #bias.21=(144)f32
pnnx.Attribute           effnet._blocks.4._se_expand 0 1 weight.47 @data=(144,6,1,1)f32 #weight.47=(144,6,1,1)f32
prim::Constant           pnnx_486                 0 1 646 value=None
prim::Constant           pnnx_487                 0 1 2592 value=1
prim::ListConstruct      pnnx_488                 2 1 641 2592 647
prim::Constant           pnnx_489                 0 1 2593 value=0
prim::ListConstruct      pnnx_490                 2 1 642 2593 648
prim::Constant           pnnx_491                 0 1 2594 value=1
prim::Constant           pnnx_492                 0 1 2595 value=1
prim::ListConstruct      pnnx_493                 2 1 2594 2595 649
prim::Constant           pnnx_497                 0 1 2598 value=1
F.conv2d                 F.conv2d_45              7 1 638 weight.47 bias.21 647 648 649 2598 x_squeezed.10 $input=638 $weight=weight.47 $bias=bias.21 $stride=647 $padding=648 $dilation=649 $groups=2598 #638=(1,6,1,1)f32 #weight.47=(144,6,1,1)f32 #bias.21=(144)f32 #x_squeezed.10=(1,144,1,1)f32
F.sigmoid                F.sigmoid_142            1 1 x_squeezed.10 652 $input=x_squeezed.10 #x_squeezed.10=(1,144,1,1)f32 #652=(1,144,1,1)f32
aten::mul                pnnx_503                 2 1 652 622 x0.10 #652=(1,144,1,1)f32 #622=(1,144,32,125)f32 #x0.10=(1,144,32,125)f32
prim::Constant           pnnx_506                 0 1 656 value=None
prim::Constant           pnnx_507                 0 1 657 value=1
prim::Constant           pnnx_508                 0 1 658 value=0
pnnx.Attribute           effnet._blocks.4._project_conv 0 1 weight.49 @data=(24,144,1,1)f32 #weight.49=(24,144,1,1)f32
prim::Constant           pnnx_509                 0 1 661 value=None
prim::Constant           pnnx_510                 0 1 2602 value=1
prim::ListConstruct      pnnx_511                 2 1 657 2602 662
prim::Constant           pnnx_512                 0 1 2603 value=0
prim::ListConstruct      pnnx_513                 2 1 658 2603 663
prim::Constant           pnnx_514                 0 1 2604 value=1
prim::Constant           pnnx_515                 0 1 2605 value=1
prim::ListConstruct      pnnx_516                 2 1 2604 2605 664
prim::Constant           pnnx_520                 0 1 2608 value=1
F.conv2d                 F.conv2d_46              7 1 x0.10 weight.49 656 662 663 664 2608 input.39 $input=x0.10 $weight=weight.49 $bias=656 $stride=662 $padding=663 $dilation=664 $groups=2608 #x0.10=(1,144,32,125)f32 #weight.49=(24,144,1,1)f32 #input.39=(1,24,32,125)f32
nn.BatchNorm2d           effnet._blocks.4._bn2    1 1 input.39 667 affine=True eps=1.000000e-03 num_features=24 @bias=(24)f32 @running_mean=(24)f32 @running_var=(24)f32 @weight=(24)f32 #input.39=(1,24,32,125)f32 #667=(1,24,32,125)f32
prim::Constant           pnnx_525                 0 1 2612 value=1
aten::add                pnnx_526                 3 1 667 581 2612 668 #667=(1,24,32,125)f32 #581=(1,24,32,125)f32 #668=(1,24,32,125)f32
prim::Constant           pnnx_527                 0 1 669 value=1
prim::Constant           pnnx_530                 0 1 681 value=None
prim::Constant           pnnx_531                 0 1 682 value=1
prim::Constant           pnnx_532                 0 1 683 value=0
pnnx.Attribute           effnet._blocks.5._expand_conv 0 1 weight.51 @data=(144,24,1,1)f32 #weight.51=(144,24,1,1)f32
prim::Constant           pnnx_533                 0 1 686 value=None
prim::Constant           pnnx_534                 0 1 2613 value=1
prim::ListConstruct      pnnx_535                 2 1 682 2613 687
prim::Constant           pnnx_536                 0 1 2614 value=0
prim::ListConstruct      pnnx_537                 2 1 683 2614 688
prim::Constant           pnnx_538                 0 1 2615 value=1
prim::Constant           pnnx_539                 0 1 2616 value=1
prim::ListConstruct      pnnx_540                 2 1 2615 2616 689
prim::Constant           pnnx_544                 0 1 2619 value=1
F.conv2d                 F.conv2d_47              7 1 668 weight.51 681 687 688 689 2619 input.41 $input=668 $weight=weight.51 $bias=681 $stride=687 $padding=688 $dilation=689 $groups=2619 #668=(1,24,32,125)f32 #weight.51=(144,24,1,1)f32 #input.41=(1,144,32,125)f32
nn.BatchNorm2d           effnet._blocks.5._bn0    1 1 input.41 692 affine=True eps=1.000000e-03 num_features=144 @bias=(144)f32 @running_mean=(144)f32 @running_var=(144)f32 @weight=(144)f32 #input.41=(1,144,32,125)f32 #692=(1,144,32,125)f32
nn.SiLU                  effnet._blocks.5._swish  1 1 692 693 #692=(1,144,32,125)f32 #693=(1,144,32,125)f32
prim::Constant           pnnx_551                 0 1 696 value=None
prim::Constant           pnnx_552                 0 1 697 value=2
prim::Constant           pnnx_553                 0 1 698 value=0
prim::Constant           pnnx_554                 0 1 699 value=1
prim::Constant           pnnx_555                 0 1 700 value=144
pnnx.Attribute           effnet._blocks.5._depthwise_conv 0 1 weight.53 @data=(144,1,5,5)f32 #weight.53=(144,1,5,5)f32
nn.ZeroPad2d             effnet._blocks.5._depthwise_conv.static_padding 1 1 693 703 padding=(2,2,2,2) #693=(1,144,32,125)f32 #703=(1,144,36,129)f32
prim::Constant           pnnx_556                 0 1 2623 value=2
prim::ListConstruct      pnnx_557                 2 1 697 2623 704
prim::Constant           pnnx_558                 0 1 2624 value=0
prim::ListConstruct      pnnx_559                 2 1 698 2624 705
prim::Constant           pnnx_560                 0 1 2625 value=1
prim::ListConstruct      pnnx_561                 2 1 699 2625 706
F.conv2d                 F.conv2d_48              7 1 703 weight.53 696 704 705 706 700 input.43 $input=703 $weight=weight.53 $bias=696 $stride=704 $padding=705 $dilation=706 $groups=700 #703=(1,144,36,129)f32 #weight.53=(144,1,5,5)f32 #input.43=(1,144,16,63)f32
nn.BatchNorm2d           effnet._blocks.5._bn1    1 1 input.43 709 affine=True eps=1.000000e-03 num_features=144 @bias=(144)f32 @running_mean=(144)f32 @running_var=(144)f32 @weight=(144)f32 #input.43=(1,144,16,63)f32 #709=(1,144,16,63)f32
nn.SiLU                  effnet._blocks.5._swish  1 1 709 710 #709=(1,144,16,63)f32 #710=(1,144,16,63)f32
prim::Constant           pnnx_569                 0 1 2631 value=1
prim::ListConstruct      pnnx_570                 2 1 669 2631 711
prim::Constant           pnnx_574                 0 1 715 value=1
prim::Constant           pnnx_575                 0 1 716 value=0
pnnx.Attribute           effnet._blocks.5._se_reduce 0 1 bias.23 @data=(6)f32 #bias.23=(6)f32
pnnx.Attribute           effnet._blocks.5._se_reduce 0 1 weight.55 @data=(6,144,1,1)f32 #weight.55=(6,144,1,1)f32
prim::Constant           pnnx_576                 0 1 720 value=None
prim::Constant           pnnx_577                 0 1 2632 value=1
prim::ListConstruct      pnnx_578                 2 1 715 2632 721
prim::Constant           pnnx_579                 0 1 2633 value=0
prim::ListConstruct      pnnx_580                 2 1 716 2633 722
prim::Constant           pnnx_581                 0 1 2634 value=1
prim::Constant           pnnx_582                 0 1 2635 value=1
prim::ListConstruct      pnnx_583                 2 1 2634 2635 723
prim::Constant           pnnx_587                 0 1 2638 value=1
F.adaptive_avg_pool2d    F.adaptive_avg_pool2d_5  2 1 710 711 x.15 $input=710 $output_size=711 #710=(1,144,16,63)f32 #x.15=(1,144,1,1)f32
F.conv2d                 F.conv2d_49              7 1 x.15 weight.55 bias.23 721 722 723 2638 input.45 $input=x.15 $weight=weight.55 $bias=bias.23 $stride=721 $padding=722 $dilation=723 $groups=2638 #x.15=(1,144,1,1)f32 #weight.55=(6,144,1,1)f32 #bias.23=(6)f32 #input.45=(1,6,1,1)f32
nn.SiLU                  effnet._blocks.5._swish  1 1 input.45 726 #input.45=(1,6,1,1)f32 #726=(1,6,1,1)f32
prim::Constant           pnnx_594                 0 1 729 value=1
prim::Constant           pnnx_595                 0 1 730 value=0
pnnx.Attribute           effnet._blocks.5._se_expand 0 1 bias.25 @data=(144)f32 #bias.25=(144)f32
pnnx.Attribute           effnet._blocks.5._se_expand 0 1 weight.57 @data=(144,6,1,1)f32 #weight.57=(144,6,1,1)f32
prim::Constant           pnnx_596                 0 1 734 value=None
prim::Constant           pnnx_597                 0 1 2642 value=1
prim::ListConstruct      pnnx_598                 2 1 729 2642 735
prim::Constant           pnnx_599                 0 1 2643 value=0
prim::ListConstruct      pnnx_600                 2 1 730 2643 736
prim::Constant           pnnx_601                 0 1 2644 value=1
prim::Constant           pnnx_602                 0 1 2645 value=1
prim::ListConstruct      pnnx_603                 2 1 2644 2645 737
prim::Constant           pnnx_607                 0 1 2648 value=1
F.conv2d                 F.conv2d_50              7 1 726 weight.57 bias.25 735 736 737 2648 x_squeezed.12 $input=726 $weight=weight.57 $bias=bias.25 $stride=735 $padding=736 $dilation=737 $groups=2648 #726=(1,6,1,1)f32 #weight.57=(144,6,1,1)f32 #bias.25=(144)f32 #x_squeezed.12=(1,144,1,1)f32
F.sigmoid                F.sigmoid_143            1 1 x_squeezed.12 740 $input=x_squeezed.12 #x_squeezed.12=(1,144,1,1)f32 #740=(1,144,1,1)f32
aten::mul                pnnx_613                 2 1 740 710 x0.12 #740=(1,144,1,1)f32 #710=(1,144,16,63)f32 #x0.12=(1,144,16,63)f32
prim::Constant           pnnx_616                 0 1 744 value=None
prim::Constant           pnnx_617                 0 1 745 value=1
prim::Constant           pnnx_618                 0 1 746 value=0
pnnx.Attribute           effnet._blocks.5._project_conv 0 1 weight.59 @data=(48,144,1,1)f32 #weight.59=(48,144,1,1)f32
prim::Constant           pnnx_619                 0 1 749 value=None
prim::Constant           pnnx_620                 0 1 2652 value=1
prim::ListConstruct      pnnx_621                 2 1 745 2652 750
prim::Constant           pnnx_622                 0 1 2653 value=0
prim::ListConstruct      pnnx_623                 2 1 746 2653 751
prim::Constant           pnnx_624                 0 1 2654 value=1
prim::Constant           pnnx_625                 0 1 2655 value=1
prim::ListConstruct      pnnx_626                 2 1 2654 2655 752
prim::Constant           pnnx_630                 0 1 2658 value=1
F.conv2d                 F.conv2d_51              7 1 x0.12 weight.59 744 750 751 752 2658 input.47 $input=x0.12 $weight=weight.59 $bias=744 $stride=750 $padding=751 $dilation=752 $groups=2658 #x0.12=(1,144,16,63)f32 #weight.59=(48,144,1,1)f32 #input.47=(1,48,16,63)f32
nn.BatchNorm2d           effnet._blocks.5._bn2    1 1 input.47 755 affine=True eps=1.000000e-03 num_features=48 @bias=(48)f32 @running_mean=(48)f32 @running_var=(48)f32 @weight=(48)f32 #input.47=(1,48,16,63)f32 #755=(1,48,16,63)f32
prim::Constant           pnnx_635                 0 1 756 value=1
prim::Constant           pnnx_638                 0 1 768 value=None
prim::Constant           pnnx_639                 0 1 769 value=1
prim::Constant           pnnx_640                 0 1 770 value=0
pnnx.Attribute           effnet._blocks.6._expand_conv 0 1 weight.61 @data=(288,48,1,1)f32 #weight.61=(288,48,1,1)f32
prim::Constant           pnnx_641                 0 1 773 value=None
prim::Constant           pnnx_642                 0 1 2662 value=1
prim::ListConstruct      pnnx_643                 2 1 769 2662 774
prim::Constant           pnnx_644                 0 1 2663 value=0
prim::ListConstruct      pnnx_645                 2 1 770 2663 775
prim::Constant           pnnx_646                 0 1 2664 value=1
prim::Constant           pnnx_647                 0 1 2665 value=1
prim::ListConstruct      pnnx_648                 2 1 2664 2665 776
prim::Constant           pnnx_652                 0 1 2668 value=1
F.conv2d                 F.conv2d_52              7 1 755 weight.61 768 774 775 776 2668 input.49 $input=755 $weight=weight.61 $bias=768 $stride=774 $padding=775 $dilation=776 $groups=2668 #755=(1,48,16,63)f32 #weight.61=(288,48,1,1)f32 #input.49=(1,288,16,63)f32
nn.BatchNorm2d           effnet._blocks.6._bn0    1 1 input.49 779 affine=True eps=1.000000e-03 num_features=288 @bias=(288)f32 @running_mean=(288)f32 @running_var=(288)f32 @weight=(288)f32 #input.49=(1,288,16,63)f32 #779=(1,288,16,63)f32
nn.SiLU                  effnet._blocks.6._swish  1 1 779 780 #779=(1,288,16,63)f32 #780=(1,288,16,63)f32
prim::Constant           pnnx_659                 0 1 783 value=None
prim::Constant           pnnx_660                 0 1 784 value=1
prim::Constant           pnnx_661                 0 1 785 value=0
prim::Constant           pnnx_662                 0 1 786 value=288
pnnx.Attribute           effnet._blocks.6._depthwise_conv 0 1 weight.63 @data=(288,1,5,5)f32 #weight.63=(288,1,5,5)f32
nn.ZeroPad2d             effnet._blocks.6._depthwise_conv.static_padding 1 1 780 789 padding=(2,2,2,2) #780=(1,288,16,63)f32 #789=(1,288,20,67)f32
prim::Constant           pnnx_663                 0 1 2672 value=1
prim::ListConstruct      pnnx_664                 2 1 784 2672 790
prim::Constant           pnnx_665                 0 1 2673 value=0
prim::ListConstruct      pnnx_666                 2 1 785 2673 791
prim::Constant           pnnx_667                 0 1 2674 value=1
prim::Constant           pnnx_668                 0 1 2675 value=1
prim::ListConstruct      pnnx_669                 2 1 2674 2675 792
F.conv2d                 F.conv2d_53              7 1 789 weight.63 783 790 791 792 786 input.51 $input=789 $weight=weight.63 $bias=783 $stride=790 $padding=791 $dilation=792 $groups=786 #789=(1,288,20,67)f32 #weight.63=(288,1,5,5)f32 #input.51=(1,288,16,63)f32
nn.BatchNorm2d           effnet._blocks.6._bn1    1 1 input.51 795 affine=True eps=1.000000e-03 num_features=288 @bias=(288)f32 @running_mean=(288)f32 @running_var=(288)f32 @weight=(288)f32 #input.51=(1,288,16,63)f32 #795=(1,288,16,63)f32
nn.SiLU                  effnet._blocks.6._swish  1 1 795 796 #795=(1,288,16,63)f32 #796=(1,288,16,63)f32
prim::Constant           pnnx_677                 0 1 2681 value=1
prim::ListConstruct      pnnx_678                 2 1 756 2681 797
prim::Constant           pnnx_682                 0 1 801 value=1
prim::Constant           pnnx_683                 0 1 802 value=0
pnnx.Attribute           effnet._blocks.6._se_reduce 0 1 bias.27 @data=(12)f32 #bias.27=(12)f32
pnnx.Attribute           effnet._blocks.6._se_reduce 0 1 weight.65 @data=(12,288,1,1)f32 #weight.65=(12,288,1,1)f32
prim::Constant           pnnx_684                 0 1 806 value=None
prim::Constant           pnnx_685                 0 1 2682 value=1
prim::ListConstruct      pnnx_686                 2 1 801 2682 807
prim::Constant           pnnx_687                 0 1 2683 value=0
prim::ListConstruct      pnnx_688                 2 1 802 2683 808
prim::Constant           pnnx_689                 0 1 2684 value=1
prim::Constant           pnnx_690                 0 1 2685 value=1
prim::ListConstruct      pnnx_691                 2 1 2684 2685 809
prim::Constant           pnnx_695                 0 1 2688 value=1
F.adaptive_avg_pool2d    F.adaptive_avg_pool2d_6  2 1 796 797 x.17 $input=796 $output_size=797 #796=(1,288,16,63)f32 #x.17=(1,288,1,1)f32
F.conv2d                 F.conv2d_54              7 1 x.17 weight.65 bias.27 807 808 809 2688 input.53 $input=x.17 $weight=weight.65 $bias=bias.27 $stride=807 $padding=808 $dilation=809 $groups=2688 #x.17=(1,288,1,1)f32 #weight.65=(12,288,1,1)f32 #bias.27=(12)f32 #input.53=(1,12,1,1)f32
nn.SiLU                  effnet._blocks.6._swish  1 1 input.53 812 #input.53=(1,12,1,1)f32 #812=(1,12,1,1)f32
prim::Constant           pnnx_702                 0 1 815 value=1
prim::Constant           pnnx_703                 0 1 816 value=0
pnnx.Attribute           effnet._blocks.6._se_expand 0 1 bias.29 @data=(288)f32 #bias.29=(288)f32
pnnx.Attribute           effnet._blocks.6._se_expand 0 1 weight.67 @data=(288,12,1,1)f32 #weight.67=(288,12,1,1)f32
prim::Constant           pnnx_704                 0 1 820 value=None
prim::Constant           pnnx_705                 0 1 2692 value=1
prim::ListConstruct      pnnx_706                 2 1 815 2692 821
prim::Constant           pnnx_707                 0 1 2693 value=0
prim::ListConstruct      pnnx_708                 2 1 816 2693 822
prim::Constant           pnnx_709                 0 1 2694 value=1
prim::Constant           pnnx_710                 0 1 2695 value=1
prim::ListConstruct      pnnx_711                 2 1 2694 2695 823
prim::Constant           pnnx_715                 0 1 2698 value=1
F.conv2d                 F.conv2d_55              7 1 812 weight.67 bias.29 821 822 823 2698 x_squeezed.14 $input=812 $weight=weight.67 $bias=bias.29 $stride=821 $padding=822 $dilation=823 $groups=2698 #812=(1,12,1,1)f32 #weight.67=(288,12,1,1)f32 #bias.29=(288)f32 #x_squeezed.14=(1,288,1,1)f32
F.sigmoid                F.sigmoid_144            1 1 x_squeezed.14 826 $input=x_squeezed.14 #x_squeezed.14=(1,288,1,1)f32 #826=(1,288,1,1)f32
aten::mul                pnnx_721                 2 1 826 796 x0.14 #826=(1,288,1,1)f32 #796=(1,288,16,63)f32 #x0.14=(1,288,16,63)f32
prim::Constant           pnnx_724                 0 1 830 value=None
prim::Constant           pnnx_725                 0 1 831 value=1
prim::Constant           pnnx_726                 0 1 832 value=0
pnnx.Attribute           effnet._blocks.6._project_conv 0 1 weight.69 @data=(48,288,1,1)f32 #weight.69=(48,288,1,1)f32
prim::Constant           pnnx_727                 0 1 835 value=None
prim::Constant           pnnx_728                 0 1 2702 value=1
prim::ListConstruct      pnnx_729                 2 1 831 2702 836
prim::Constant           pnnx_730                 0 1 2703 value=0
prim::ListConstruct      pnnx_731                 2 1 832 2703 837
prim::Constant           pnnx_732                 0 1 2704 value=1
prim::Constant           pnnx_733                 0 1 2705 value=1
prim::ListConstruct      pnnx_734                 2 1 2704 2705 838
prim::Constant           pnnx_738                 0 1 2708 value=1
F.conv2d                 F.conv2d_56              7 1 x0.14 weight.69 830 836 837 838 2708 input.55 $input=x0.14 $weight=weight.69 $bias=830 $stride=836 $padding=837 $dilation=838 $groups=2708 #x0.14=(1,288,16,63)f32 #weight.69=(48,288,1,1)f32 #input.55=(1,48,16,63)f32
nn.BatchNorm2d           effnet._blocks.6._bn2    1 1 input.55 841 affine=True eps=1.000000e-03 num_features=48 @bias=(48)f32 @running_mean=(48)f32 @running_var=(48)f32 @weight=(48)f32 #input.55=(1,48,16,63)f32 #841=(1,48,16,63)f32
prim::Constant           pnnx_743                 0 1 2712 value=1
aten::add                pnnx_744                 3 1 841 755 2712 842 #841=(1,48,16,63)f32 #755=(1,48,16,63)f32 #842=(1,48,16,63)f32
prim::Constant           pnnx_745                 0 1 843 value=1
prim::Constant           pnnx_748                 0 1 855 value=None
prim::Constant           pnnx_749                 0 1 856 value=1
prim::Constant           pnnx_750                 0 1 857 value=0
pnnx.Attribute           effnet._blocks.7._expand_conv 0 1 weight.71 @data=(288,48,1,1)f32 #weight.71=(288,48,1,1)f32
prim::Constant           pnnx_751                 0 1 860 value=None
prim::Constant           pnnx_752                 0 1 2713 value=1
prim::ListConstruct      pnnx_753                 2 1 856 2713 861
prim::Constant           pnnx_754                 0 1 2714 value=0
prim::ListConstruct      pnnx_755                 2 1 857 2714 862
prim::Constant           pnnx_756                 0 1 2715 value=1
prim::Constant           pnnx_757                 0 1 2716 value=1
prim::ListConstruct      pnnx_758                 2 1 2715 2716 863
prim::Constant           pnnx_762                 0 1 2719 value=1
F.conv2d                 F.conv2d_57              7 1 842 weight.71 855 861 862 863 2719 input.57 $input=842 $weight=weight.71 $bias=855 $stride=861 $padding=862 $dilation=863 $groups=2719 #842=(1,48,16,63)f32 #weight.71=(288,48,1,1)f32 #input.57=(1,288,16,63)f32
nn.BatchNorm2d           effnet._blocks.7._bn0    1 1 input.57 866 affine=True eps=1.000000e-03 num_features=288 @bias=(288)f32 @running_mean=(288)f32 @running_var=(288)f32 @weight=(288)f32 #input.57=(1,288,16,63)f32 #866=(1,288,16,63)f32
nn.SiLU                  effnet._blocks.7._swish  1 1 866 867 #866=(1,288,16,63)f32 #867=(1,288,16,63)f32
prim::Constant           pnnx_769                 0 1 870 value=None
prim::Constant           pnnx_770                 0 1 871 value=1
prim::Constant           pnnx_771                 0 1 872 value=0
prim::Constant           pnnx_772                 0 1 873 value=288
pnnx.Attribute           effnet._blocks.7._depthwise_conv 0 1 weight.73 @data=(288,1,5,5)f32 #weight.73=(288,1,5,5)f32
nn.ZeroPad2d             effnet._blocks.7._depthwise_conv.static_padding 1 1 867 876 padding=(2,2,2,2) #867=(1,288,16,63)f32 #876=(1,288,20,67)f32
prim::Constant           pnnx_773                 0 1 2723 value=1
prim::ListConstruct      pnnx_774                 2 1 871 2723 877
prim::Constant           pnnx_775                 0 1 2724 value=0
prim::ListConstruct      pnnx_776                 2 1 872 2724 878
prim::Constant           pnnx_777                 0 1 2725 value=1
prim::Constant           pnnx_778                 0 1 2726 value=1
prim::ListConstruct      pnnx_779                 2 1 2725 2726 879
F.conv2d                 F.conv2d_58              7 1 876 weight.73 870 877 878 879 873 input.59 $input=876 $weight=weight.73 $bias=870 $stride=877 $padding=878 $dilation=879 $groups=873 #876=(1,288,20,67)f32 #weight.73=(288,1,5,5)f32 #input.59=(1,288,16,63)f32
nn.BatchNorm2d           effnet._blocks.7._bn1    1 1 input.59 882 affine=True eps=1.000000e-03 num_features=288 @bias=(288)f32 @running_mean=(288)f32 @running_var=(288)f32 @weight=(288)f32 #input.59=(1,288,16,63)f32 #882=(1,288,16,63)f32
nn.SiLU                  effnet._blocks.7._swish  1 1 882 883 #882=(1,288,16,63)f32 #883=(1,288,16,63)f32
prim::Constant           pnnx_787                 0 1 2732 value=1
prim::ListConstruct      pnnx_788                 2 1 843 2732 884
prim::Constant           pnnx_792                 0 1 888 value=1
prim::Constant           pnnx_793                 0 1 889 value=0
pnnx.Attribute           effnet._blocks.7._se_reduce 0 1 bias.31 @data=(12)f32 #bias.31=(12)f32
pnnx.Attribute           effnet._blocks.7._se_reduce 0 1 weight.75 @data=(12,288,1,1)f32 #weight.75=(12,288,1,1)f32
prim::Constant           pnnx_794                 0 1 893 value=None
prim::Constant           pnnx_795                 0 1 2733 value=1
prim::ListConstruct      pnnx_796                 2 1 888 2733 894
prim::Constant           pnnx_797                 0 1 2734 value=0
prim::ListConstruct      pnnx_798                 2 1 889 2734 895
prim::Constant           pnnx_799                 0 1 2735 value=1
prim::Constant           pnnx_800                 0 1 2736 value=1
prim::ListConstruct      pnnx_801                 2 1 2735 2736 896
prim::Constant           pnnx_805                 0 1 2739 value=1
F.adaptive_avg_pool2d    F.adaptive_avg_pool2d_7  2 1 883 884 x.19 $input=883 $output_size=884 #883=(1,288,16,63)f32 #x.19=(1,288,1,1)f32
F.conv2d                 F.conv2d_59              7 1 x.19 weight.75 bias.31 894 895 896 2739 input.61 $input=x.19 $weight=weight.75 $bias=bias.31 $stride=894 $padding=895 $dilation=896 $groups=2739 #x.19=(1,288,1,1)f32 #weight.75=(12,288,1,1)f32 #bias.31=(12)f32 #input.61=(1,12,1,1)f32
nn.SiLU                  effnet._blocks.7._swish  1 1 input.61 899 #input.61=(1,12,1,1)f32 #899=(1,12,1,1)f32
prim::Constant           pnnx_812                 0 1 902 value=1
prim::Constant           pnnx_813                 0 1 903 value=0
pnnx.Attribute           effnet._blocks.7._se_expand 0 1 bias.33 @data=(288)f32 #bias.33=(288)f32
pnnx.Attribute           effnet._blocks.7._se_expand 0 1 weight.77 @data=(288,12,1,1)f32 #weight.77=(288,12,1,1)f32
prim::Constant           pnnx_814                 0 1 907 value=None
prim::Constant           pnnx_815                 0 1 2743 value=1
prim::ListConstruct      pnnx_816                 2 1 902 2743 908
prim::Constant           pnnx_817                 0 1 2744 value=0
prim::ListConstruct      pnnx_818                 2 1 903 2744 909
prim::Constant           pnnx_819                 0 1 2745 value=1
prim::Constant           pnnx_820                 0 1 2746 value=1
prim::ListConstruct      pnnx_821                 2 1 2745 2746 910
prim::Constant           pnnx_825                 0 1 2749 value=1
F.conv2d                 F.conv2d_60              7 1 899 weight.77 bias.33 908 909 910 2749 x_squeezed.16 $input=899 $weight=weight.77 $bias=bias.33 $stride=908 $padding=909 $dilation=910 $groups=2749 #899=(1,12,1,1)f32 #weight.77=(288,12,1,1)f32 #bias.33=(288)f32 #x_squeezed.16=(1,288,1,1)f32
F.sigmoid                F.sigmoid_145            1 1 x_squeezed.16 913 $input=x_squeezed.16 #x_squeezed.16=(1,288,1,1)f32 #913=(1,288,1,1)f32
aten::mul                pnnx_831                 2 1 913 883 x0.16 #913=(1,288,1,1)f32 #883=(1,288,16,63)f32 #x0.16=(1,288,16,63)f32
prim::Constant           pnnx_834                 0 1 917 value=None
prim::Constant           pnnx_835                 0 1 918 value=1
prim::Constant           pnnx_836                 0 1 919 value=0
pnnx.Attribute           effnet._blocks.7._project_conv 0 1 weight.79 @data=(48,288,1,1)f32 #weight.79=(48,288,1,1)f32
prim::Constant           pnnx_837                 0 1 922 value=None
prim::Constant           pnnx_838                 0 1 2753 value=1
prim::ListConstruct      pnnx_839                 2 1 918 2753 923
prim::Constant           pnnx_840                 0 1 2754 value=0
prim::ListConstruct      pnnx_841                 2 1 919 2754 924
prim::Constant           pnnx_842                 0 1 2755 value=1
prim::Constant           pnnx_843                 0 1 2756 value=1
prim::ListConstruct      pnnx_844                 2 1 2755 2756 925
prim::Constant           pnnx_848                 0 1 2759 value=1
F.conv2d                 F.conv2d_61              7 1 x0.16 weight.79 917 923 924 925 2759 input.63 $input=x0.16 $weight=weight.79 $bias=917 $stride=923 $padding=924 $dilation=925 $groups=2759 #x0.16=(1,288,16,63)f32 #weight.79=(48,288,1,1)f32 #input.63=(1,48,16,63)f32
nn.BatchNorm2d           effnet._blocks.7._bn2    1 1 input.63 928 affine=True eps=1.000000e-03 num_features=48 @bias=(48)f32 @running_mean=(48)f32 @running_var=(48)f32 @weight=(48)f32 #input.63=(1,48,16,63)f32 #928=(1,48,16,63)f32
prim::Constant           pnnx_853                 0 1 2763 value=1
aten::add                pnnx_854                 3 1 928 842 2763 929 #928=(1,48,16,63)f32 #842=(1,48,16,63)f32 #929=(1,48,16,63)f32
prim::Constant           pnnx_855                 0 1 930 value=1
prim::Constant           pnnx_858                 0 1 942 value=None
prim::Constant           pnnx_859                 0 1 943 value=1
prim::Constant           pnnx_860                 0 1 944 value=0
pnnx.Attribute           effnet._blocks.8._expand_conv 0 1 weight.81 @data=(288,48,1,1)f32 #weight.81=(288,48,1,1)f32
prim::Constant           pnnx_861                 0 1 947 value=None
prim::Constant           pnnx_862                 0 1 2764 value=1
prim::ListConstruct      pnnx_863                 2 1 943 2764 948
prim::Constant           pnnx_864                 0 1 2765 value=0
prim::ListConstruct      pnnx_865                 2 1 944 2765 949
prim::Constant           pnnx_866                 0 1 2766 value=1
prim::Constant           pnnx_867                 0 1 2767 value=1
prim::ListConstruct      pnnx_868                 2 1 2766 2767 950
prim::Constant           pnnx_872                 0 1 2770 value=1
F.conv2d                 F.conv2d_62              7 1 929 weight.81 942 948 949 950 2770 input.65 $input=929 $weight=weight.81 $bias=942 $stride=948 $padding=949 $dilation=950 $groups=2770 #929=(1,48,16,63)f32 #weight.81=(288,48,1,1)f32 #input.65=(1,288,16,63)f32
nn.BatchNorm2d           effnet._blocks.8._bn0    1 1 input.65 953 affine=True eps=1.000000e-03 num_features=288 @bias=(288)f32 @running_mean=(288)f32 @running_var=(288)f32 @weight=(288)f32 #input.65=(1,288,16,63)f32 #953=(1,288,16,63)f32
nn.SiLU                  effnet._blocks.8._swish  1 1 953 954 #953=(1,288,16,63)f32 #954=(1,288,16,63)f32
prim::Constant           pnnx_879                 0 1 957 value=None
prim::Constant           pnnx_880                 0 1 958 value=2
prim::Constant           pnnx_881                 0 1 959 value=0
prim::Constant           pnnx_882                 0 1 960 value=1
prim::Constant           pnnx_883                 0 1 961 value=288
pnnx.Attribute           effnet._blocks.8._depthwise_conv 0 1 weight.83 @data=(288,1,3,3)f32 #weight.83=(288,1,3,3)f32
nn.ZeroPad2d             effnet._blocks.8._depthwise_conv.static_padding 1 1 954 964 padding=(1,1,1,1) #954=(1,288,16,63)f32 #964=(1,288,18,65)f32
prim::Constant           pnnx_884                 0 1 2774 value=2
prim::ListConstruct      pnnx_885                 2 1 958 2774 965
prim::Constant           pnnx_886                 0 1 2775 value=0
prim::ListConstruct      pnnx_887                 2 1 959 2775 966
prim::Constant           pnnx_888                 0 1 2776 value=1
prim::ListConstruct      pnnx_889                 2 1 960 2776 967
F.conv2d                 F.conv2d_63              7 1 964 weight.83 957 965 966 967 961 input.67 $input=964 $weight=weight.83 $bias=957 $stride=965 $padding=966 $dilation=967 $groups=961 #964=(1,288,18,65)f32 #weight.83=(288,1,3,3)f32 #input.67=(1,288,8,32)f32
nn.BatchNorm2d           effnet._blocks.8._bn1    1 1 input.67 970 affine=True eps=1.000000e-03 num_features=288 @bias=(288)f32 @running_mean=(288)f32 @running_var=(288)f32 @weight=(288)f32 #input.67=(1,288,8,32)f32 #970=(1,288,8,32)f32
nn.SiLU                  effnet._blocks.8._swish  1 1 970 971 #970=(1,288,8,32)f32 #971=(1,288,8,32)f32
prim::Constant           pnnx_897                 0 1 2782 value=1
prim::ListConstruct      pnnx_898                 2 1 930 2782 972
prim::Constant           pnnx_902                 0 1 976 value=1
prim::Constant           pnnx_903                 0 1 977 value=0
pnnx.Attribute           effnet._blocks.8._se_reduce 0 1 bias.35 @data=(12)f32 #bias.35=(12)f32
pnnx.Attribute           effnet._blocks.8._se_reduce 0 1 weight.85 @data=(12,288,1,1)f32 #weight.85=(12,288,1,1)f32
prim::Constant           pnnx_904                 0 1 981 value=None
prim::Constant           pnnx_905                 0 1 2783 value=1
prim::ListConstruct      pnnx_906                 2 1 976 2783 982
prim::Constant           pnnx_907                 0 1 2784 value=0
prim::ListConstruct      pnnx_908                 2 1 977 2784 983
prim::Constant           pnnx_909                 0 1 2785 value=1
prim::Constant           pnnx_910                 0 1 2786 value=1
prim::ListConstruct      pnnx_911                 2 1 2785 2786 984
prim::Constant           pnnx_915                 0 1 2789 value=1
F.adaptive_avg_pool2d    F.adaptive_avg_pool2d_8  2 1 971 972 x.21 $input=971 $output_size=972 #971=(1,288,8,32)f32 #x.21=(1,288,1,1)f32
F.conv2d                 F.conv2d_64              7 1 x.21 weight.85 bias.35 982 983 984 2789 input.69 $input=x.21 $weight=weight.85 $bias=bias.35 $stride=982 $padding=983 $dilation=984 $groups=2789 #x.21=(1,288,1,1)f32 #weight.85=(12,288,1,1)f32 #bias.35=(12)f32 #input.69=(1,12,1,1)f32
nn.SiLU                  effnet._blocks.8._swish  1 1 input.69 987 #input.69=(1,12,1,1)f32 #987=(1,12,1,1)f32
prim::Constant           pnnx_922                 0 1 990 value=1
prim::Constant           pnnx_923                 0 1 991 value=0
pnnx.Attribute           effnet._blocks.8._se_expand 0 1 bias.37 @data=(288)f32 #bias.37=(288)f32
pnnx.Attribute           effnet._blocks.8._se_expand 0 1 weight.87 @data=(288,12,1,1)f32 #weight.87=(288,12,1,1)f32
prim::Constant           pnnx_924                 0 1 995 value=None
prim::Constant           pnnx_925                 0 1 2793 value=1
prim::ListConstruct      pnnx_926                 2 1 990 2793 996
prim::Constant           pnnx_927                 0 1 2794 value=0
prim::ListConstruct      pnnx_928                 2 1 991 2794 997
prim::Constant           pnnx_929                 0 1 2795 value=1
prim::Constant           pnnx_930                 0 1 2796 value=1
prim::ListConstruct      pnnx_931                 2 1 2795 2796 998
prim::Constant           pnnx_935                 0 1 2799 value=1
F.conv2d                 F.conv2d_65              7 1 987 weight.87 bias.37 996 997 998 2799 x_squeezed.18 $input=987 $weight=weight.87 $bias=bias.37 $stride=996 $padding=997 $dilation=998 $groups=2799 #987=(1,12,1,1)f32 #weight.87=(288,12,1,1)f32 #bias.37=(288)f32 #x_squeezed.18=(1,288,1,1)f32
F.sigmoid                F.sigmoid_146            1 1 x_squeezed.18 1001 $input=x_squeezed.18 #x_squeezed.18=(1,288,1,1)f32 #1001=(1,288,1,1)f32
aten::mul                pnnx_941                 2 1 1001 971 x0.18 #1001=(1,288,1,1)f32 #971=(1,288,8,32)f32 #x0.18=(1,288,8,32)f32
prim::Constant           pnnx_944                 0 1 1005 value=None
prim::Constant           pnnx_945                 0 1 1006 value=1
prim::Constant           pnnx_946                 0 1 1007 value=0
pnnx.Attribute           effnet._blocks.8._project_conv 0 1 weight.89 @data=(88,288,1,1)f32 #weight.89=(88,288,1,1)f32
prim::Constant           pnnx_947                 0 1 1010 value=None
prim::Constant           pnnx_948                 0 1 2803 value=1
prim::ListConstruct      pnnx_949                 2 1 1006 2803 1011
prim::Constant           pnnx_950                 0 1 2804 value=0
prim::ListConstruct      pnnx_951                 2 1 1007 2804 1012
prim::Constant           pnnx_952                 0 1 2805 value=1
prim::Constant           pnnx_953                 0 1 2806 value=1
prim::ListConstruct      pnnx_954                 2 1 2805 2806 1013
prim::Constant           pnnx_958                 0 1 2809 value=1
F.conv2d                 F.conv2d_66              7 1 x0.18 weight.89 1005 1011 1012 1013 2809 input.71 $input=x0.18 $weight=weight.89 $bias=1005 $stride=1011 $padding=1012 $dilation=1013 $groups=2809 #x0.18=(1,288,8,32)f32 #weight.89=(88,288,1,1)f32 #input.71=(1,88,8,32)f32
nn.BatchNorm2d           effnet._blocks.8._bn2    1 1 input.71 1016 affine=True eps=1.000000e-03 num_features=88 @bias=(88)f32 @running_mean=(88)f32 @running_var=(88)f32 @weight=(88)f32 #input.71=(1,88,8,32)f32 #1016=(1,88,8,32)f32
prim::Constant           pnnx_963                 0 1 1017 value=1
prim::Constant           pnnx_966                 0 1 1029 value=None
prim::Constant           pnnx_967                 0 1 1030 value=1
prim::Constant           pnnx_968                 0 1 1031 value=0
pnnx.Attribute           effnet._blocks.9._expand_conv 0 1 weight.91 @data=(528,88,1,1)f32 #weight.91=(528,88,1,1)f32
prim::Constant           pnnx_969                 0 1 1034 value=None
prim::Constant           pnnx_970                 0 1 2813 value=1
prim::ListConstruct      pnnx_971                 2 1 1030 2813 1035
prim::Constant           pnnx_972                 0 1 2814 value=0
prim::ListConstruct      pnnx_973                 2 1 1031 2814 1036
prim::Constant           pnnx_974                 0 1 2815 value=1
prim::Constant           pnnx_975                 0 1 2816 value=1
prim::ListConstruct      pnnx_976                 2 1 2815 2816 1037
prim::Constant           pnnx_980                 0 1 2819 value=1
F.conv2d                 F.conv2d_67              7 1 1016 weight.91 1029 1035 1036 1037 2819 input.73 $input=1016 $weight=weight.91 $bias=1029 $stride=1035 $padding=1036 $dilation=1037 $groups=2819 #1016=(1,88,8,32)f32 #weight.91=(528,88,1,1)f32 #input.73=(1,528,8,32)f32
nn.BatchNorm2d           effnet._blocks.9._bn0    1 1 input.73 1040 affine=True eps=1.000000e-03 num_features=528 @bias=(528)f32 @running_mean=(528)f32 @running_var=(528)f32 @weight=(528)f32 #input.73=(1,528,8,32)f32 #1040=(1,528,8,32)f32
nn.SiLU                  effnet._blocks.9._swish  1 1 1040 1041 #1040=(1,528,8,32)f32 #1041=(1,528,8,32)f32
prim::Constant           pnnx_987                 0 1 1044 value=None
prim::Constant           pnnx_988                 0 1 1045 value=1
prim::Constant           pnnx_989                 0 1 1046 value=0
prim::Constant           pnnx_990                 0 1 1047 value=528
pnnx.Attribute           effnet._blocks.9._depthwise_conv 0 1 weight.93 @data=(528,1,3,3)f32 #weight.93=(528,1,3,3)f32
nn.ZeroPad2d             effnet._blocks.9._depthwise_conv.static_padding 1 1 1041 1050 padding=(1,1,1,1) #1041=(1,528,8,32)f32 #1050=(1,528,10,34)f32
prim::Constant           pnnx_991                 0 1 2823 value=1
prim::ListConstruct      pnnx_992                 2 1 1045 2823 1051
prim::Constant           pnnx_993                 0 1 2824 value=0
prim::ListConstruct      pnnx_994                 2 1 1046 2824 1052
prim::Constant           pnnx_995                 0 1 2825 value=1
prim::Constant           pnnx_996                 0 1 2826 value=1
prim::ListConstruct      pnnx_997                 2 1 2825 2826 1053
F.conv2d                 F.conv2d_68              7 1 1050 weight.93 1044 1051 1052 1053 1047 input.75 $input=1050 $weight=weight.93 $bias=1044 $stride=1051 $padding=1052 $dilation=1053 $groups=1047 #1050=(1,528,10,34)f32 #weight.93=(528,1,3,3)f32 #input.75=(1,528,8,32)f32
nn.BatchNorm2d           effnet._blocks.9._bn1    1 1 input.75 1056 affine=True eps=1.000000e-03 num_features=528 @bias=(528)f32 @running_mean=(528)f32 @running_var=(528)f32 @weight=(528)f32 #input.75=(1,528,8,32)f32 #1056=(1,528,8,32)f32
nn.SiLU                  effnet._blocks.9._swish  1 1 1056 1057 #1056=(1,528,8,32)f32 #1057=(1,528,8,32)f32
prim::Constant           pnnx_1005                0 1 2832 value=1
prim::ListConstruct      pnnx_1006                2 1 1017 2832 1058
prim::Constant           pnnx_1010                0 1 1062 value=1
prim::Constant           pnnx_1011                0 1 1063 value=0
pnnx.Attribute           effnet._blocks.9._se_reduce 0 1 bias.39 @data=(22)f32 #bias.39=(22)f32
pnnx.Attribute           effnet._blocks.9._se_reduce 0 1 weight.95 @data=(22,528,1,1)f32 #weight.95=(22,528,1,1)f32
prim::Constant           pnnx_1012                0 1 1067 value=None
prim::Constant           pnnx_1013                0 1 2833 value=1
prim::ListConstruct      pnnx_1014                2 1 1062 2833 1068
prim::Constant           pnnx_1015                0 1 2834 value=0
prim::ListConstruct      pnnx_1016                2 1 1063 2834 1069
prim::Constant           pnnx_1017                0 1 2835 value=1
prim::Constant           pnnx_1018                0 1 2836 value=1
prim::ListConstruct      pnnx_1019                2 1 2835 2836 1070
prim::Constant           pnnx_1023                0 1 2839 value=1
F.adaptive_avg_pool2d    F.adaptive_avg_pool2d_9  2 1 1057 1058 x.23 $input=1057 $output_size=1058 #1057=(1,528,8,32)f32 #x.23=(1,528,1,1)f32
F.conv2d                 F.conv2d_69              7 1 x.23 weight.95 bias.39 1068 1069 1070 2839 input.77 $input=x.23 $weight=weight.95 $bias=bias.39 $stride=1068 $padding=1069 $dilation=1070 $groups=2839 #x.23=(1,528,1,1)f32 #weight.95=(22,528,1,1)f32 #bias.39=(22)f32 #input.77=(1,22,1,1)f32
nn.SiLU                  effnet._blocks.9._swish  1 1 input.77 1073 #input.77=(1,22,1,1)f32 #1073=(1,22,1,1)f32
prim::Constant           pnnx_1030                0 1 1076 value=1
prim::Constant           pnnx_1031                0 1 1077 value=0
pnnx.Attribute           effnet._blocks.9._se_expand 0 1 bias.41 @data=(528)f32 #bias.41=(528)f32
pnnx.Attribute           effnet._blocks.9._se_expand 0 1 weight.97 @data=(528,22,1,1)f32 #weight.97=(528,22,1,1)f32
prim::Constant           pnnx_1032                0 1 1081 value=None
prim::Constant           pnnx_1033                0 1 2843 value=1
prim::ListConstruct      pnnx_1034                2 1 1076 2843 1082
prim::Constant           pnnx_1035                0 1 2844 value=0
prim::ListConstruct      pnnx_1036                2 1 1077 2844 1083
prim::Constant           pnnx_1037                0 1 2845 value=1
prim::Constant           pnnx_1038                0 1 2846 value=1
prim::ListConstruct      pnnx_1039                2 1 2845 2846 1084
prim::Constant           pnnx_1043                0 1 2849 value=1
F.conv2d                 F.conv2d_70              7 1 1073 weight.97 bias.41 1082 1083 1084 2849 x_squeezed.20 $input=1073 $weight=weight.97 $bias=bias.41 $stride=1082 $padding=1083 $dilation=1084 $groups=2849 #1073=(1,22,1,1)f32 #weight.97=(528,22,1,1)f32 #bias.41=(528)f32 #x_squeezed.20=(1,528,1,1)f32
F.sigmoid                F.sigmoid_147            1 1 x_squeezed.20 1087 $input=x_squeezed.20 #x_squeezed.20=(1,528,1,1)f32 #1087=(1,528,1,1)f32
aten::mul                pnnx_1049                2 1 1087 1057 x0.20 #1087=(1,528,1,1)f32 #1057=(1,528,8,32)f32 #x0.20=(1,528,8,32)f32
prim::Constant           pnnx_1052                0 1 1091 value=None
prim::Constant           pnnx_1053                0 1 1092 value=1
prim::Constant           pnnx_1054                0 1 1093 value=0
pnnx.Attribute           effnet._blocks.9._project_conv 0 1 weight.99 @data=(88,528,1,1)f32 #weight.99=(88,528,1,1)f32
prim::Constant           pnnx_1055                0 1 1096 value=None
prim::Constant           pnnx_1056                0 1 2853 value=1
prim::ListConstruct      pnnx_1057                2 1 1092 2853 1097
prim::Constant           pnnx_1058                0 1 2854 value=0
prim::ListConstruct      pnnx_1059                2 1 1093 2854 1098
prim::Constant           pnnx_1060                0 1 2855 value=1
prim::Constant           pnnx_1061                0 1 2856 value=1
prim::ListConstruct      pnnx_1062                2 1 2855 2856 1099
prim::Constant           pnnx_1066                0 1 2859 value=1
F.conv2d                 F.conv2d_71              7 1 x0.20 weight.99 1091 1097 1098 1099 2859 input.79 $input=x0.20 $weight=weight.99 $bias=1091 $stride=1097 $padding=1098 $dilation=1099 $groups=2859 #x0.20=(1,528,8,32)f32 #weight.99=(88,528,1,1)f32 #input.79=(1,88,8,32)f32
nn.BatchNorm2d           effnet._blocks.9._bn2    1 1 input.79 1102 affine=True eps=1.000000e-03 num_features=88 @bias=(88)f32 @running_mean=(88)f32 @running_var=(88)f32 @weight=(88)f32 #input.79=(1,88,8,32)f32 #1102=(1,88,8,32)f32
prim::Constant           pnnx_1071                0 1 2863 value=1
aten::add                pnnx_1072                3 1 1102 1016 2863 1103 #1102=(1,88,8,32)f32 #1016=(1,88,8,32)f32 #1103=(1,88,8,32)f32
prim::Constant           pnnx_1073                0 1 1104 value=1
prim::Constant           pnnx_1076                0 1 1116 value=None
prim::Constant           pnnx_1077                0 1 1117 value=1
prim::Constant           pnnx_1078                0 1 1118 value=0
pnnx.Attribute           effnet._blocks.10._expand_conv 0 1 weight.101 @data=(528,88,1,1)f32 #weight.101=(528,88,1,1)f32
prim::Constant           pnnx_1079                0 1 1121 value=None
prim::Constant           pnnx_1080                0 1 2864 value=1
prim::ListConstruct      pnnx_1081                2 1 1117 2864 1122
prim::Constant           pnnx_1082                0 1 2865 value=0
prim::ListConstruct      pnnx_1083                2 1 1118 2865 1123
prim::Constant           pnnx_1084                0 1 2866 value=1
prim::Constant           pnnx_1085                0 1 2867 value=1
prim::ListConstruct      pnnx_1086                2 1 2866 2867 1124
prim::Constant           pnnx_1090                0 1 2870 value=1
F.conv2d                 F.conv2d_72              7 1 1103 weight.101 1116 1122 1123 1124 2870 input.81 $input=1103 $weight=weight.101 $bias=1116 $stride=1122 $padding=1123 $dilation=1124 $groups=2870 #1103=(1,88,8,32)f32 #weight.101=(528,88,1,1)f32 #input.81=(1,528,8,32)f32
nn.BatchNorm2d           effnet._blocks.10._bn0   1 1 input.81 1127 affine=True eps=1.000000e-03 num_features=528 @bias=(528)f32 @running_mean=(528)f32 @running_var=(528)f32 @weight=(528)f32 #input.81=(1,528,8,32)f32 #1127=(1,528,8,32)f32
nn.SiLU                  effnet._blocks.10._swish 1 1 1127 1128 #1127=(1,528,8,32)f32 #1128=(1,528,8,32)f32
prim::Constant           pnnx_1097                0 1 1131 value=None
prim::Constant           pnnx_1098                0 1 1132 value=1
prim::Constant           pnnx_1099                0 1 1133 value=0
prim::Constant           pnnx_1100                0 1 1134 value=528
pnnx.Attribute           effnet._blocks.10._depthwise_conv 0 1 weight.103 @data=(528,1,3,3)f32 #weight.103=(528,1,3,3)f32
nn.ZeroPad2d             effnet._blocks.10._depthwise_conv.static_padding 1 1 1128 1137 padding=(1,1,1,1) #1128=(1,528,8,32)f32 #1137=(1,528,10,34)f32
prim::Constant           pnnx_1101                0 1 2874 value=1
prim::ListConstruct      pnnx_1102                2 1 1132 2874 1138
prim::Constant           pnnx_1103                0 1 2875 value=0
prim::ListConstruct      pnnx_1104                2 1 1133 2875 1139
prim::Constant           pnnx_1105                0 1 2876 value=1
prim::Constant           pnnx_1106                0 1 2877 value=1
prim::ListConstruct      pnnx_1107                2 1 2876 2877 1140
F.conv2d                 F.conv2d_73              7 1 1137 weight.103 1131 1138 1139 1140 1134 input.83 $input=1137 $weight=weight.103 $bias=1131 $stride=1138 $padding=1139 $dilation=1140 $groups=1134 #1137=(1,528,10,34)f32 #weight.103=(528,1,3,3)f32 #input.83=(1,528,8,32)f32
nn.BatchNorm2d           effnet._blocks.10._bn1   1 1 input.83 1143 affine=True eps=1.000000e-03 num_features=528 @bias=(528)f32 @running_mean=(528)f32 @running_var=(528)f32 @weight=(528)f32 #input.83=(1,528,8,32)f32 #1143=(1,528,8,32)f32
nn.SiLU                  effnet._blocks.10._swish 1 1 1143 1144 #1143=(1,528,8,32)f32 #1144=(1,528,8,32)f32
prim::Constant           pnnx_1115                0 1 2883 value=1
prim::ListConstruct      pnnx_1116                2 1 1104 2883 1145
prim::Constant           pnnx_1120                0 1 1149 value=1
prim::Constant           pnnx_1121                0 1 1150 value=0
pnnx.Attribute           effnet._blocks.10._se_reduce 0 1 bias.43 @data=(22)f32 #bias.43=(22)f32
pnnx.Attribute           effnet._blocks.10._se_reduce 0 1 weight.105 @data=(22,528,1,1)f32 #weight.105=(22,528,1,1)f32
prim::Constant           pnnx_1122                0 1 1154 value=None
prim::Constant           pnnx_1123                0 1 2884 value=1
prim::ListConstruct      pnnx_1124                2 1 1149 2884 1155
prim::Constant           pnnx_1125                0 1 2885 value=0
prim::ListConstruct      pnnx_1126                2 1 1150 2885 1156
prim::Constant           pnnx_1127                0 1 2886 value=1
prim::Constant           pnnx_1128                0 1 2887 value=1
prim::ListConstruct      pnnx_1129                2 1 2886 2887 1157
prim::Constant           pnnx_1133                0 1 2890 value=1
F.adaptive_avg_pool2d    F.adaptive_avg_pool2d_10 2 1 1144 1145 x.25 $input=1144 $output_size=1145 #1144=(1,528,8,32)f32 #x.25=(1,528,1,1)f32
F.conv2d                 F.conv2d_74              7 1 x.25 weight.105 bias.43 1155 1156 1157 2890 input.85 $input=x.25 $weight=weight.105 $bias=bias.43 $stride=1155 $padding=1156 $dilation=1157 $groups=2890 #x.25=(1,528,1,1)f32 #weight.105=(22,528,1,1)f32 #bias.43=(22)f32 #input.85=(1,22,1,1)f32
nn.SiLU                  effnet._blocks.10._swish 1 1 input.85 1160 #input.85=(1,22,1,1)f32 #1160=(1,22,1,1)f32
prim::Constant           pnnx_1140                0 1 1163 value=1
prim::Constant           pnnx_1141                0 1 1164 value=0
pnnx.Attribute           effnet._blocks.10._se_expand 0 1 bias.45 @data=(528)f32 #bias.45=(528)f32
pnnx.Attribute           effnet._blocks.10._se_expand 0 1 weight.107 @data=(528,22,1,1)f32 #weight.107=(528,22,1,1)f32
prim::Constant           pnnx_1142                0 1 1168 value=None
prim::Constant           pnnx_1143                0 1 2894 value=1
prim::ListConstruct      pnnx_1144                2 1 1163 2894 1169
prim::Constant           pnnx_1145                0 1 2895 value=0
prim::ListConstruct      pnnx_1146                2 1 1164 2895 1170
prim::Constant           pnnx_1147                0 1 2896 value=1
prim::Constant           pnnx_1148                0 1 2897 value=1
prim::ListConstruct      pnnx_1149                2 1 2896 2897 1171
prim::Constant           pnnx_1153                0 1 2900 value=1
F.conv2d                 F.conv2d_75              7 1 1160 weight.107 bias.45 1169 1170 1171 2900 x_squeezed.22 $input=1160 $weight=weight.107 $bias=bias.45 $stride=1169 $padding=1170 $dilation=1171 $groups=2900 #1160=(1,22,1,1)f32 #weight.107=(528,22,1,1)f32 #bias.45=(528)f32 #x_squeezed.22=(1,528,1,1)f32
F.sigmoid                F.sigmoid_148            1 1 x_squeezed.22 1174 $input=x_squeezed.22 #x_squeezed.22=(1,528,1,1)f32 #1174=(1,528,1,1)f32
aten::mul                pnnx_1159                2 1 1174 1144 x0.22 #1174=(1,528,1,1)f32 #1144=(1,528,8,32)f32 #x0.22=(1,528,8,32)f32
prim::Constant           pnnx_1162                0 1 1178 value=None
prim::Constant           pnnx_1163                0 1 1179 value=1
prim::Constant           pnnx_1164                0 1 1180 value=0
pnnx.Attribute           effnet._blocks.10._project_conv 0 1 weight.109 @data=(88,528,1,1)f32 #weight.109=(88,528,1,1)f32
prim::Constant           pnnx_1165                0 1 1183 value=None
prim::Constant           pnnx_1166                0 1 2904 value=1
prim::ListConstruct      pnnx_1167                2 1 1179 2904 1184
prim::Constant           pnnx_1168                0 1 2905 value=0
prim::ListConstruct      pnnx_1169                2 1 1180 2905 1185
prim::Constant           pnnx_1170                0 1 2906 value=1
prim::Constant           pnnx_1171                0 1 2907 value=1
prim::ListConstruct      pnnx_1172                2 1 2906 2907 1186
prim::Constant           pnnx_1176                0 1 2910 value=1
F.conv2d                 F.conv2d_76              7 1 x0.22 weight.109 1178 1184 1185 1186 2910 input.87 $input=x0.22 $weight=weight.109 $bias=1178 $stride=1184 $padding=1185 $dilation=1186 $groups=2910 #x0.22=(1,528,8,32)f32 #weight.109=(88,528,1,1)f32 #input.87=(1,88,8,32)f32
nn.BatchNorm2d           effnet._blocks.10._bn2   1 1 input.87 1189 affine=True eps=1.000000e-03 num_features=88 @bias=(88)f32 @running_mean=(88)f32 @running_var=(88)f32 @weight=(88)f32 #input.87=(1,88,8,32)f32 #1189=(1,88,8,32)f32
prim::Constant           pnnx_1181                0 1 2914 value=1
aten::add                pnnx_1182                3 1 1189 1103 2914 1190 #1189=(1,88,8,32)f32 #1103=(1,88,8,32)f32 #1190=(1,88,8,32)f32
prim::Constant           pnnx_1183                0 1 1191 value=1
prim::Constant           pnnx_1186                0 1 1203 value=None
prim::Constant           pnnx_1187                0 1 1204 value=1
prim::Constant           pnnx_1188                0 1 1205 value=0
pnnx.Attribute           effnet._blocks.11._expand_conv 0 1 weight.111 @data=(528,88,1,1)f32 #weight.111=(528,88,1,1)f32
prim::Constant           pnnx_1189                0 1 1208 value=None
prim::Constant           pnnx_1190                0 1 2915 value=1
prim::ListConstruct      pnnx_1191                2 1 1204 2915 1209
prim::Constant           pnnx_1192                0 1 2916 value=0
prim::ListConstruct      pnnx_1193                2 1 1205 2916 1210
prim::Constant           pnnx_1194                0 1 2917 value=1
prim::Constant           pnnx_1195                0 1 2918 value=1
prim::ListConstruct      pnnx_1196                2 1 2917 2918 1211
prim::Constant           pnnx_1200                0 1 2921 value=1
F.conv2d                 F.conv2d_77              7 1 1190 weight.111 1203 1209 1210 1211 2921 input.89 $input=1190 $weight=weight.111 $bias=1203 $stride=1209 $padding=1210 $dilation=1211 $groups=2921 #1190=(1,88,8,32)f32 #weight.111=(528,88,1,1)f32 #input.89=(1,528,8,32)f32
nn.BatchNorm2d           effnet._blocks.11._bn0   1 1 input.89 1214 affine=True eps=1.000000e-03 num_features=528 @bias=(528)f32 @running_mean=(528)f32 @running_var=(528)f32 @weight=(528)f32 #input.89=(1,528,8,32)f32 #1214=(1,528,8,32)f32
nn.SiLU                  effnet._blocks.11._swish 1 1 1214 1215 #1214=(1,528,8,32)f32 #1215=(1,528,8,32)f32
prim::Constant           pnnx_1207                0 1 1218 value=None
prim::Constant           pnnx_1208                0 1 1219 value=1
prim::Constant           pnnx_1209                0 1 1220 value=0
prim::Constant           pnnx_1210                0 1 1221 value=528
pnnx.Attribute           effnet._blocks.11._depthwise_conv 0 1 weight.113 @data=(528,1,3,3)f32 #weight.113=(528,1,3,3)f32
nn.ZeroPad2d             effnet._blocks.11._depthwise_conv.static_padding 1 1 1215 1224 padding=(1,1,1,1) #1215=(1,528,8,32)f32 #1224=(1,528,10,34)f32
prim::Constant           pnnx_1211                0 1 2925 value=1
prim::ListConstruct      pnnx_1212                2 1 1219 2925 1225
prim::Constant           pnnx_1213                0 1 2926 value=0
prim::ListConstruct      pnnx_1214                2 1 1220 2926 1226
prim::Constant           pnnx_1215                0 1 2927 value=1
prim::Constant           pnnx_1216                0 1 2928 value=1
prim::ListConstruct      pnnx_1217                2 1 2927 2928 1227
F.conv2d                 F.conv2d_78              7 1 1224 weight.113 1218 1225 1226 1227 1221 input.91 $input=1224 $weight=weight.113 $bias=1218 $stride=1225 $padding=1226 $dilation=1227 $groups=1221 #1224=(1,528,10,34)f32 #weight.113=(528,1,3,3)f32 #input.91=(1,528,8,32)f32
nn.BatchNorm2d           effnet._blocks.11._bn1   1 1 input.91 1230 affine=True eps=1.000000e-03 num_features=528 @bias=(528)f32 @running_mean=(528)f32 @running_var=(528)f32 @weight=(528)f32 #input.91=(1,528,8,32)f32 #1230=(1,528,8,32)f32
nn.SiLU                  effnet._blocks.11._swish 1 1 1230 1231 #1230=(1,528,8,32)f32 #1231=(1,528,8,32)f32
prim::Constant           pnnx_1225                0 1 2934 value=1
prim::ListConstruct      pnnx_1226                2 1 1191 2934 1232
prim::Constant           pnnx_1230                0 1 1236 value=1
prim::Constant           pnnx_1231                0 1 1237 value=0
pnnx.Attribute           effnet._blocks.11._se_reduce 0 1 bias.47 @data=(22)f32 #bias.47=(22)f32
pnnx.Attribute           effnet._blocks.11._se_reduce 0 1 weight.115 @data=(22,528,1,1)f32 #weight.115=(22,528,1,1)f32
prim::Constant           pnnx_1232                0 1 1241 value=None
prim::Constant           pnnx_1233                0 1 2935 value=1
prim::ListConstruct      pnnx_1234                2 1 1236 2935 1242
prim::Constant           pnnx_1235                0 1 2936 value=0
prim::ListConstruct      pnnx_1236                2 1 1237 2936 1243
prim::Constant           pnnx_1237                0 1 2937 value=1
prim::Constant           pnnx_1238                0 1 2938 value=1
prim::ListConstruct      pnnx_1239                2 1 2937 2938 1244
prim::Constant           pnnx_1243                0 1 2941 value=1
F.adaptive_avg_pool2d    F.adaptive_avg_pool2d_11 2 1 1231 1232 x.27 $input=1231 $output_size=1232 #1231=(1,528,8,32)f32 #x.27=(1,528,1,1)f32
F.conv2d                 F.conv2d_79              7 1 x.27 weight.115 bias.47 1242 1243 1244 2941 input.93 $input=x.27 $weight=weight.115 $bias=bias.47 $stride=1242 $padding=1243 $dilation=1244 $groups=2941 #x.27=(1,528,1,1)f32 #weight.115=(22,528,1,1)f32 #bias.47=(22)f32 #input.93=(1,22,1,1)f32
nn.SiLU                  effnet._blocks.11._swish 1 1 input.93 1247 #input.93=(1,22,1,1)f32 #1247=(1,22,1,1)f32
prim::Constant           pnnx_1250                0 1 1250 value=1
prim::Constant           pnnx_1251                0 1 1251 value=0
pnnx.Attribute           effnet._blocks.11._se_expand 0 1 bias.49 @data=(528)f32 #bias.49=(528)f32
pnnx.Attribute           effnet._blocks.11._se_expand 0 1 weight.117 @data=(528,22,1,1)f32 #weight.117=(528,22,1,1)f32
prim::Constant           pnnx_1252                0 1 1255 value=None
prim::Constant           pnnx_1253                0 1 2945 value=1
prim::ListConstruct      pnnx_1254                2 1 1250 2945 1256
prim::Constant           pnnx_1255                0 1 2946 value=0
prim::ListConstruct      pnnx_1256                2 1 1251 2946 1257
prim::Constant           pnnx_1257                0 1 2947 value=1
prim::Constant           pnnx_1258                0 1 2948 value=1
prim::ListConstruct      pnnx_1259                2 1 2947 2948 1258
prim::Constant           pnnx_1263                0 1 2951 value=1
F.conv2d                 F.conv2d_80              7 1 1247 weight.117 bias.49 1256 1257 1258 2951 x_squeezed.24 $input=1247 $weight=weight.117 $bias=bias.49 $stride=1256 $padding=1257 $dilation=1258 $groups=2951 #1247=(1,22,1,1)f32 #weight.117=(528,22,1,1)f32 #bias.49=(528)f32 #x_squeezed.24=(1,528,1,1)f32
F.sigmoid                F.sigmoid_149            1 1 x_squeezed.24 1261 $input=x_squeezed.24 #x_squeezed.24=(1,528,1,1)f32 #1261=(1,528,1,1)f32
aten::mul                pnnx_1269                2 1 1261 1231 x0.24 #1261=(1,528,1,1)f32 #1231=(1,528,8,32)f32 #x0.24=(1,528,8,32)f32
prim::Constant           pnnx_1272                0 1 1265 value=None
prim::Constant           pnnx_1273                0 1 1266 value=1
prim::Constant           pnnx_1274                0 1 1267 value=0
pnnx.Attribute           effnet._blocks.11._project_conv 0 1 weight.119 @data=(88,528,1,1)f32 #weight.119=(88,528,1,1)f32
prim::Constant           pnnx_1275                0 1 1270 value=None
prim::Constant           pnnx_1276                0 1 2955 value=1
prim::ListConstruct      pnnx_1277                2 1 1266 2955 1271
prim::Constant           pnnx_1278                0 1 2956 value=0
prim::ListConstruct      pnnx_1279                2 1 1267 2956 1272
prim::Constant           pnnx_1280                0 1 2957 value=1
prim::Constant           pnnx_1281                0 1 2958 value=1
prim::ListConstruct      pnnx_1282                2 1 2957 2958 1273
prim::Constant           pnnx_1286                0 1 2961 value=1
F.conv2d                 F.conv2d_81              7 1 x0.24 weight.119 1265 1271 1272 1273 2961 input.95 $input=x0.24 $weight=weight.119 $bias=1265 $stride=1271 $padding=1272 $dilation=1273 $groups=2961 #x0.24=(1,528,8,32)f32 #weight.119=(88,528,1,1)f32 #input.95=(1,88,8,32)f32
nn.BatchNorm2d           effnet._blocks.11._bn2   1 1 input.95 1276 affine=True eps=1.000000e-03 num_features=88 @bias=(88)f32 @running_mean=(88)f32 @running_var=(88)f32 @weight=(88)f32 #input.95=(1,88,8,32)f32 #1276=(1,88,8,32)f32
prim::Constant           pnnx_1291                0 1 2965 value=1
aten::add                pnnx_1292                3 1 1276 1190 2965 1277 #1276=(1,88,8,32)f32 #1190=(1,88,8,32)f32 #1277=(1,88,8,32)f32
prim::Constant           pnnx_1293                0 1 1278 value=1
prim::Constant           pnnx_1296                0 1 1290 value=None
prim::Constant           pnnx_1297                0 1 1291 value=1
prim::Constant           pnnx_1298                0 1 1292 value=0
pnnx.Attribute           effnet._blocks.12._expand_conv 0 1 weight.121 @data=(528,88,1,1)f32 #weight.121=(528,88,1,1)f32
prim::Constant           pnnx_1299                0 1 1295 value=None
prim::Constant           pnnx_1300                0 1 2966 value=1
prim::ListConstruct      pnnx_1301                2 1 1291 2966 1296
prim::Constant           pnnx_1302                0 1 2967 value=0
prim::ListConstruct      pnnx_1303                2 1 1292 2967 1297
prim::Constant           pnnx_1304                0 1 2968 value=1
prim::Constant           pnnx_1305                0 1 2969 value=1
prim::ListConstruct      pnnx_1306                2 1 2968 2969 1298
prim::Constant           pnnx_1310                0 1 2972 value=1
F.conv2d                 F.conv2d_82              7 1 1277 weight.121 1290 1296 1297 1298 2972 input.97 $input=1277 $weight=weight.121 $bias=1290 $stride=1296 $padding=1297 $dilation=1298 $groups=2972 #1277=(1,88,8,32)f32 #weight.121=(528,88,1,1)f32 #input.97=(1,528,8,32)f32
nn.BatchNorm2d           effnet._blocks.12._bn0   1 1 input.97 1301 affine=True eps=1.000000e-03 num_features=528 @bias=(528)f32 @running_mean=(528)f32 @running_var=(528)f32 @weight=(528)f32 #input.97=(1,528,8,32)f32 #1301=(1,528,8,32)f32
nn.SiLU                  effnet._blocks.12._swish 1 1 1301 1302 #1301=(1,528,8,32)f32 #1302=(1,528,8,32)f32
prim::Constant           pnnx_1317                0 1 1305 value=None
prim::Constant           pnnx_1318                0 1 1306 value=1
prim::Constant           pnnx_1319                0 1 1307 value=0
prim::Constant           pnnx_1320                0 1 1308 value=528
pnnx.Attribute           effnet._blocks.12._depthwise_conv 0 1 weight.123 @data=(528,1,5,5)f32 #weight.123=(528,1,5,5)f32
nn.ZeroPad2d             effnet._blocks.12._depthwise_conv.static_padding 1 1 1302 1311 padding=(2,2,2,2) #1302=(1,528,8,32)f32 #1311=(1,528,12,36)f32
prim::Constant           pnnx_1321                0 1 2976 value=1
prim::ListConstruct      pnnx_1322                2 1 1306 2976 1312
prim::Constant           pnnx_1323                0 1 2977 value=0
prim::ListConstruct      pnnx_1324                2 1 1307 2977 1313
prim::Constant           pnnx_1325                0 1 2978 value=1
prim::Constant           pnnx_1326                0 1 2979 value=1
prim::ListConstruct      pnnx_1327                2 1 2978 2979 1314
F.conv2d                 F.conv2d_83              7 1 1311 weight.123 1305 1312 1313 1314 1308 input.99 $input=1311 $weight=weight.123 $bias=1305 $stride=1312 $padding=1313 $dilation=1314 $groups=1308 #1311=(1,528,12,36)f32 #weight.123=(528,1,5,5)f32 #input.99=(1,528,8,32)f32
nn.BatchNorm2d           effnet._blocks.12._bn1   1 1 input.99 1317 affine=True eps=1.000000e-03 num_features=528 @bias=(528)f32 @running_mean=(528)f32 @running_var=(528)f32 @weight=(528)f32 #input.99=(1,528,8,32)f32 #1317=(1,528,8,32)f32
nn.SiLU                  effnet._blocks.12._swish 1 1 1317 1318 #1317=(1,528,8,32)f32 #1318=(1,528,8,32)f32
prim::Constant           pnnx_1335                0 1 2985 value=1
prim::ListConstruct      pnnx_1336                2 1 1278 2985 1319
prim::Constant           pnnx_1340                0 1 1323 value=1
prim::Constant           pnnx_1341                0 1 1324 value=0
pnnx.Attribute           effnet._blocks.12._se_reduce 0 1 bias.51 @data=(22)f32 #bias.51=(22)f32
pnnx.Attribute           effnet._blocks.12._se_reduce 0 1 weight.125 @data=(22,528,1,1)f32 #weight.125=(22,528,1,1)f32
prim::Constant           pnnx_1342                0 1 1328 value=None
prim::Constant           pnnx_1343                0 1 2986 value=1
prim::ListConstruct      pnnx_1344                2 1 1323 2986 1329
prim::Constant           pnnx_1345                0 1 2987 value=0
prim::ListConstruct      pnnx_1346                2 1 1324 2987 1330
prim::Constant           pnnx_1347                0 1 2988 value=1
prim::Constant           pnnx_1348                0 1 2989 value=1
prim::ListConstruct      pnnx_1349                2 1 2988 2989 1331
prim::Constant           pnnx_1353                0 1 2992 value=1
F.adaptive_avg_pool2d    F.adaptive_avg_pool2d_12 2 1 1318 1319 x.29 $input=1318 $output_size=1319 #1318=(1,528,8,32)f32 #x.29=(1,528,1,1)f32
F.conv2d                 F.conv2d_84              7 1 x.29 weight.125 bias.51 1329 1330 1331 2992 input.101 $input=x.29 $weight=weight.125 $bias=bias.51 $stride=1329 $padding=1330 $dilation=1331 $groups=2992 #x.29=(1,528,1,1)f32 #weight.125=(22,528,1,1)f32 #bias.51=(22)f32 #input.101=(1,22,1,1)f32
nn.SiLU                  effnet._blocks.12._swish 1 1 input.101 1334 #input.101=(1,22,1,1)f32 #1334=(1,22,1,1)f32
prim::Constant           pnnx_1360                0 1 1337 value=1
prim::Constant           pnnx_1361                0 1 1338 value=0
pnnx.Attribute           effnet._blocks.12._se_expand 0 1 bias.53 @data=(528)f32 #bias.53=(528)f32
pnnx.Attribute           effnet._blocks.12._se_expand 0 1 weight.127 @data=(528,22,1,1)f32 #weight.127=(528,22,1,1)f32
prim::Constant           pnnx_1362                0 1 1342 value=None
prim::Constant           pnnx_1363                0 1 2996 value=1
prim::ListConstruct      pnnx_1364                2 1 1337 2996 1343
prim::Constant           pnnx_1365                0 1 2997 value=0
prim::ListConstruct      pnnx_1366                2 1 1338 2997 1344
prim::Constant           pnnx_1367                0 1 2998 value=1
prim::Constant           pnnx_1368                0 1 2999 value=1
prim::ListConstruct      pnnx_1369                2 1 2998 2999 1345
prim::Constant           pnnx_1373                0 1 3002 value=1
F.conv2d                 F.conv2d_85              7 1 1334 weight.127 bias.53 1343 1344 1345 3002 x_squeezed.26 $input=1334 $weight=weight.127 $bias=bias.53 $stride=1343 $padding=1344 $dilation=1345 $groups=3002 #1334=(1,22,1,1)f32 #weight.127=(528,22,1,1)f32 #bias.53=(528)f32 #x_squeezed.26=(1,528,1,1)f32
F.sigmoid                F.sigmoid_150            1 1 x_squeezed.26 1348 $input=x_squeezed.26 #x_squeezed.26=(1,528,1,1)f32 #1348=(1,528,1,1)f32
aten::mul                pnnx_1379                2 1 1348 1318 x0.26 #1348=(1,528,1,1)f32 #1318=(1,528,8,32)f32 #x0.26=(1,528,8,32)f32
prim::Constant           pnnx_1382                0 1 1352 value=None
prim::Constant           pnnx_1383                0 1 1353 value=1
prim::Constant           pnnx_1384                0 1 1354 value=0
pnnx.Attribute           effnet._blocks.12._project_conv 0 1 weight.129 @data=(120,528,1,1)f32 #weight.129=(120,528,1,1)f32
prim::Constant           pnnx_1385                0 1 1357 value=None
prim::Constant           pnnx_1386                0 1 3006 value=1
prim::ListConstruct      pnnx_1387                2 1 1353 3006 1358
prim::Constant           pnnx_1388                0 1 3007 value=0
prim::ListConstruct      pnnx_1389                2 1 1354 3007 1359
prim::Constant           pnnx_1390                0 1 3008 value=1
prim::Constant           pnnx_1391                0 1 3009 value=1
prim::ListConstruct      pnnx_1392                2 1 3008 3009 1360
prim::Constant           pnnx_1396                0 1 3012 value=1
F.conv2d                 F.conv2d_86              7 1 x0.26 weight.129 1352 1358 1359 1360 3012 input.103 $input=x0.26 $weight=weight.129 $bias=1352 $stride=1358 $padding=1359 $dilation=1360 $groups=3012 #x0.26=(1,528,8,32)f32 #weight.129=(120,528,1,1)f32 #input.103=(1,120,8,32)f32
nn.BatchNorm2d           effnet._blocks.12._bn2   1 1 input.103 1363 affine=True eps=1.000000e-03 num_features=120 @bias=(120)f32 @running_mean=(120)f32 @running_var=(120)f32 @weight=(120)f32 #input.103=(1,120,8,32)f32 #1363=(1,120,8,32)f32
prim::Constant           pnnx_1401                0 1 1364 value=1
prim::Constant           pnnx_1404                0 1 1376 value=None
prim::Constant           pnnx_1405                0 1 1377 value=1
prim::Constant           pnnx_1406                0 1 1378 value=0
pnnx.Attribute           effnet._blocks.13._expand_conv 0 1 weight.131 @data=(720,120,1,1)f32 #weight.131=(720,120,1,1)f32
prim::Constant           pnnx_1407                0 1 1381 value=None
prim::Constant           pnnx_1408                0 1 3016 value=1
prim::ListConstruct      pnnx_1409                2 1 1377 3016 1382
prim::Constant           pnnx_1410                0 1 3017 value=0
prim::ListConstruct      pnnx_1411                2 1 1378 3017 1383
prim::Constant           pnnx_1412                0 1 3018 value=1
prim::Constant           pnnx_1413                0 1 3019 value=1
prim::ListConstruct      pnnx_1414                2 1 3018 3019 1384
prim::Constant           pnnx_1418                0 1 3022 value=1
F.conv2d                 F.conv2d_87              7 1 1363 weight.131 1376 1382 1383 1384 3022 input.105 $input=1363 $weight=weight.131 $bias=1376 $stride=1382 $padding=1383 $dilation=1384 $groups=3022 #1363=(1,120,8,32)f32 #weight.131=(720,120,1,1)f32 #input.105=(1,720,8,32)f32
nn.BatchNorm2d           effnet._blocks.13._bn0   1 1 input.105 1387 affine=True eps=1.000000e-03 num_features=720 @bias=(720)f32 @running_mean=(720)f32 @running_var=(720)f32 @weight=(720)f32 #input.105=(1,720,8,32)f32 #1387=(1,720,8,32)f32
nn.SiLU                  effnet._blocks.13._swish 1 1 1387 1388 #1387=(1,720,8,32)f32 #1388=(1,720,8,32)f32
prim::Constant           pnnx_1425                0 1 1391 value=None
prim::Constant           pnnx_1426                0 1 1392 value=1
prim::Constant           pnnx_1427                0 1 1393 value=0
prim::Constant           pnnx_1428                0 1 1394 value=720
pnnx.Attribute           effnet._blocks.13._depthwise_conv 0 1 weight.133 @data=(720,1,5,5)f32 #weight.133=(720,1,5,5)f32
nn.ZeroPad2d             effnet._blocks.13._depthwise_conv.static_padding 1 1 1388 1397 padding=(2,2,2,2) #1388=(1,720,8,32)f32 #1397=(1,720,12,36)f32
prim::Constant           pnnx_1429                0 1 3026 value=1
prim::ListConstruct      pnnx_1430                2 1 1392 3026 1398
prim::Constant           pnnx_1431                0 1 3027 value=0
prim::ListConstruct      pnnx_1432                2 1 1393 3027 1399
prim::Constant           pnnx_1433                0 1 3028 value=1
prim::Constant           pnnx_1434                0 1 3029 value=1
prim::ListConstruct      pnnx_1435                2 1 3028 3029 1400
F.conv2d                 F.conv2d_88              7 1 1397 weight.133 1391 1398 1399 1400 1394 input.107 $input=1397 $weight=weight.133 $bias=1391 $stride=1398 $padding=1399 $dilation=1400 $groups=1394 #1397=(1,720,12,36)f32 #weight.133=(720,1,5,5)f32 #input.107=(1,720,8,32)f32
nn.BatchNorm2d           effnet._blocks.13._bn1   1 1 input.107 1403 affine=True eps=1.000000e-03 num_features=720 @bias=(720)f32 @running_mean=(720)f32 @running_var=(720)f32 @weight=(720)f32 #input.107=(1,720,8,32)f32 #1403=(1,720,8,32)f32
nn.SiLU                  effnet._blocks.13._swish 1 1 1403 1404 #1403=(1,720,8,32)f32 #1404=(1,720,8,32)f32
prim::Constant           pnnx_1443                0 1 3035 value=1
prim::ListConstruct      pnnx_1444                2 1 1364 3035 1405
prim::Constant           pnnx_1448                0 1 1409 value=1
prim::Constant           pnnx_1449                0 1 1410 value=0
pnnx.Attribute           effnet._blocks.13._se_reduce 0 1 bias.55 @data=(30)f32 #bias.55=(30)f32
pnnx.Attribute           effnet._blocks.13._se_reduce 0 1 weight.135 @data=(30,720,1,1)f32 #weight.135=(30,720,1,1)f32
prim::Constant           pnnx_1450                0 1 1414 value=None
prim::Constant           pnnx_1451                0 1 3036 value=1
prim::ListConstruct      pnnx_1452                2 1 1409 3036 1415
prim::Constant           pnnx_1453                0 1 3037 value=0
prim::ListConstruct      pnnx_1454                2 1 1410 3037 1416
prim::Constant           pnnx_1455                0 1 3038 value=1
prim::Constant           pnnx_1456                0 1 3039 value=1
prim::ListConstruct      pnnx_1457                2 1 3038 3039 1417
prim::Constant           pnnx_1461                0 1 3042 value=1
F.adaptive_avg_pool2d    F.adaptive_avg_pool2d_13 2 1 1404 1405 x.31 $input=1404 $output_size=1405 #1404=(1,720,8,32)f32 #x.31=(1,720,1,1)f32
F.conv2d                 F.conv2d_89              7 1 x.31 weight.135 bias.55 1415 1416 1417 3042 input.109 $input=x.31 $weight=weight.135 $bias=bias.55 $stride=1415 $padding=1416 $dilation=1417 $groups=3042 #x.31=(1,720,1,1)f32 #weight.135=(30,720,1,1)f32 #bias.55=(30)f32 #input.109=(1,30,1,1)f32
nn.SiLU                  effnet._blocks.13._swish 1 1 input.109 1420 #input.109=(1,30,1,1)f32 #1420=(1,30,1,1)f32
prim::Constant           pnnx_1468                0 1 1423 value=1
prim::Constant           pnnx_1469                0 1 1424 value=0
pnnx.Attribute           effnet._blocks.13._se_expand 0 1 bias.57 @data=(720)f32 #bias.57=(720)f32
pnnx.Attribute           effnet._blocks.13._se_expand 0 1 weight.137 @data=(720,30,1,1)f32 #weight.137=(720,30,1,1)f32
prim::Constant           pnnx_1470                0 1 1428 value=None
prim::Constant           pnnx_1471                0 1 3046 value=1
prim::ListConstruct      pnnx_1472                2 1 1423 3046 1429
prim::Constant           pnnx_1473                0 1 3047 value=0
prim::ListConstruct      pnnx_1474                2 1 1424 3047 1430
prim::Constant           pnnx_1475                0 1 3048 value=1
prim::Constant           pnnx_1476                0 1 3049 value=1
prim::ListConstruct      pnnx_1477                2 1 3048 3049 1431
prim::Constant           pnnx_1481                0 1 3052 value=1
F.conv2d                 F.conv2d_90              7 1 1420 weight.137 bias.57 1429 1430 1431 3052 x_squeezed.28 $input=1420 $weight=weight.137 $bias=bias.57 $stride=1429 $padding=1430 $dilation=1431 $groups=3052 #1420=(1,30,1,1)f32 #weight.137=(720,30,1,1)f32 #bias.57=(720)f32 #x_squeezed.28=(1,720,1,1)f32
F.sigmoid                F.sigmoid_151            1 1 x_squeezed.28 1434 $input=x_squeezed.28 #x_squeezed.28=(1,720,1,1)f32 #1434=(1,720,1,1)f32
aten::mul                pnnx_1487                2 1 1434 1404 x0.28 #1434=(1,720,1,1)f32 #1404=(1,720,8,32)f32 #x0.28=(1,720,8,32)f32
prim::Constant           pnnx_1490                0 1 1438 value=None
prim::Constant           pnnx_1491                0 1 1439 value=1
prim::Constant           pnnx_1492                0 1 1440 value=0
pnnx.Attribute           effnet._blocks.13._project_conv 0 1 weight.139 @data=(120,720,1,1)f32 #weight.139=(120,720,1,1)f32
prim::Constant           pnnx_1493                0 1 1443 value=None
prim::Constant           pnnx_1494                0 1 3056 value=1
prim::ListConstruct      pnnx_1495                2 1 1439 3056 1444
prim::Constant           pnnx_1496                0 1 3057 value=0
prim::ListConstruct      pnnx_1497                2 1 1440 3057 1445
prim::Constant           pnnx_1498                0 1 3058 value=1
prim::Constant           pnnx_1499                0 1 3059 value=1
prim::ListConstruct      pnnx_1500                2 1 3058 3059 1446
prim::Constant           pnnx_1504                0 1 3062 value=1
F.conv2d                 F.conv2d_91              7 1 x0.28 weight.139 1438 1444 1445 1446 3062 input.111 $input=x0.28 $weight=weight.139 $bias=1438 $stride=1444 $padding=1445 $dilation=1446 $groups=3062 #x0.28=(1,720,8,32)f32 #weight.139=(120,720,1,1)f32 #input.111=(1,120,8,32)f32
nn.BatchNorm2d           effnet._blocks.13._bn2   1 1 input.111 1449 affine=True eps=1.000000e-03 num_features=120 @bias=(120)f32 @running_mean=(120)f32 @running_var=(120)f32 @weight=(120)f32 #input.111=(1,120,8,32)f32 #1449=(1,120,8,32)f32
prim::Constant           pnnx_1509                0 1 3066 value=1
aten::add                pnnx_1510                3 1 1449 1363 3066 1450 #1449=(1,120,8,32)f32 #1363=(1,120,8,32)f32 #1450=(1,120,8,32)f32
prim::Constant           pnnx_1511                0 1 1451 value=1
prim::Constant           pnnx_1514                0 1 1463 value=None
prim::Constant           pnnx_1515                0 1 1464 value=1
prim::Constant           pnnx_1516                0 1 1465 value=0
pnnx.Attribute           effnet._blocks.14._expand_conv 0 1 weight.141 @data=(720,120,1,1)f32 #weight.141=(720,120,1,1)f32
prim::Constant           pnnx_1517                0 1 1468 value=None
prim::Constant           pnnx_1518                0 1 3067 value=1
prim::ListConstruct      pnnx_1519                2 1 1464 3067 1469
prim::Constant           pnnx_1520                0 1 3068 value=0
prim::ListConstruct      pnnx_1521                2 1 1465 3068 1470
prim::Constant           pnnx_1522                0 1 3069 value=1
prim::Constant           pnnx_1523                0 1 3070 value=1
prim::ListConstruct      pnnx_1524                2 1 3069 3070 1471
prim::Constant           pnnx_1528                0 1 3073 value=1
F.conv2d                 F.conv2d_92              7 1 1450 weight.141 1463 1469 1470 1471 3073 input.113 $input=1450 $weight=weight.141 $bias=1463 $stride=1469 $padding=1470 $dilation=1471 $groups=3073 #1450=(1,120,8,32)f32 #weight.141=(720,120,1,1)f32 #input.113=(1,720,8,32)f32
nn.BatchNorm2d           effnet._blocks.14._bn0   1 1 input.113 1474 affine=True eps=1.000000e-03 num_features=720 @bias=(720)f32 @running_mean=(720)f32 @running_var=(720)f32 @weight=(720)f32 #input.113=(1,720,8,32)f32 #1474=(1,720,8,32)f32
nn.SiLU                  effnet._blocks.14._swish 1 1 1474 1475 #1474=(1,720,8,32)f32 #1475=(1,720,8,32)f32
prim::Constant           pnnx_1535                0 1 1478 value=None
prim::Constant           pnnx_1536                0 1 1479 value=1
prim::Constant           pnnx_1537                0 1 1480 value=0
prim::Constant           pnnx_1538                0 1 1481 value=720
pnnx.Attribute           effnet._blocks.14._depthwise_conv 0 1 weight.143 @data=(720,1,5,5)f32 #weight.143=(720,1,5,5)f32
nn.ZeroPad2d             effnet._blocks.14._depthwise_conv.static_padding 1 1 1475 1484 padding=(2,2,2,2) #1475=(1,720,8,32)f32 #1484=(1,720,12,36)f32
prim::Constant           pnnx_1539                0 1 3077 value=1
prim::ListConstruct      pnnx_1540                2 1 1479 3077 1485
prim::Constant           pnnx_1541                0 1 3078 value=0
prim::ListConstruct      pnnx_1542                2 1 1480 3078 1486
prim::Constant           pnnx_1543                0 1 3079 value=1
prim::Constant           pnnx_1544                0 1 3080 value=1
prim::ListConstruct      pnnx_1545                2 1 3079 3080 1487
F.conv2d                 F.conv2d_93              7 1 1484 weight.143 1478 1485 1486 1487 1481 input.115 $input=1484 $weight=weight.143 $bias=1478 $stride=1485 $padding=1486 $dilation=1487 $groups=1481 #1484=(1,720,12,36)f32 #weight.143=(720,1,5,5)f32 #input.115=(1,720,8,32)f32
nn.BatchNorm2d           effnet._blocks.14._bn1   1 1 input.115 1490 affine=True eps=1.000000e-03 num_features=720 @bias=(720)f32 @running_mean=(720)f32 @running_var=(720)f32 @weight=(720)f32 #input.115=(1,720,8,32)f32 #1490=(1,720,8,32)f32
nn.SiLU                  effnet._blocks.14._swish 1 1 1490 1491 #1490=(1,720,8,32)f32 #1491=(1,720,8,32)f32
prim::Constant           pnnx_1553                0 1 3086 value=1
prim::ListConstruct      pnnx_1554                2 1 1451 3086 1492
prim::Constant           pnnx_1558                0 1 1496 value=1
prim::Constant           pnnx_1559                0 1 1497 value=0
pnnx.Attribute           effnet._blocks.14._se_reduce 0 1 bias.59 @data=(30)f32 #bias.59=(30)f32
pnnx.Attribute           effnet._blocks.14._se_reduce 0 1 weight.145 @data=(30,720,1,1)f32 #weight.145=(30,720,1,1)f32
prim::Constant           pnnx_1560                0 1 1501 value=None
prim::Constant           pnnx_1561                0 1 3087 value=1
prim::ListConstruct      pnnx_1562                2 1 1496 3087 1502
prim::Constant           pnnx_1563                0 1 3088 value=0
prim::ListConstruct      pnnx_1564                2 1 1497 3088 1503
prim::Constant           pnnx_1565                0 1 3089 value=1
prim::Constant           pnnx_1566                0 1 3090 value=1
prim::ListConstruct      pnnx_1567                2 1 3089 3090 1504
prim::Constant           pnnx_1571                0 1 3093 value=1
F.adaptive_avg_pool2d    F.adaptive_avg_pool2d_14 2 1 1491 1492 x.33 $input=1491 $output_size=1492 #1491=(1,720,8,32)f32 #x.33=(1,720,1,1)f32
F.conv2d                 F.conv2d_94              7 1 x.33 weight.145 bias.59 1502 1503 1504 3093 input.117 $input=x.33 $weight=weight.145 $bias=bias.59 $stride=1502 $padding=1503 $dilation=1504 $groups=3093 #x.33=(1,720,1,1)f32 #weight.145=(30,720,1,1)f32 #bias.59=(30)f32 #input.117=(1,30,1,1)f32
nn.SiLU                  effnet._blocks.14._swish 1 1 input.117 1507 #input.117=(1,30,1,1)f32 #1507=(1,30,1,1)f32
prim::Constant           pnnx_1578                0 1 1510 value=1
prim::Constant           pnnx_1579                0 1 1511 value=0
pnnx.Attribute           effnet._blocks.14._se_expand 0 1 bias.61 @data=(720)f32 #bias.61=(720)f32
pnnx.Attribute           effnet._blocks.14._se_expand 0 1 weight.147 @data=(720,30,1,1)f32 #weight.147=(720,30,1,1)f32
prim::Constant           pnnx_1580                0 1 1515 value=None
prim::Constant           pnnx_1581                0 1 3097 value=1
prim::ListConstruct      pnnx_1582                2 1 1510 3097 1516
prim::Constant           pnnx_1583                0 1 3098 value=0
prim::ListConstruct      pnnx_1584                2 1 1511 3098 1517
prim::Constant           pnnx_1585                0 1 3099 value=1
prim::Constant           pnnx_1586                0 1 3100 value=1
prim::ListConstruct      pnnx_1587                2 1 3099 3100 1518
prim::Constant           pnnx_1591                0 1 3103 value=1
F.conv2d                 F.conv2d_95              7 1 1507 weight.147 bias.61 1516 1517 1518 3103 x_squeezed.30 $input=1507 $weight=weight.147 $bias=bias.61 $stride=1516 $padding=1517 $dilation=1518 $groups=3103 #1507=(1,30,1,1)f32 #weight.147=(720,30,1,1)f32 #bias.61=(720)f32 #x_squeezed.30=(1,720,1,1)f32
F.sigmoid                F.sigmoid_152            1 1 x_squeezed.30 1521 $input=x_squeezed.30 #x_squeezed.30=(1,720,1,1)f32 #1521=(1,720,1,1)f32
aten::mul                pnnx_1597                2 1 1521 1491 x0.30 #1521=(1,720,1,1)f32 #1491=(1,720,8,32)f32 #x0.30=(1,720,8,32)f32
prim::Constant           pnnx_1600                0 1 1525 value=None
prim::Constant           pnnx_1601                0 1 1526 value=1
prim::Constant           pnnx_1602                0 1 1527 value=0
pnnx.Attribute           effnet._blocks.14._project_conv 0 1 weight.149 @data=(120,720,1,1)f32 #weight.149=(120,720,1,1)f32
prim::Constant           pnnx_1603                0 1 1530 value=None
prim::Constant           pnnx_1604                0 1 3107 value=1
prim::ListConstruct      pnnx_1605                2 1 1526 3107 1531
prim::Constant           pnnx_1606                0 1 3108 value=0
prim::ListConstruct      pnnx_1607                2 1 1527 3108 1532
prim::Constant           pnnx_1608                0 1 3109 value=1
prim::Constant           pnnx_1609                0 1 3110 value=1
prim::ListConstruct      pnnx_1610                2 1 3109 3110 1533
prim::Constant           pnnx_1614                0 1 3113 value=1
F.conv2d                 F.conv2d_96              7 1 x0.30 weight.149 1525 1531 1532 1533 3113 input.119 $input=x0.30 $weight=weight.149 $bias=1525 $stride=1531 $padding=1532 $dilation=1533 $groups=3113 #x0.30=(1,720,8,32)f32 #weight.149=(120,720,1,1)f32 #input.119=(1,120,8,32)f32
nn.BatchNorm2d           effnet._blocks.14._bn2   1 1 input.119 1536 affine=True eps=1.000000e-03 num_features=120 @bias=(120)f32 @running_mean=(120)f32 @running_var=(120)f32 @weight=(120)f32 #input.119=(1,120,8,32)f32 #1536=(1,120,8,32)f32
prim::Constant           pnnx_1619                0 1 3117 value=1
aten::add                pnnx_1620                3 1 1536 1450 3117 1537 #1536=(1,120,8,32)f32 #1450=(1,120,8,32)f32 #1537=(1,120,8,32)f32
prim::Constant           pnnx_1621                0 1 1538 value=1
prim::Constant           pnnx_1624                0 1 1550 value=None
prim::Constant           pnnx_1625                0 1 1551 value=1
prim::Constant           pnnx_1626                0 1 1552 value=0
pnnx.Attribute           effnet._blocks.15._expand_conv 0 1 weight.151 @data=(720,120,1,1)f32 #weight.151=(720,120,1,1)f32
prim::Constant           pnnx_1627                0 1 1555 value=None
prim::Constant           pnnx_1628                0 1 3118 value=1
prim::ListConstruct      pnnx_1629                2 1 1551 3118 1556
prim::Constant           pnnx_1630                0 1 3119 value=0
prim::ListConstruct      pnnx_1631                2 1 1552 3119 1557
prim::Constant           pnnx_1632                0 1 3120 value=1
prim::Constant           pnnx_1633                0 1 3121 value=1
prim::ListConstruct      pnnx_1634                2 1 3120 3121 1558
prim::Constant           pnnx_1638                0 1 3124 value=1
F.conv2d                 F.conv2d_97              7 1 1537 weight.151 1550 1556 1557 1558 3124 input.121 $input=1537 $weight=weight.151 $bias=1550 $stride=1556 $padding=1557 $dilation=1558 $groups=3124 #1537=(1,120,8,32)f32 #weight.151=(720,120,1,1)f32 #input.121=(1,720,8,32)f32
nn.BatchNorm2d           effnet._blocks.15._bn0   1 1 input.121 1561 affine=True eps=1.000000e-03 num_features=720 @bias=(720)f32 @running_mean=(720)f32 @running_var=(720)f32 @weight=(720)f32 #input.121=(1,720,8,32)f32 #1561=(1,720,8,32)f32
nn.SiLU                  effnet._blocks.15._swish 1 1 1561 1562 #1561=(1,720,8,32)f32 #1562=(1,720,8,32)f32
prim::Constant           pnnx_1645                0 1 1565 value=None
prim::Constant           pnnx_1646                0 1 1566 value=1
prim::Constant           pnnx_1647                0 1 1567 value=0
prim::Constant           pnnx_1648                0 1 1568 value=720
pnnx.Attribute           effnet._blocks.15._depthwise_conv 0 1 weight.153 @data=(720,1,5,5)f32 #weight.153=(720,1,5,5)f32
nn.ZeroPad2d             effnet._blocks.15._depthwise_conv.static_padding 1 1 1562 1571 padding=(2,2,2,2) #1562=(1,720,8,32)f32 #1571=(1,720,12,36)f32
prim::Constant           pnnx_1649                0 1 3128 value=1
prim::ListConstruct      pnnx_1650                2 1 1566 3128 1572
prim::Constant           pnnx_1651                0 1 3129 value=0
prim::ListConstruct      pnnx_1652                2 1 1567 3129 1573
prim::Constant           pnnx_1653                0 1 3130 value=1
prim::Constant           pnnx_1654                0 1 3131 value=1
prim::ListConstruct      pnnx_1655                2 1 3130 3131 1574
F.conv2d                 F.conv2d_98              7 1 1571 weight.153 1565 1572 1573 1574 1568 input.123 $input=1571 $weight=weight.153 $bias=1565 $stride=1572 $padding=1573 $dilation=1574 $groups=1568 #1571=(1,720,12,36)f32 #weight.153=(720,1,5,5)f32 #input.123=(1,720,8,32)f32
nn.BatchNorm2d           effnet._blocks.15._bn1   1 1 input.123 1577 affine=True eps=1.000000e-03 num_features=720 @bias=(720)f32 @running_mean=(720)f32 @running_var=(720)f32 @weight=(720)f32 #input.123=(1,720,8,32)f32 #1577=(1,720,8,32)f32
nn.SiLU                  effnet._blocks.15._swish 1 1 1577 1578 #1577=(1,720,8,32)f32 #1578=(1,720,8,32)f32
prim::Constant           pnnx_1663                0 1 3137 value=1
prim::ListConstruct      pnnx_1664                2 1 1538 3137 1579
prim::Constant           pnnx_1668                0 1 1583 value=1
prim::Constant           pnnx_1669                0 1 1584 value=0
pnnx.Attribute           effnet._blocks.15._se_reduce 0 1 bias.63 @data=(30)f32 #bias.63=(30)f32
pnnx.Attribute           effnet._blocks.15._se_reduce 0 1 weight.155 @data=(30,720,1,1)f32 #weight.155=(30,720,1,1)f32
prim::Constant           pnnx_1670                0 1 1588 value=None
prim::Constant           pnnx_1671                0 1 3138 value=1
prim::ListConstruct      pnnx_1672                2 1 1583 3138 1589
prim::Constant           pnnx_1673                0 1 3139 value=0
prim::ListConstruct      pnnx_1674                2 1 1584 3139 1590
prim::Constant           pnnx_1675                0 1 3140 value=1
prim::Constant           pnnx_1676                0 1 3141 value=1
prim::ListConstruct      pnnx_1677                2 1 3140 3141 1591
prim::Constant           pnnx_1681                0 1 3144 value=1
F.adaptive_avg_pool2d    F.adaptive_avg_pool2d_15 2 1 1578 1579 x.35 $input=1578 $output_size=1579 #1578=(1,720,8,32)f32 #x.35=(1,720,1,1)f32
F.conv2d                 F.conv2d_99              7 1 x.35 weight.155 bias.63 1589 1590 1591 3144 input.125 $input=x.35 $weight=weight.155 $bias=bias.63 $stride=1589 $padding=1590 $dilation=1591 $groups=3144 #x.35=(1,720,1,1)f32 #weight.155=(30,720,1,1)f32 #bias.63=(30)f32 #input.125=(1,30,1,1)f32
nn.SiLU                  effnet._blocks.15._swish 1 1 input.125 1594 #input.125=(1,30,1,1)f32 #1594=(1,30,1,1)f32
prim::Constant           pnnx_1688                0 1 1597 value=1
prim::Constant           pnnx_1689                0 1 1598 value=0
pnnx.Attribute           effnet._blocks.15._se_expand 0 1 bias.65 @data=(720)f32 #bias.65=(720)f32
pnnx.Attribute           effnet._blocks.15._se_expand 0 1 weight.157 @data=(720,30,1,1)f32 #weight.157=(720,30,1,1)f32
prim::Constant           pnnx_1690                0 1 1602 value=None
prim::Constant           pnnx_1691                0 1 3148 value=1
prim::ListConstruct      pnnx_1692                2 1 1597 3148 1603
prim::Constant           pnnx_1693                0 1 3149 value=0
prim::ListConstruct      pnnx_1694                2 1 1598 3149 1604
prim::Constant           pnnx_1695                0 1 3150 value=1
prim::Constant           pnnx_1696                0 1 3151 value=1
prim::ListConstruct      pnnx_1697                2 1 3150 3151 1605
prim::Constant           pnnx_1701                0 1 3154 value=1
F.conv2d                 F.conv2d_100             7 1 1594 weight.157 bias.65 1603 1604 1605 3154 x_squeezed.32 $input=1594 $weight=weight.157 $bias=bias.65 $stride=1603 $padding=1604 $dilation=1605 $groups=3154 #1594=(1,30,1,1)f32 #weight.157=(720,30,1,1)f32 #bias.65=(720)f32 #x_squeezed.32=(1,720,1,1)f32
F.sigmoid                F.sigmoid_153            1 1 x_squeezed.32 1608 $input=x_squeezed.32 #x_squeezed.32=(1,720,1,1)f32 #1608=(1,720,1,1)f32
aten::mul                pnnx_1707                2 1 1608 1578 x0.32 #1608=(1,720,1,1)f32 #1578=(1,720,8,32)f32 #x0.32=(1,720,8,32)f32
prim::Constant           pnnx_1710                0 1 1612 value=None
prim::Constant           pnnx_1711                0 1 1613 value=1
prim::Constant           pnnx_1712                0 1 1614 value=0
pnnx.Attribute           effnet._blocks.15._project_conv 0 1 weight.159 @data=(120,720,1,1)f32 #weight.159=(120,720,1,1)f32
prim::Constant           pnnx_1713                0 1 1617 value=None
prim::Constant           pnnx_1714                0 1 3158 value=1
prim::ListConstruct      pnnx_1715                2 1 1613 3158 1618
prim::Constant           pnnx_1716                0 1 3159 value=0
prim::ListConstruct      pnnx_1717                2 1 1614 3159 1619
prim::Constant           pnnx_1718                0 1 3160 value=1
prim::Constant           pnnx_1719                0 1 3161 value=1
prim::ListConstruct      pnnx_1720                2 1 3160 3161 1620
prim::Constant           pnnx_1724                0 1 3164 value=1
F.conv2d                 F.conv2d_101             7 1 x0.32 weight.159 1612 1618 1619 1620 3164 input.127 $input=x0.32 $weight=weight.159 $bias=1612 $stride=1618 $padding=1619 $dilation=1620 $groups=3164 #x0.32=(1,720,8,32)f32 #weight.159=(120,720,1,1)f32 #input.127=(1,120,8,32)f32
nn.BatchNorm2d           effnet._blocks.15._bn2   1 1 input.127 1623 affine=True eps=1.000000e-03 num_features=120 @bias=(120)f32 @running_mean=(120)f32 @running_var=(120)f32 @weight=(120)f32 #input.127=(1,120,8,32)f32 #1623=(1,120,8,32)f32
prim::Constant           pnnx_1729                0 1 3168 value=1
aten::add                pnnx_1730                3 1 1623 1537 3168 1624 #1623=(1,120,8,32)f32 #1537=(1,120,8,32)f32 #1624=(1,120,8,32)f32
prim::Constant           pnnx_1731                0 1 1625 value=1
prim::Constant           pnnx_1734                0 1 1637 value=None
prim::Constant           pnnx_1735                0 1 1638 value=1
prim::Constant           pnnx_1736                0 1 1639 value=0
pnnx.Attribute           effnet._blocks.16._expand_conv 0 1 weight.161 @data=(720,120,1,1)f32 #weight.161=(720,120,1,1)f32
prim::Constant           pnnx_1737                0 1 1642 value=None
prim::Constant           pnnx_1738                0 1 3169 value=1
prim::ListConstruct      pnnx_1739                2 1 1638 3169 1643
prim::Constant           pnnx_1740                0 1 3170 value=0
prim::ListConstruct      pnnx_1741                2 1 1639 3170 1644
prim::Constant           pnnx_1742                0 1 3171 value=1
prim::Constant           pnnx_1743                0 1 3172 value=1
prim::ListConstruct      pnnx_1744                2 1 3171 3172 1645
prim::Constant           pnnx_1748                0 1 3175 value=1
F.conv2d                 F.conv2d_102             7 1 1624 weight.161 1637 1643 1644 1645 3175 input.129 $input=1624 $weight=weight.161 $bias=1637 $stride=1643 $padding=1644 $dilation=1645 $groups=3175 #1624=(1,120,8,32)f32 #weight.161=(720,120,1,1)f32 #input.129=(1,720,8,32)f32
nn.BatchNorm2d           effnet._blocks.16._bn0   1 1 input.129 1648 affine=True eps=1.000000e-03 num_features=720 @bias=(720)f32 @running_mean=(720)f32 @running_var=(720)f32 @weight=(720)f32 #input.129=(1,720,8,32)f32 #1648=(1,720,8,32)f32
nn.SiLU                  effnet._blocks.16._swish 1 1 1648 1649 #1648=(1,720,8,32)f32 #1649=(1,720,8,32)f32
prim::Constant           pnnx_1755                0 1 1652 value=None
prim::Constant           pnnx_1756                0 1 1653 value=2
prim::Constant           pnnx_1757                0 1 1654 value=0
prim::Constant           pnnx_1758                0 1 1655 value=1
prim::Constant           pnnx_1759                0 1 1656 value=720
pnnx.Attribute           effnet._blocks.16._depthwise_conv 0 1 weight.163 @data=(720,1,5,5)f32 #weight.163=(720,1,5,5)f32
nn.ZeroPad2d             effnet._blocks.16._depthwise_conv.static_padding 1 1 1649 1659 padding=(2,2,2,2) #1649=(1,720,8,32)f32 #1659=(1,720,12,36)f32
prim::Constant           pnnx_1760                0 1 3179 value=2
prim::ListConstruct      pnnx_1761                2 1 1653 3179 1660
prim::Constant           pnnx_1762                0 1 3180 value=0
prim::ListConstruct      pnnx_1763                2 1 1654 3180 1661
prim::Constant           pnnx_1764                0 1 3181 value=1
prim::ListConstruct      pnnx_1765                2 1 1655 3181 1662
F.conv2d                 F.conv2d_103             7 1 1659 weight.163 1652 1660 1661 1662 1656 input.131 $input=1659 $weight=weight.163 $bias=1652 $stride=1660 $padding=1661 $dilation=1662 $groups=1656 #1659=(1,720,12,36)f32 #weight.163=(720,1,5,5)f32 #input.131=(1,720,4,16)f32
nn.BatchNorm2d           effnet._blocks.16._bn1   1 1 input.131 1665 affine=True eps=1.000000e-03 num_features=720 @bias=(720)f32 @running_mean=(720)f32 @running_var=(720)f32 @weight=(720)f32 #input.131=(1,720,4,16)f32 #1665=(1,720,4,16)f32
nn.SiLU                  effnet._blocks.16._swish 1 1 1665 1666 #1665=(1,720,4,16)f32 #1666=(1,720,4,16)f32
prim::Constant           pnnx_1773                0 1 3187 value=1
prim::ListConstruct      pnnx_1774                2 1 1625 3187 1667
prim::Constant           pnnx_1778                0 1 1671 value=1
prim::Constant           pnnx_1779                0 1 1672 value=0
pnnx.Attribute           effnet._blocks.16._se_reduce 0 1 bias.67 @data=(30)f32 #bias.67=(30)f32
pnnx.Attribute           effnet._blocks.16._se_reduce 0 1 weight.165 @data=(30,720,1,1)f32 #weight.165=(30,720,1,1)f32
prim::Constant           pnnx_1780                0 1 1676 value=None
prim::Constant           pnnx_1781                0 1 3188 value=1
prim::ListConstruct      pnnx_1782                2 1 1671 3188 1677
prim::Constant           pnnx_1783                0 1 3189 value=0
prim::ListConstruct      pnnx_1784                2 1 1672 3189 1678
prim::Constant           pnnx_1785                0 1 3190 value=1
prim::Constant           pnnx_1786                0 1 3191 value=1
prim::ListConstruct      pnnx_1787                2 1 3190 3191 1679
prim::Constant           pnnx_1791                0 1 3194 value=1
F.adaptive_avg_pool2d    F.adaptive_avg_pool2d_16 2 1 1666 1667 x.37 $input=1666 $output_size=1667 #1666=(1,720,4,16)f32 #x.37=(1,720,1,1)f32
F.conv2d                 F.conv2d_104             7 1 x.37 weight.165 bias.67 1677 1678 1679 3194 input.133 $input=x.37 $weight=weight.165 $bias=bias.67 $stride=1677 $padding=1678 $dilation=1679 $groups=3194 #x.37=(1,720,1,1)f32 #weight.165=(30,720,1,1)f32 #bias.67=(30)f32 #input.133=(1,30,1,1)f32
nn.SiLU                  effnet._blocks.16._swish 1 1 input.133 1682 #input.133=(1,30,1,1)f32 #1682=(1,30,1,1)f32
prim::Constant           pnnx_1798                0 1 1685 value=1
prim::Constant           pnnx_1799                0 1 1686 value=0
pnnx.Attribute           effnet._blocks.16._se_expand 0 1 bias.69 @data=(720)f32 #bias.69=(720)f32
pnnx.Attribute           effnet._blocks.16._se_expand 0 1 weight.167 @data=(720,30,1,1)f32 #weight.167=(720,30,1,1)f32
prim::Constant           pnnx_1800                0 1 1690 value=None
prim::Constant           pnnx_1801                0 1 3198 value=1
prim::ListConstruct      pnnx_1802                2 1 1685 3198 1691
prim::Constant           pnnx_1803                0 1 3199 value=0
prim::ListConstruct      pnnx_1804                2 1 1686 3199 1692
prim::Constant           pnnx_1805                0 1 3200 value=1
prim::Constant           pnnx_1806                0 1 3201 value=1
prim::ListConstruct      pnnx_1807                2 1 3200 3201 1693
prim::Constant           pnnx_1811                0 1 3204 value=1
F.conv2d                 F.conv2d_105             7 1 1682 weight.167 bias.69 1691 1692 1693 3204 x_squeezed.34 $input=1682 $weight=weight.167 $bias=bias.69 $stride=1691 $padding=1692 $dilation=1693 $groups=3204 #1682=(1,30,1,1)f32 #weight.167=(720,30,1,1)f32 #bias.69=(720)f32 #x_squeezed.34=(1,720,1,1)f32
F.sigmoid                F.sigmoid_154            1 1 x_squeezed.34 1696 $input=x_squeezed.34 #x_squeezed.34=(1,720,1,1)f32 #1696=(1,720,1,1)f32
aten::mul                pnnx_1817                2 1 1696 1666 x0.34 #1696=(1,720,1,1)f32 #1666=(1,720,4,16)f32 #x0.34=(1,720,4,16)f32
prim::Constant           pnnx_1820                0 1 1700 value=None
prim::Constant           pnnx_1821                0 1 1701 value=1
prim::Constant           pnnx_1822                0 1 1702 value=0
pnnx.Attribute           effnet._blocks.16._project_conv 0 1 weight.169 @data=(208,720,1,1)f32 #weight.169=(208,720,1,1)f32
prim::Constant           pnnx_1823                0 1 1705 value=None
prim::Constant           pnnx_1824                0 1 3208 value=1
prim::ListConstruct      pnnx_1825                2 1 1701 3208 1706
prim::Constant           pnnx_1826                0 1 3209 value=0
prim::ListConstruct      pnnx_1827                2 1 1702 3209 1707
prim::Constant           pnnx_1828                0 1 3210 value=1
prim::Constant           pnnx_1829                0 1 3211 value=1
prim::ListConstruct      pnnx_1830                2 1 3210 3211 1708
prim::Constant           pnnx_1834                0 1 3214 value=1
F.conv2d                 F.conv2d_106             7 1 x0.34 weight.169 1700 1706 1707 1708 3214 input.135 $input=x0.34 $weight=weight.169 $bias=1700 $stride=1706 $padding=1707 $dilation=1708 $groups=3214 #x0.34=(1,720,4,16)f32 #weight.169=(208,720,1,1)f32 #input.135=(1,208,4,16)f32
nn.BatchNorm2d           effnet._blocks.16._bn2   1 1 input.135 1711 affine=True eps=1.000000e-03 num_features=208 @bias=(208)f32 @running_mean=(208)f32 @running_var=(208)f32 @weight=(208)f32 #input.135=(1,208,4,16)f32 #1711=(1,208,4,16)f32
prim::Constant           pnnx_1839                0 1 1712 value=1
prim::Constant           pnnx_1842                0 1 1724 value=None
prim::Constant           pnnx_1843                0 1 1725 value=1
prim::Constant           pnnx_1844                0 1 1726 value=0
pnnx.Attribute           effnet._blocks.17._expand_conv 0 1 weight.171 @data=(1248,208,1,1)f32 #weight.171=(1248,208,1,1)f32
prim::Constant           pnnx_1845                0 1 1729 value=None
prim::Constant           pnnx_1846                0 1 3218 value=1
prim::ListConstruct      pnnx_1847                2 1 1725 3218 1730
prim::Constant           pnnx_1848                0 1 3219 value=0
prim::ListConstruct      pnnx_1849                2 1 1726 3219 1731
prim::Constant           pnnx_1850                0 1 3220 value=1
prim::Constant           pnnx_1851                0 1 3221 value=1
prim::ListConstruct      pnnx_1852                2 1 3220 3221 1732
prim::Constant           pnnx_1856                0 1 3224 value=1
F.conv2d                 F.conv2d_107             7 1 1711 weight.171 1724 1730 1731 1732 3224 input.137 $input=1711 $weight=weight.171 $bias=1724 $stride=1730 $padding=1731 $dilation=1732 $groups=3224 #1711=(1,208,4,16)f32 #weight.171=(1248,208,1,1)f32 #input.137=(1,1248,4,16)f32
nn.BatchNorm2d           effnet._blocks.17._bn0   1 1 input.137 1735 affine=True eps=1.000000e-03 num_features=1248 @bias=(1248)f32 @running_mean=(1248)f32 @running_var=(1248)f32 @weight=(1248)f32 #input.137=(1,1248,4,16)f32 #1735=(1,1248,4,16)f32
nn.SiLU                  effnet._blocks.17._swish 1 1 1735 1736 #1735=(1,1248,4,16)f32 #1736=(1,1248,4,16)f32
prim::Constant           pnnx_1863                0 1 1739 value=None
prim::Constant           pnnx_1864                0 1 1740 value=1
prim::Constant           pnnx_1865                0 1 1741 value=0
prim::Constant           pnnx_1866                0 1 1742 value=1248
pnnx.Attribute           effnet._blocks.17._depthwise_conv 0 1 weight.173 @data=(1248,1,5,5)f32 #weight.173=(1248,1,5,5)f32
nn.ZeroPad2d             effnet._blocks.17._depthwise_conv.static_padding 1 1 1736 1745 padding=(2,2,2,2) #1736=(1,1248,4,16)f32 #1745=(1,1248,8,20)f32
prim::Constant           pnnx_1867                0 1 3228 value=1
prim::ListConstruct      pnnx_1868                2 1 1740 3228 1746
prim::Constant           pnnx_1869                0 1 3229 value=0
prim::ListConstruct      pnnx_1870                2 1 1741 3229 1747
prim::Constant           pnnx_1871                0 1 3230 value=1
prim::Constant           pnnx_1872                0 1 3231 value=1
prim::ListConstruct      pnnx_1873                2 1 3230 3231 1748
F.conv2d                 F.conv2d_108             7 1 1745 weight.173 1739 1746 1747 1748 1742 input.139 $input=1745 $weight=weight.173 $bias=1739 $stride=1746 $padding=1747 $dilation=1748 $groups=1742 #1745=(1,1248,8,20)f32 #weight.173=(1248,1,5,5)f32 #input.139=(1,1248,4,16)f32
nn.BatchNorm2d           effnet._blocks.17._bn1   1 1 input.139 1751 affine=True eps=1.000000e-03 num_features=1248 @bias=(1248)f32 @running_mean=(1248)f32 @running_var=(1248)f32 @weight=(1248)f32 #input.139=(1,1248,4,16)f32 #1751=(1,1248,4,16)f32
nn.SiLU                  effnet._blocks.17._swish 1 1 1751 1752 #1751=(1,1248,4,16)f32 #1752=(1,1248,4,16)f32
prim::Constant           pnnx_1881                0 1 3237 value=1
prim::ListConstruct      pnnx_1882                2 1 1712 3237 1753
prim::Constant           pnnx_1886                0 1 1757 value=1
prim::Constant           pnnx_1887                0 1 1758 value=0
pnnx.Attribute           effnet._blocks.17._se_reduce 0 1 bias.71 @data=(52)f32 #bias.71=(52)f32
pnnx.Attribute           effnet._blocks.17._se_reduce 0 1 weight.175 @data=(52,1248,1,1)f32 #weight.175=(52,1248,1,1)f32
prim::Constant           pnnx_1888                0 1 1762 value=None
prim::Constant           pnnx_1889                0 1 3238 value=1
prim::ListConstruct      pnnx_1890                2 1 1757 3238 1763
prim::Constant           pnnx_1891                0 1 3239 value=0
prim::ListConstruct      pnnx_1892                2 1 1758 3239 1764
prim::Constant           pnnx_1893                0 1 3240 value=1
prim::Constant           pnnx_1894                0 1 3241 value=1
prim::ListConstruct      pnnx_1895                2 1 3240 3241 1765
prim::Constant           pnnx_1899                0 1 3244 value=1
F.adaptive_avg_pool2d    F.adaptive_avg_pool2d_17 2 1 1752 1753 x.39 $input=1752 $output_size=1753 #1752=(1,1248,4,16)f32 #x.39=(1,1248,1,1)f32
F.conv2d                 F.conv2d_109             7 1 x.39 weight.175 bias.71 1763 1764 1765 3244 input.141 $input=x.39 $weight=weight.175 $bias=bias.71 $stride=1763 $padding=1764 $dilation=1765 $groups=3244 #x.39=(1,1248,1,1)f32 #weight.175=(52,1248,1,1)f32 #bias.71=(52)f32 #input.141=(1,52,1,1)f32
nn.SiLU                  effnet._blocks.17._swish 1 1 input.141 1768 #input.141=(1,52,1,1)f32 #1768=(1,52,1,1)f32
prim::Constant           pnnx_1906                0 1 1771 value=1
prim::Constant           pnnx_1907                0 1 1772 value=0
pnnx.Attribute           effnet._blocks.17._se_expand 0 1 bias.73 @data=(1248)f32 #bias.73=(1248)f32
pnnx.Attribute           effnet._blocks.17._se_expand 0 1 weight.177 @data=(1248,52,1,1)f32 #weight.177=(1248,52,1,1)f32
prim::Constant           pnnx_1908                0 1 1776 value=None
prim::Constant           pnnx_1909                0 1 3248 value=1
prim::ListConstruct      pnnx_1910                2 1 1771 3248 1777
prim::Constant           pnnx_1911                0 1 3249 value=0
prim::ListConstruct      pnnx_1912                2 1 1772 3249 1778
prim::Constant           pnnx_1913                0 1 3250 value=1
prim::Constant           pnnx_1914                0 1 3251 value=1
prim::ListConstruct      pnnx_1915                2 1 3250 3251 1779
prim::Constant           pnnx_1919                0 1 3254 value=1
F.conv2d                 F.conv2d_110             7 1 1768 weight.177 bias.73 1777 1778 1779 3254 x_squeezed.36 $input=1768 $weight=weight.177 $bias=bias.73 $stride=1777 $padding=1778 $dilation=1779 $groups=3254 #1768=(1,52,1,1)f32 #weight.177=(1248,52,1,1)f32 #bias.73=(1248)f32 #x_squeezed.36=(1,1248,1,1)f32
F.sigmoid                F.sigmoid_155            1 1 x_squeezed.36 1782 $input=x_squeezed.36 #x_squeezed.36=(1,1248,1,1)f32 #1782=(1,1248,1,1)f32
aten::mul                pnnx_1925                2 1 1782 1752 x0.36 #1782=(1,1248,1,1)f32 #1752=(1,1248,4,16)f32 #x0.36=(1,1248,4,16)f32
prim::Constant           pnnx_1928                0 1 1786 value=None
prim::Constant           pnnx_1929                0 1 1787 value=1
prim::Constant           pnnx_1930                0 1 1788 value=0
pnnx.Attribute           effnet._blocks.17._project_conv 0 1 weight.179 @data=(208,1248,1,1)f32 #weight.179=(208,1248,1,1)f32
prim::Constant           pnnx_1931                0 1 1791 value=None
prim::Constant           pnnx_1932                0 1 3258 value=1
prim::ListConstruct      pnnx_1933                2 1 1787 3258 1792
prim::Constant           pnnx_1934                0 1 3259 value=0
prim::ListConstruct      pnnx_1935                2 1 1788 3259 1793
prim::Constant           pnnx_1936                0 1 3260 value=1
prim::Constant           pnnx_1937                0 1 3261 value=1
prim::ListConstruct      pnnx_1938                2 1 3260 3261 1794
prim::Constant           pnnx_1942                0 1 3264 value=1
F.conv2d                 F.conv2d_111             7 1 x0.36 weight.179 1786 1792 1793 1794 3264 input.143 $input=x0.36 $weight=weight.179 $bias=1786 $stride=1792 $padding=1793 $dilation=1794 $groups=3264 #x0.36=(1,1248,4,16)f32 #weight.179=(208,1248,1,1)f32 #input.143=(1,208,4,16)f32
nn.BatchNorm2d           effnet._blocks.17._bn2   1 1 input.143 1797 affine=True eps=1.000000e-03 num_features=208 @bias=(208)f32 @running_mean=(208)f32 @running_var=(208)f32 @weight=(208)f32 #input.143=(1,208,4,16)f32 #1797=(1,208,4,16)f32
prim::Constant           pnnx_1947                0 1 3268 value=1
aten::add                pnnx_1948                3 1 1797 1711 3268 1798 #1797=(1,208,4,16)f32 #1711=(1,208,4,16)f32 #1798=(1,208,4,16)f32
prim::Constant           pnnx_1949                0 1 1799 value=1
prim::Constant           pnnx_1952                0 1 1811 value=None
prim::Constant           pnnx_1953                0 1 1812 value=1
prim::Constant           pnnx_1954                0 1 1813 value=0
pnnx.Attribute           effnet._blocks.18._expand_conv 0 1 weight.181 @data=(1248,208,1,1)f32 #weight.181=(1248,208,1,1)f32
prim::Constant           pnnx_1955                0 1 1816 value=None
prim::Constant           pnnx_1956                0 1 3269 value=1
prim::ListConstruct      pnnx_1957                2 1 1812 3269 1817
prim::Constant           pnnx_1958                0 1 3270 value=0
prim::ListConstruct      pnnx_1959                2 1 1813 3270 1818
prim::Constant           pnnx_1960                0 1 3271 value=1
prim::Constant           pnnx_1961                0 1 3272 value=1
prim::ListConstruct      pnnx_1962                2 1 3271 3272 1819
prim::Constant           pnnx_1966                0 1 3275 value=1
F.conv2d                 F.conv2d_112             7 1 1798 weight.181 1811 1817 1818 1819 3275 input.145 $input=1798 $weight=weight.181 $bias=1811 $stride=1817 $padding=1818 $dilation=1819 $groups=3275 #1798=(1,208,4,16)f32 #weight.181=(1248,208,1,1)f32 #input.145=(1,1248,4,16)f32
nn.BatchNorm2d           effnet._blocks.18._bn0   1 1 input.145 1822 affine=True eps=1.000000e-03 num_features=1248 @bias=(1248)f32 @running_mean=(1248)f32 @running_var=(1248)f32 @weight=(1248)f32 #input.145=(1,1248,4,16)f32 #1822=(1,1248,4,16)f32
nn.SiLU                  effnet._blocks.18._swish 1 1 1822 1823 #1822=(1,1248,4,16)f32 #1823=(1,1248,4,16)f32
prim::Constant           pnnx_1973                0 1 1826 value=None
prim::Constant           pnnx_1974                0 1 1827 value=1
prim::Constant           pnnx_1975                0 1 1828 value=0
prim::Constant           pnnx_1976                0 1 1829 value=1248
pnnx.Attribute           effnet._blocks.18._depthwise_conv 0 1 weight.183 @data=(1248,1,5,5)f32 #weight.183=(1248,1,5,5)f32
nn.ZeroPad2d             effnet._blocks.18._depthwise_conv.static_padding 1 1 1823 1832 padding=(2,2,2,2) #1823=(1,1248,4,16)f32 #1832=(1,1248,8,20)f32
prim::Constant           pnnx_1977                0 1 3279 value=1
prim::ListConstruct      pnnx_1978                2 1 1827 3279 1833
prim::Constant           pnnx_1979                0 1 3280 value=0
prim::ListConstruct      pnnx_1980                2 1 1828 3280 1834
prim::Constant           pnnx_1981                0 1 3281 value=1
prim::Constant           pnnx_1982                0 1 3282 value=1
prim::ListConstruct      pnnx_1983                2 1 3281 3282 1835
F.conv2d                 F.conv2d_113             7 1 1832 weight.183 1826 1833 1834 1835 1829 input.147 $input=1832 $weight=weight.183 $bias=1826 $stride=1833 $padding=1834 $dilation=1835 $groups=1829 #1832=(1,1248,8,20)f32 #weight.183=(1248,1,5,5)f32 #input.147=(1,1248,4,16)f32
nn.BatchNorm2d           effnet._blocks.18._bn1   1 1 input.147 1838 affine=True eps=1.000000e-03 num_features=1248 @bias=(1248)f32 @running_mean=(1248)f32 @running_var=(1248)f32 @weight=(1248)f32 #input.147=(1,1248,4,16)f32 #1838=(1,1248,4,16)f32
nn.SiLU                  effnet._blocks.18._swish 1 1 1838 1839 #1838=(1,1248,4,16)f32 #1839=(1,1248,4,16)f32
prim::Constant           pnnx_1991                0 1 3288 value=1
prim::ListConstruct      pnnx_1992                2 1 1799 3288 1840
prim::Constant           pnnx_1996                0 1 1844 value=1
prim::Constant           pnnx_1997                0 1 1845 value=0
pnnx.Attribute           effnet._blocks.18._se_reduce 0 1 bias.75 @data=(52)f32 #bias.75=(52)f32
pnnx.Attribute           effnet._blocks.18._se_reduce 0 1 weight.185 @data=(52,1248,1,1)f32 #weight.185=(52,1248,1,1)f32
prim::Constant           pnnx_1998                0 1 1849 value=None
prim::Constant           pnnx_1999                0 1 3289 value=1
prim::ListConstruct      pnnx_2000                2 1 1844 3289 1850
prim::Constant           pnnx_2001                0 1 3290 value=0
prim::ListConstruct      pnnx_2002                2 1 1845 3290 1851
prim::Constant           pnnx_2003                0 1 3291 value=1
prim::Constant           pnnx_2004                0 1 3292 value=1
prim::ListConstruct      pnnx_2005                2 1 3291 3292 1852
prim::Constant           pnnx_2009                0 1 3295 value=1
F.adaptive_avg_pool2d    F.adaptive_avg_pool2d_18 2 1 1839 1840 x.41 $input=1839 $output_size=1840 #1839=(1,1248,4,16)f32 #x.41=(1,1248,1,1)f32
F.conv2d                 F.conv2d_114             7 1 x.41 weight.185 bias.75 1850 1851 1852 3295 input.149 $input=x.41 $weight=weight.185 $bias=bias.75 $stride=1850 $padding=1851 $dilation=1852 $groups=3295 #x.41=(1,1248,1,1)f32 #weight.185=(52,1248,1,1)f32 #bias.75=(52)f32 #input.149=(1,52,1,1)f32
nn.SiLU                  effnet._blocks.18._swish 1 1 input.149 1855 #input.149=(1,52,1,1)f32 #1855=(1,52,1,1)f32
prim::Constant           pnnx_2016                0 1 1858 value=1
prim::Constant           pnnx_2017                0 1 1859 value=0
pnnx.Attribute           effnet._blocks.18._se_expand 0 1 bias.77 @data=(1248)f32 #bias.77=(1248)f32
pnnx.Attribute           effnet._blocks.18._se_expand 0 1 weight.187 @data=(1248,52,1,1)f32 #weight.187=(1248,52,1,1)f32
prim::Constant           pnnx_2018                0 1 1863 value=None
prim::Constant           pnnx_2019                0 1 3299 value=1
prim::ListConstruct      pnnx_2020                2 1 1858 3299 1864
prim::Constant           pnnx_2021                0 1 3300 value=0
prim::ListConstruct      pnnx_2022                2 1 1859 3300 1865
prim::Constant           pnnx_2023                0 1 3301 value=1
prim::Constant           pnnx_2024                0 1 3302 value=1
prim::ListConstruct      pnnx_2025                2 1 3301 3302 1866
prim::Constant           pnnx_2029                0 1 3305 value=1
F.conv2d                 F.conv2d_115             7 1 1855 weight.187 bias.77 1864 1865 1866 3305 x_squeezed.38 $input=1855 $weight=weight.187 $bias=bias.77 $stride=1864 $padding=1865 $dilation=1866 $groups=3305 #1855=(1,52,1,1)f32 #weight.187=(1248,52,1,1)f32 #bias.77=(1248)f32 #x_squeezed.38=(1,1248,1,1)f32
F.sigmoid                F.sigmoid_156            1 1 x_squeezed.38 1869 $input=x_squeezed.38 #x_squeezed.38=(1,1248,1,1)f32 #1869=(1,1248,1,1)f32
aten::mul                pnnx_2035                2 1 1869 1839 x0.38 #1869=(1,1248,1,1)f32 #1839=(1,1248,4,16)f32 #x0.38=(1,1248,4,16)f32
prim::Constant           pnnx_2038                0 1 1873 value=None
prim::Constant           pnnx_2039                0 1 1874 value=1
prim::Constant           pnnx_2040                0 1 1875 value=0
pnnx.Attribute           effnet._blocks.18._project_conv 0 1 weight.189 @data=(208,1248,1,1)f32 #weight.189=(208,1248,1,1)f32
prim::Constant           pnnx_2041                0 1 1878 value=None
prim::Constant           pnnx_2042                0 1 3309 value=1
prim::ListConstruct      pnnx_2043                2 1 1874 3309 1879
prim::Constant           pnnx_2044                0 1 3310 value=0
prim::ListConstruct      pnnx_2045                2 1 1875 3310 1880
prim::Constant           pnnx_2046                0 1 3311 value=1
prim::Constant           pnnx_2047                0 1 3312 value=1
prim::ListConstruct      pnnx_2048                2 1 3311 3312 1881
prim::Constant           pnnx_2052                0 1 3315 value=1
F.conv2d                 F.conv2d_116             7 1 x0.38 weight.189 1873 1879 1880 1881 3315 input.151 $input=x0.38 $weight=weight.189 $bias=1873 $stride=1879 $padding=1880 $dilation=1881 $groups=3315 #x0.38=(1,1248,4,16)f32 #weight.189=(208,1248,1,1)f32 #input.151=(1,208,4,16)f32
nn.BatchNorm2d           effnet._blocks.18._bn2   1 1 input.151 1884 affine=True eps=1.000000e-03 num_features=208 @bias=(208)f32 @running_mean=(208)f32 @running_var=(208)f32 @weight=(208)f32 #input.151=(1,208,4,16)f32 #1884=(1,208,4,16)f32
prim::Constant           pnnx_2057                0 1 3319 value=1
aten::add                pnnx_2058                3 1 1884 1798 3319 1885 #1884=(1,208,4,16)f32 #1798=(1,208,4,16)f32 #1885=(1,208,4,16)f32
prim::Constant           pnnx_2059                0 1 1886 value=1
prim::Constant           pnnx_2062                0 1 1898 value=None
prim::Constant           pnnx_2063                0 1 1899 value=1
prim::Constant           pnnx_2064                0 1 1900 value=0
pnnx.Attribute           effnet._blocks.19._expand_conv 0 1 weight.191 @data=(1248,208,1,1)f32 #weight.191=(1248,208,1,1)f32
prim::Constant           pnnx_2065                0 1 1903 value=None
prim::Constant           pnnx_2066                0 1 3320 value=1
prim::ListConstruct      pnnx_2067                2 1 1899 3320 1904
prim::Constant           pnnx_2068                0 1 3321 value=0
prim::ListConstruct      pnnx_2069                2 1 1900 3321 1905
prim::Constant           pnnx_2070                0 1 3322 value=1
prim::Constant           pnnx_2071                0 1 3323 value=1
prim::ListConstruct      pnnx_2072                2 1 3322 3323 1906
prim::Constant           pnnx_2076                0 1 3326 value=1
F.conv2d                 F.conv2d_117             7 1 1885 weight.191 1898 1904 1905 1906 3326 input.153 $input=1885 $weight=weight.191 $bias=1898 $stride=1904 $padding=1905 $dilation=1906 $groups=3326 #1885=(1,208,4,16)f32 #weight.191=(1248,208,1,1)f32 #input.153=(1,1248,4,16)f32
nn.BatchNorm2d           effnet._blocks.19._bn0   1 1 input.153 1909 affine=True eps=1.000000e-03 num_features=1248 @bias=(1248)f32 @running_mean=(1248)f32 @running_var=(1248)f32 @weight=(1248)f32 #input.153=(1,1248,4,16)f32 #1909=(1,1248,4,16)f32
nn.SiLU                  effnet._blocks.19._swish 1 1 1909 1910 #1909=(1,1248,4,16)f32 #1910=(1,1248,4,16)f32
prim::Constant           pnnx_2083                0 1 1913 value=None
prim::Constant           pnnx_2084                0 1 1914 value=1
prim::Constant           pnnx_2085                0 1 1915 value=0
prim::Constant           pnnx_2086                0 1 1916 value=1248
pnnx.Attribute           effnet._blocks.19._depthwise_conv 0 1 weight.193 @data=(1248,1,5,5)f32 #weight.193=(1248,1,5,5)f32
nn.ZeroPad2d             effnet._blocks.19._depthwise_conv.static_padding 1 1 1910 1919 padding=(2,2,2,2) #1910=(1,1248,4,16)f32 #1919=(1,1248,8,20)f32
prim::Constant           pnnx_2087                0 1 3330 value=1
prim::ListConstruct      pnnx_2088                2 1 1914 3330 1920
prim::Constant           pnnx_2089                0 1 3331 value=0
prim::ListConstruct      pnnx_2090                2 1 1915 3331 1921
prim::Constant           pnnx_2091                0 1 3332 value=1
prim::Constant           pnnx_2092                0 1 3333 value=1
prim::ListConstruct      pnnx_2093                2 1 3332 3333 1922
F.conv2d                 F.conv2d_118             7 1 1919 weight.193 1913 1920 1921 1922 1916 input.155 $input=1919 $weight=weight.193 $bias=1913 $stride=1920 $padding=1921 $dilation=1922 $groups=1916 #1919=(1,1248,8,20)f32 #weight.193=(1248,1,5,5)f32 #input.155=(1,1248,4,16)f32
nn.BatchNorm2d           effnet._blocks.19._bn1   1 1 input.155 1925 affine=True eps=1.000000e-03 num_features=1248 @bias=(1248)f32 @running_mean=(1248)f32 @running_var=(1248)f32 @weight=(1248)f32 #input.155=(1,1248,4,16)f32 #1925=(1,1248,4,16)f32
nn.SiLU                  effnet._blocks.19._swish 1 1 1925 1926 #1925=(1,1248,4,16)f32 #1926=(1,1248,4,16)f32
prim::Constant           pnnx_2101                0 1 3339 value=1
prim::ListConstruct      pnnx_2102                2 1 1886 3339 1927
prim::Constant           pnnx_2106                0 1 1931 value=1
prim::Constant           pnnx_2107                0 1 1932 value=0
pnnx.Attribute           effnet._blocks.19._se_reduce 0 1 bias.79 @data=(52)f32 #bias.79=(52)f32
pnnx.Attribute           effnet._blocks.19._se_reduce 0 1 weight.195 @data=(52,1248,1,1)f32 #weight.195=(52,1248,1,1)f32
prim::Constant           pnnx_2108                0 1 1936 value=None
prim::Constant           pnnx_2109                0 1 3340 value=1
prim::ListConstruct      pnnx_2110                2 1 1931 3340 1937
prim::Constant           pnnx_2111                0 1 3341 value=0
prim::ListConstruct      pnnx_2112                2 1 1932 3341 1938
prim::Constant           pnnx_2113                0 1 3342 value=1
prim::Constant           pnnx_2114                0 1 3343 value=1
prim::ListConstruct      pnnx_2115                2 1 3342 3343 1939
prim::Constant           pnnx_2119                0 1 3346 value=1
F.adaptive_avg_pool2d    F.adaptive_avg_pool2d_19 2 1 1926 1927 x.43 $input=1926 $output_size=1927 #1926=(1,1248,4,16)f32 #x.43=(1,1248,1,1)f32
F.conv2d                 F.conv2d_119             7 1 x.43 weight.195 bias.79 1937 1938 1939 3346 input.157 $input=x.43 $weight=weight.195 $bias=bias.79 $stride=1937 $padding=1938 $dilation=1939 $groups=3346 #x.43=(1,1248,1,1)f32 #weight.195=(52,1248,1,1)f32 #bias.79=(52)f32 #input.157=(1,52,1,1)f32
nn.SiLU                  effnet._blocks.19._swish 1 1 input.157 1942 #input.157=(1,52,1,1)f32 #1942=(1,52,1,1)f32
prim::Constant           pnnx_2126                0 1 1945 value=1
prim::Constant           pnnx_2127                0 1 1946 value=0
pnnx.Attribute           effnet._blocks.19._se_expand 0 1 bias.81 @data=(1248)f32 #bias.81=(1248)f32
pnnx.Attribute           effnet._blocks.19._se_expand 0 1 weight.197 @data=(1248,52,1,1)f32 #weight.197=(1248,52,1,1)f32
prim::Constant           pnnx_2128                0 1 1950 value=None
prim::Constant           pnnx_2129                0 1 3350 value=1
prim::ListConstruct      pnnx_2130                2 1 1945 3350 1951
prim::Constant           pnnx_2131                0 1 3351 value=0
prim::ListConstruct      pnnx_2132                2 1 1946 3351 1952
prim::Constant           pnnx_2133                0 1 3352 value=1
prim::Constant           pnnx_2134                0 1 3353 value=1
prim::ListConstruct      pnnx_2135                2 1 3352 3353 1953
prim::Constant           pnnx_2139                0 1 3356 value=1
F.conv2d                 F.conv2d_120             7 1 1942 weight.197 bias.81 1951 1952 1953 3356 x_squeezed.40 $input=1942 $weight=weight.197 $bias=bias.81 $stride=1951 $padding=1952 $dilation=1953 $groups=3356 #1942=(1,52,1,1)f32 #weight.197=(1248,52,1,1)f32 #bias.81=(1248)f32 #x_squeezed.40=(1,1248,1,1)f32
F.sigmoid                F.sigmoid_157            1 1 x_squeezed.40 1956 $input=x_squeezed.40 #x_squeezed.40=(1,1248,1,1)f32 #1956=(1,1248,1,1)f32
aten::mul                pnnx_2145                2 1 1956 1926 x0.40 #1956=(1,1248,1,1)f32 #1926=(1,1248,4,16)f32 #x0.40=(1,1248,4,16)f32
prim::Constant           pnnx_2148                0 1 1960 value=None
prim::Constant           pnnx_2149                0 1 1961 value=1
prim::Constant           pnnx_2150                0 1 1962 value=0
pnnx.Attribute           effnet._blocks.19._project_conv 0 1 weight.199 @data=(208,1248,1,1)f32 #weight.199=(208,1248,1,1)f32
prim::Constant           pnnx_2151                0 1 1965 value=None
prim::Constant           pnnx_2152                0 1 3360 value=1
prim::ListConstruct      pnnx_2153                2 1 1961 3360 1966
prim::Constant           pnnx_2154                0 1 3361 value=0
prim::ListConstruct      pnnx_2155                2 1 1962 3361 1967
prim::Constant           pnnx_2156                0 1 3362 value=1
prim::Constant           pnnx_2157                0 1 3363 value=1
prim::ListConstruct      pnnx_2158                2 1 3362 3363 1968
prim::Constant           pnnx_2162                0 1 3366 value=1
F.conv2d                 F.conv2d_121             7 1 x0.40 weight.199 1960 1966 1967 1968 3366 input.159 $input=x0.40 $weight=weight.199 $bias=1960 $stride=1966 $padding=1967 $dilation=1968 $groups=3366 #x0.40=(1,1248,4,16)f32 #weight.199=(208,1248,1,1)f32 #input.159=(1,208,4,16)f32
nn.BatchNorm2d           effnet._blocks.19._bn2   1 1 input.159 1971 affine=True eps=1.000000e-03 num_features=208 @bias=(208)f32 @running_mean=(208)f32 @running_var=(208)f32 @weight=(208)f32 #input.159=(1,208,4,16)f32 #1971=(1,208,4,16)f32
prim::Constant           pnnx_2167                0 1 3370 value=1
aten::add                pnnx_2168                3 1 1971 1885 3370 1972 #1971=(1,208,4,16)f32 #1885=(1,208,4,16)f32 #1972=(1,208,4,16)f32
prim::Constant           pnnx_2169                0 1 1973 value=1
prim::Constant           pnnx_2172                0 1 1985 value=None
prim::Constant           pnnx_2173                0 1 1986 value=1
prim::Constant           pnnx_2174                0 1 1987 value=0
pnnx.Attribute           effnet._blocks.20._expand_conv 0 1 weight.201 @data=(1248,208,1,1)f32 #weight.201=(1248,208,1,1)f32
prim::Constant           pnnx_2175                0 1 1990 value=None
prim::Constant           pnnx_2176                0 1 3371 value=1
prim::ListConstruct      pnnx_2177                2 1 1986 3371 1991
prim::Constant           pnnx_2178                0 1 3372 value=0
prim::ListConstruct      pnnx_2179                2 1 1987 3372 1992
prim::Constant           pnnx_2180                0 1 3373 value=1
prim::Constant           pnnx_2181                0 1 3374 value=1
prim::ListConstruct      pnnx_2182                2 1 3373 3374 1993
prim::Constant           pnnx_2186                0 1 3377 value=1
F.conv2d                 F.conv2d_122             7 1 1972 weight.201 1985 1991 1992 1993 3377 input.161 $input=1972 $weight=weight.201 $bias=1985 $stride=1991 $padding=1992 $dilation=1993 $groups=3377 #1972=(1,208,4,16)f32 #weight.201=(1248,208,1,1)f32 #input.161=(1,1248,4,16)f32
nn.BatchNorm2d           effnet._blocks.20._bn0   1 1 input.161 1996 affine=True eps=1.000000e-03 num_features=1248 @bias=(1248)f32 @running_mean=(1248)f32 @running_var=(1248)f32 @weight=(1248)f32 #input.161=(1,1248,4,16)f32 #1996=(1,1248,4,16)f32
nn.SiLU                  effnet._blocks.20._swish 1 1 1996 1997 #1996=(1,1248,4,16)f32 #1997=(1,1248,4,16)f32
prim::Constant           pnnx_2193                0 1 2000 value=None
prim::Constant           pnnx_2194                0 1 2001 value=1
prim::Constant           pnnx_2195                0 1 2002 value=0
prim::Constant           pnnx_2196                0 1 2003 value=1248
pnnx.Attribute           effnet._blocks.20._depthwise_conv 0 1 weight.203 @data=(1248,1,5,5)f32 #weight.203=(1248,1,5,5)f32
nn.ZeroPad2d             effnet._blocks.20._depthwise_conv.static_padding 1 1 1997 2006 padding=(2,2,2,2) #1997=(1,1248,4,16)f32 #2006=(1,1248,8,20)f32
prim::Constant           pnnx_2197                0 1 3381 value=1
prim::ListConstruct      pnnx_2198                2 1 2001 3381 2007
prim::Constant           pnnx_2199                0 1 3382 value=0
prim::ListConstruct      pnnx_2200                2 1 2002 3382 2008
prim::Constant           pnnx_2201                0 1 3383 value=1
prim::Constant           pnnx_2202                0 1 3384 value=1
prim::ListConstruct      pnnx_2203                2 1 3383 3384 2009
F.conv2d                 F.conv2d_123             7 1 2006 weight.203 2000 2007 2008 2009 2003 input.163 $input=2006 $weight=weight.203 $bias=2000 $stride=2007 $padding=2008 $dilation=2009 $groups=2003 #2006=(1,1248,8,20)f32 #weight.203=(1248,1,5,5)f32 #input.163=(1,1248,4,16)f32
nn.BatchNorm2d           effnet._blocks.20._bn1   1 1 input.163 2012 affine=True eps=1.000000e-03 num_features=1248 @bias=(1248)f32 @running_mean=(1248)f32 @running_var=(1248)f32 @weight=(1248)f32 #input.163=(1,1248,4,16)f32 #2012=(1,1248,4,16)f32
nn.SiLU                  effnet._blocks.20._swish 1 1 2012 2013 #2012=(1,1248,4,16)f32 #2013=(1,1248,4,16)f32
prim::Constant           pnnx_2211                0 1 3390 value=1
prim::ListConstruct      pnnx_2212                2 1 1973 3390 2014
prim::Constant           pnnx_2216                0 1 2018 value=1
prim::Constant           pnnx_2217                0 1 2019 value=0
pnnx.Attribute           effnet._blocks.20._se_reduce 0 1 bias.83 @data=(52)f32 #bias.83=(52)f32
pnnx.Attribute           effnet._blocks.20._se_reduce 0 1 weight.205 @data=(52,1248,1,1)f32 #weight.205=(52,1248,1,1)f32
prim::Constant           pnnx_2218                0 1 2023 value=None
prim::Constant           pnnx_2219                0 1 3391 value=1
prim::ListConstruct      pnnx_2220                2 1 2018 3391 2024
prim::Constant           pnnx_2221                0 1 3392 value=0
prim::ListConstruct      pnnx_2222                2 1 2019 3392 2025
prim::Constant           pnnx_2223                0 1 3393 value=1
prim::Constant           pnnx_2224                0 1 3394 value=1
prim::ListConstruct      pnnx_2225                2 1 3393 3394 2026
prim::Constant           pnnx_2229                0 1 3397 value=1
F.adaptive_avg_pool2d    F.adaptive_avg_pool2d_20 2 1 2013 2014 x.45 $input=2013 $output_size=2014 #2013=(1,1248,4,16)f32 #x.45=(1,1248,1,1)f32
F.conv2d                 F.conv2d_124             7 1 x.45 weight.205 bias.83 2024 2025 2026 3397 input.165 $input=x.45 $weight=weight.205 $bias=bias.83 $stride=2024 $padding=2025 $dilation=2026 $groups=3397 #x.45=(1,1248,1,1)f32 #weight.205=(52,1248,1,1)f32 #bias.83=(52)f32 #input.165=(1,52,1,1)f32
nn.SiLU                  effnet._blocks.20._swish 1 1 input.165 2029 #input.165=(1,52,1,1)f32 #2029=(1,52,1,1)f32
prim::Constant           pnnx_2236                0 1 2032 value=1
prim::Constant           pnnx_2237                0 1 2033 value=0
pnnx.Attribute           effnet._blocks.20._se_expand 0 1 bias.85 @data=(1248)f32 #bias.85=(1248)f32
pnnx.Attribute           effnet._blocks.20._se_expand 0 1 weight.207 @data=(1248,52,1,1)f32 #weight.207=(1248,52,1,1)f32
prim::Constant           pnnx_2238                0 1 2037 value=None
prim::Constant           pnnx_2239                0 1 3401 value=1
prim::ListConstruct      pnnx_2240                2 1 2032 3401 2038
prim::Constant           pnnx_2241                0 1 3402 value=0
prim::ListConstruct      pnnx_2242                2 1 2033 3402 2039
prim::Constant           pnnx_2243                0 1 3403 value=1
prim::Constant           pnnx_2244                0 1 3404 value=1
prim::ListConstruct      pnnx_2245                2 1 3403 3404 2040
prim::Constant           pnnx_2249                0 1 3407 value=1
F.conv2d                 F.conv2d_125             7 1 2029 weight.207 bias.85 2038 2039 2040 3407 x_squeezed.42 $input=2029 $weight=weight.207 $bias=bias.85 $stride=2038 $padding=2039 $dilation=2040 $groups=3407 #2029=(1,52,1,1)f32 #weight.207=(1248,52,1,1)f32 #bias.85=(1248)f32 #x_squeezed.42=(1,1248,1,1)f32
F.sigmoid                F.sigmoid_158            1 1 x_squeezed.42 2043 $input=x_squeezed.42 #x_squeezed.42=(1,1248,1,1)f32 #2043=(1,1248,1,1)f32
aten::mul                pnnx_2255                2 1 2043 2013 x0.42 #2043=(1,1248,1,1)f32 #2013=(1,1248,4,16)f32 #x0.42=(1,1248,4,16)f32
prim::Constant           pnnx_2258                0 1 2047 value=None
prim::Constant           pnnx_2259                0 1 2048 value=1
prim::Constant           pnnx_2260                0 1 2049 value=0
pnnx.Attribute           effnet._blocks.20._project_conv 0 1 weight.209 @data=(208,1248,1,1)f32 #weight.209=(208,1248,1,1)f32
prim::Constant           pnnx_2261                0 1 2052 value=None
prim::Constant           pnnx_2262                0 1 3411 value=1
prim::ListConstruct      pnnx_2263                2 1 2048 3411 2053
prim::Constant           pnnx_2264                0 1 3412 value=0
prim::ListConstruct      pnnx_2265                2 1 2049 3412 2054
prim::Constant           pnnx_2266                0 1 3413 value=1
prim::Constant           pnnx_2267                0 1 3414 value=1
prim::ListConstruct      pnnx_2268                2 1 3413 3414 2055
prim::Constant           pnnx_2272                0 1 3417 value=1
F.conv2d                 F.conv2d_126             7 1 x0.42 weight.209 2047 2053 2054 2055 3417 input.167 $input=x0.42 $weight=weight.209 $bias=2047 $stride=2053 $padding=2054 $dilation=2055 $groups=3417 #x0.42=(1,1248,4,16)f32 #weight.209=(208,1248,1,1)f32 #input.167=(1,208,4,16)f32
nn.BatchNorm2d           effnet._blocks.20._bn2   1 1 input.167 2058 affine=True eps=1.000000e-03 num_features=208 @bias=(208)f32 @running_mean=(208)f32 @running_var=(208)f32 @weight=(208)f32 #input.167=(1,208,4,16)f32 #2058=(1,208,4,16)f32
prim::Constant           pnnx_2277                0 1 3421 value=1
aten::add                pnnx_2278                3 1 2058 1972 3421 2059 #2058=(1,208,4,16)f32 #1972=(1,208,4,16)f32 #2059=(1,208,4,16)f32
prim::Constant           pnnx_2279                0 1 2060 value=1
prim::Constant           pnnx_2282                0 1 2072 value=None
prim::Constant           pnnx_2283                0 1 2073 value=1
prim::Constant           pnnx_2284                0 1 2074 value=0
pnnx.Attribute           effnet._blocks.21._expand_conv 0 1 weight.211 @data=(1248,208,1,1)f32 #weight.211=(1248,208,1,1)f32
prim::Constant           pnnx_2285                0 1 2077 value=None
prim::Constant           pnnx_2286                0 1 3422 value=1
prim::ListConstruct      pnnx_2287                2 1 2073 3422 2078
prim::Constant           pnnx_2288                0 1 3423 value=0
prim::ListConstruct      pnnx_2289                2 1 2074 3423 2079
prim::Constant           pnnx_2290                0 1 3424 value=1
prim::Constant           pnnx_2291                0 1 3425 value=1
prim::ListConstruct      pnnx_2292                2 1 3424 3425 2080
prim::Constant           pnnx_2296                0 1 3428 value=1
F.conv2d                 F.conv2d_127             7 1 2059 weight.211 2072 2078 2079 2080 3428 input.169 $input=2059 $weight=weight.211 $bias=2072 $stride=2078 $padding=2079 $dilation=2080 $groups=3428 #2059=(1,208,4,16)f32 #weight.211=(1248,208,1,1)f32 #input.169=(1,1248,4,16)f32
nn.BatchNorm2d           effnet._blocks.21._bn0   1 1 input.169 2083 affine=True eps=1.000000e-03 num_features=1248 @bias=(1248)f32 @running_mean=(1248)f32 @running_var=(1248)f32 @weight=(1248)f32 #input.169=(1,1248,4,16)f32 #2083=(1,1248,4,16)f32
nn.SiLU                  effnet._blocks.21._swish 1 1 2083 2084 #2083=(1,1248,4,16)f32 #2084=(1,1248,4,16)f32
prim::Constant           pnnx_2303                0 1 2087 value=None
prim::Constant           pnnx_2304                0 1 2088 value=1
prim::Constant           pnnx_2305                0 1 2089 value=0
prim::Constant           pnnx_2306                0 1 2090 value=1248
pnnx.Attribute           effnet._blocks.21._depthwise_conv 0 1 weight.213 @data=(1248,1,3,3)f32 #weight.213=(1248,1,3,3)f32
nn.ZeroPad2d             effnet._blocks.21._depthwise_conv.static_padding 1 1 2084 2093 padding=(1,1,1,1) #2084=(1,1248,4,16)f32 #2093=(1,1248,6,18)f32
prim::Constant           pnnx_2307                0 1 3432 value=1
prim::ListConstruct      pnnx_2308                2 1 2088 3432 2094
prim::Constant           pnnx_2309                0 1 3433 value=0
prim::ListConstruct      pnnx_2310                2 1 2089 3433 2095
prim::Constant           pnnx_2311                0 1 3434 value=1
prim::Constant           pnnx_2312                0 1 3435 value=1
prim::ListConstruct      pnnx_2313                2 1 3434 3435 2096
F.conv2d                 F.conv2d_128             7 1 2093 weight.213 2087 2094 2095 2096 2090 input.171 $input=2093 $weight=weight.213 $bias=2087 $stride=2094 $padding=2095 $dilation=2096 $groups=2090 #2093=(1,1248,6,18)f32 #weight.213=(1248,1,3,3)f32 #input.171=(1,1248,4,16)f32
nn.BatchNorm2d           effnet._blocks.21._bn1   1 1 input.171 2099 affine=True eps=1.000000e-03 num_features=1248 @bias=(1248)f32 @running_mean=(1248)f32 @running_var=(1248)f32 @weight=(1248)f32 #input.171=(1,1248,4,16)f32 #2099=(1,1248,4,16)f32
nn.SiLU                  effnet._blocks.21._swish 1 1 2099 2100 #2099=(1,1248,4,16)f32 #2100=(1,1248,4,16)f32
prim::Constant           pnnx_2321                0 1 3441 value=1
prim::ListConstruct      pnnx_2322                2 1 2060 3441 2101
prim::Constant           pnnx_2326                0 1 2105 value=1
prim::Constant           pnnx_2327                0 1 2106 value=0
pnnx.Attribute           effnet._blocks.21._se_reduce 0 1 bias.87 @data=(52)f32 #bias.87=(52)f32
pnnx.Attribute           effnet._blocks.21._se_reduce 0 1 weight.215 @data=(52,1248,1,1)f32 #weight.215=(52,1248,1,1)f32
prim::Constant           pnnx_2328                0 1 2110 value=None
prim::Constant           pnnx_2329                0 1 3442 value=1
prim::ListConstruct      pnnx_2330                2 1 2105 3442 2111
prim::Constant           pnnx_2331                0 1 3443 value=0
prim::ListConstruct      pnnx_2332                2 1 2106 3443 2112
prim::Constant           pnnx_2333                0 1 3444 value=1
prim::Constant           pnnx_2334                0 1 3445 value=1
prim::ListConstruct      pnnx_2335                2 1 3444 3445 2113
prim::Constant           pnnx_2339                0 1 3448 value=1
F.adaptive_avg_pool2d    F.adaptive_avg_pool2d_21 2 1 2100 2101 x.47 $input=2100 $output_size=2101 #2100=(1,1248,4,16)f32 #x.47=(1,1248,1,1)f32
F.conv2d                 F.conv2d_129             7 1 x.47 weight.215 bias.87 2111 2112 2113 3448 input.173 $input=x.47 $weight=weight.215 $bias=bias.87 $stride=2111 $padding=2112 $dilation=2113 $groups=3448 #x.47=(1,1248,1,1)f32 #weight.215=(52,1248,1,1)f32 #bias.87=(52)f32 #input.173=(1,52,1,1)f32
nn.SiLU                  effnet._blocks.21._swish 1 1 input.173 2116 #input.173=(1,52,1,1)f32 #2116=(1,52,1,1)f32
prim::Constant           pnnx_2346                0 1 2119 value=1
prim::Constant           pnnx_2347                0 1 2120 value=0
pnnx.Attribute           effnet._blocks.21._se_expand 0 1 bias.89 @data=(1248)f32 #bias.89=(1248)f32
pnnx.Attribute           effnet._blocks.21._se_expand 0 1 weight.217 @data=(1248,52,1,1)f32 #weight.217=(1248,52,1,1)f32
prim::Constant           pnnx_2348                0 1 2124 value=None
prim::Constant           pnnx_2349                0 1 3452 value=1
prim::ListConstruct      pnnx_2350                2 1 2119 3452 2125
prim::Constant           pnnx_2351                0 1 3453 value=0
prim::ListConstruct      pnnx_2352                2 1 2120 3453 2126
prim::Constant           pnnx_2353                0 1 3454 value=1
prim::Constant           pnnx_2354                0 1 3455 value=1
prim::ListConstruct      pnnx_2355                2 1 3454 3455 2127
prim::Constant           pnnx_2359                0 1 3458 value=1
F.conv2d                 F.conv2d_130             7 1 2116 weight.217 bias.89 2125 2126 2127 3458 x_squeezed.44 $input=2116 $weight=weight.217 $bias=bias.89 $stride=2125 $padding=2126 $dilation=2127 $groups=3458 #2116=(1,52,1,1)f32 #weight.217=(1248,52,1,1)f32 #bias.89=(1248)f32 #x_squeezed.44=(1,1248,1,1)f32
F.sigmoid                F.sigmoid_159            1 1 x_squeezed.44 2130 $input=x_squeezed.44 #x_squeezed.44=(1,1248,1,1)f32 #2130=(1,1248,1,1)f32
aten::mul                pnnx_2365                2 1 2130 2100 x0.44 #2130=(1,1248,1,1)f32 #2100=(1,1248,4,16)f32 #x0.44=(1,1248,4,16)f32
prim::Constant           pnnx_2368                0 1 2134 value=None
prim::Constant           pnnx_2369                0 1 2135 value=1
prim::Constant           pnnx_2370                0 1 2136 value=0
pnnx.Attribute           effnet._blocks.21._project_conv 0 1 weight.219 @data=(352,1248,1,1)f32 #weight.219=(352,1248,1,1)f32
prim::Constant           pnnx_2371                0 1 2139 value=None
prim::Constant           pnnx_2372                0 1 3462 value=1
prim::ListConstruct      pnnx_2373                2 1 2135 3462 2140
prim::Constant           pnnx_2374                0 1 3463 value=0
prim::ListConstruct      pnnx_2375                2 1 2136 3463 2141
prim::Constant           pnnx_2376                0 1 3464 value=1
prim::Constant           pnnx_2377                0 1 3465 value=1
prim::ListConstruct      pnnx_2378                2 1 3464 3465 2142
prim::Constant           pnnx_2382                0 1 3468 value=1
F.conv2d                 F.conv2d_131             7 1 x0.44 weight.219 2134 2140 2141 2142 3468 input.175 $input=x0.44 $weight=weight.219 $bias=2134 $stride=2140 $padding=2141 $dilation=2142 $groups=3468 #x0.44=(1,1248,4,16)f32 #weight.219=(352,1248,1,1)f32 #input.175=(1,352,4,16)f32
nn.BatchNorm2d           effnet._blocks.21._bn2   1 1 input.175 2145 affine=True eps=1.000000e-03 num_features=352 @bias=(352)f32 @running_mean=(352)f32 @running_var=(352)f32 @weight=(352)f32 #input.175=(1,352,4,16)f32 #2145=(1,352,4,16)f32
prim::Constant           pnnx_2387                0 1 2146 value=1
prim::Constant           pnnx_2390                0 1 2158 value=None
prim::Constant           pnnx_2391                0 1 2159 value=1
prim::Constant           pnnx_2392                0 1 2160 value=0
pnnx.Attribute           effnet._blocks.22._expand_conv 0 1 weight.2 @data=(2112,352,1,1)f32 #weight.2=(2112,352,1,1)f32
prim::Constant           pnnx_2393                0 1 2163 value=None
prim::Constant           pnnx_2394                0 1 3472 value=1
prim::ListConstruct      pnnx_2395                2 1 2159 3472 2164
prim::Constant           pnnx_2396                0 1 3473 value=0
prim::ListConstruct      pnnx_2397                2 1 2160 3473 2165
prim::Constant           pnnx_2398                0 1 3474 value=1
prim::Constant           pnnx_2399                0 1 3475 value=1
prim::ListConstruct      pnnx_2400                2 1 3474 3475 2166
prim::Constant           pnnx_2404                0 1 3478 value=1
F.conv2d                 F.conv2d_132             7 1 2145 weight.2 2158 2164 2165 2166 3478 input.2 $input=2145 $weight=weight.2 $bias=2158 $stride=2164 $padding=2165 $dilation=2166 $groups=3478 #2145=(1,352,4,16)f32 #weight.2=(2112,352,1,1)f32 #input.2=(1,2112,4,16)f32
nn.BatchNorm2d           effnet._blocks.22._bn0   1 1 input.2 2169 affine=True eps=1.000000e-03 num_features=2112 @bias=(2112)f32 @running_mean=(2112)f32 @running_var=(2112)f32 @weight=(2112)f32 #input.2=(1,2112,4,16)f32 #2169=(1,2112,4,16)f32
nn.SiLU                  effnet._blocks.22._swish 1 1 2169 2170 #2169=(1,2112,4,16)f32 #2170=(1,2112,4,16)f32
prim::Constant           pnnx_2411                0 1 2173 value=None
prim::Constant           pnnx_2412                0 1 2174 value=1
prim::Constant           pnnx_2413                0 1 2175 value=0
prim::Constant           pnnx_2414                0 1 2176 value=2112
pnnx.Attribute           effnet._blocks.22._depthwise_conv 0 1 weight.4 @data=(2112,1,3,3)f32 #weight.4=(2112,1,3,3)f32
nn.ZeroPad2d             effnet._blocks.22._depthwise_conv.static_padding 1 1 2170 2179 padding=(1,1,1,1) #2170=(1,2112,4,16)f32 #2179=(1,2112,6,18)f32
prim::Constant           pnnx_2415                0 1 3482 value=1
prim::ListConstruct      pnnx_2416                2 1 2174 3482 2180
prim::Constant           pnnx_2417                0 1 3483 value=0
prim::ListConstruct      pnnx_2418                2 1 2175 3483 2181
prim::Constant           pnnx_2419                0 1 3484 value=1
prim::Constant           pnnx_2420                0 1 3485 value=1
prim::ListConstruct      pnnx_2421                2 1 3484 3485 2182
F.conv2d                 F.conv2d_133             7 1 2179 weight.4 2173 2180 2181 2182 2176 input.4 $input=2179 $weight=weight.4 $bias=2173 $stride=2180 $padding=2181 $dilation=2182 $groups=2176 #2179=(1,2112,6,18)f32 #weight.4=(2112,1,3,3)f32 #input.4=(1,2112,4,16)f32
nn.BatchNorm2d           effnet._blocks.22._bn1   1 1 input.4 2185 affine=True eps=1.000000e-03 num_features=2112 @bias=(2112)f32 @running_mean=(2112)f32 @running_var=(2112)f32 @weight=(2112)f32 #input.4=(1,2112,4,16)f32 #2185=(1,2112,4,16)f32
nn.SiLU                  effnet._blocks.22._swish 1 1 2185 2186 #2185=(1,2112,4,16)f32 #2186=(1,2112,4,16)f32
prim::Constant           pnnx_2429                0 1 3491 value=1
prim::ListConstruct      pnnx_2430                2 1 2146 3491 2187
prim::Constant           pnnx_2434                0 1 2191 value=1
prim::Constant           pnnx_2435                0 1 2192 value=0
pnnx.Attribute           effnet._blocks.22._se_reduce 0 1 bias.2 @data=(88)f32 #bias.2=(88)f32
pnnx.Attribute           effnet._blocks.22._se_reduce 0 1 weight.6 @data=(88,2112,1,1)f32 #weight.6=(88,2112,1,1)f32
prim::Constant           pnnx_2436                0 1 2196 value=None
prim::Constant           pnnx_2437                0 1 3492 value=1
prim::ListConstruct      pnnx_2438                2 1 2191 3492 2197
prim::Constant           pnnx_2439                0 1 3493 value=0
prim::ListConstruct      pnnx_2440                2 1 2192 3493 2198
prim::Constant           pnnx_2441                0 1 3494 value=1
prim::Constant           pnnx_2442                0 1 3495 value=1
prim::ListConstruct      pnnx_2443                2 1 3494 3495 2199
prim::Constant           pnnx_2447                0 1 3498 value=1
F.adaptive_avg_pool2d    F.adaptive_avg_pool2d_22 2 1 2186 2187 x.1 $input=2186 $output_size=2187 #2186=(1,2112,4,16)f32 #x.1=(1,2112,1,1)f32
F.conv2d                 F.conv2d_134             7 1 x.1 weight.6 bias.2 2197 2198 2199 3498 input.6 $input=x.1 $weight=weight.6 $bias=bias.2 $stride=2197 $padding=2198 $dilation=2199 $groups=3498 #x.1=(1,2112,1,1)f32 #weight.6=(88,2112,1,1)f32 #bias.2=(88)f32 #input.6=(1,88,1,1)f32
nn.SiLU                  effnet._blocks.22._swish 1 1 input.6 2202 #input.6=(1,88,1,1)f32 #2202=(1,88,1,1)f32
prim::Constant           pnnx_2454                0 1 2205 value=1
prim::Constant           pnnx_2455                0 1 2206 value=0
pnnx.Attribute           effnet._blocks.22._se_expand 0 1 bias.1 @data=(2112)f32 #bias.1=(2112)f32
pnnx.Attribute           effnet._blocks.22._se_expand 0 1 weight.8 @data=(2112,88,1,1)f32 #weight.8=(2112,88,1,1)f32
prim::Constant           pnnx_2456                0 1 2210 value=None
prim::Constant           pnnx_2457                0 1 3502 value=1
prim::ListConstruct      pnnx_2458                2 1 2205 3502 2211
prim::Constant           pnnx_2459                0 1 3503 value=0
prim::ListConstruct      pnnx_2460                2 1 2206 3503 2212
prim::Constant           pnnx_2461                0 1 3504 value=1
prim::Constant           pnnx_2462                0 1 3505 value=1
prim::ListConstruct      pnnx_2463                2 1 3504 3505 2213
prim::Constant           pnnx_2467                0 1 3508 value=1
F.conv2d                 F.conv2d_135             7 1 2202 weight.8 bias.1 2211 2212 2213 3508 x_squeezed.1 $input=2202 $weight=weight.8 $bias=bias.1 $stride=2211 $padding=2212 $dilation=2213 $groups=3508 #2202=(1,88,1,1)f32 #weight.8=(2112,88,1,1)f32 #bias.1=(2112)f32 #x_squeezed.1=(1,2112,1,1)f32
F.sigmoid                F.sigmoid_160            1 1 x_squeezed.1 2216 $input=x_squeezed.1 #x_squeezed.1=(1,2112,1,1)f32 #2216=(1,2112,1,1)f32
aten::mul                pnnx_2473                2 1 2216 2186 x0.1 #2216=(1,2112,1,1)f32 #2186=(1,2112,4,16)f32 #x0.1=(1,2112,4,16)f32
prim::Constant           pnnx_2476                0 1 2220 value=None
prim::Constant           pnnx_2477                0 1 2221 value=1
prim::Constant           pnnx_2478                0 1 2222 value=0
pnnx.Attribute           effnet._blocks.22._project_conv 0 1 weight.221 @data=(352,2112,1,1)f32 #weight.221=(352,2112,1,1)f32
prim::Constant           pnnx_2479                0 1 2225 value=None
prim::Constant           pnnx_2480                0 1 3512 value=1
prim::ListConstruct      pnnx_2481                2 1 2221 3512 2226
prim::Constant           pnnx_2482                0 1 3513 value=0
prim::ListConstruct      pnnx_2483                2 1 2222 3513 2227
prim::Constant           pnnx_2484                0 1 3514 value=1
prim::Constant           pnnx_2485                0 1 3515 value=1
prim::ListConstruct      pnnx_2486                2 1 3514 3515 2228
prim::Constant           pnnx_2490                0 1 3518 value=1
F.conv2d                 F.conv2d_136             7 1 x0.1 weight.221 2220 2226 2227 2228 3518 input.177 $input=x0.1 $weight=weight.221 $bias=2220 $stride=2226 $padding=2227 $dilation=2228 $groups=3518 #x0.1=(1,2112,4,16)f32 #weight.221=(352,2112,1,1)f32 #input.177=(1,352,4,16)f32
nn.BatchNorm2d           effnet._blocks.22._bn2   1 1 input.177 2231 affine=True eps=1.000000e-03 num_features=352 @bias=(352)f32 @running_mean=(352)f32 @running_var=(352)f32 @weight=(352)f32 #input.177=(1,352,4,16)f32 #2231=(1,352,4,16)f32
prim::Constant           pnnx_2495                0 1 3522 value=1
aten::add                pnnx_2496                3 1 2231 2145 3522 2232 #2231=(1,352,4,16)f32 #2145=(1,352,4,16)f32 #2232=(1,352,4,16)f32
prim::Constant           pnnx_2499                0 1 2235 value=None
prim::Constant           pnnx_2500                0 1 2236 value=1
prim::Constant           pnnx_2501                0 1 2237 value=0
pnnx.Attribute           effnet._conv_head        0 1 weight.1 @data=(1408,352,1,1)f32 #weight.1=(1408,352,1,1)f32
prim::Constant           pnnx_2502                0 1 2240 value=None
prim::Constant           pnnx_2503                0 1 3523 value=1
prim::ListConstruct      pnnx_2504                2 1 2236 3523 2241
prim::Constant           pnnx_2505                0 1 3524 value=0
prim::ListConstruct      pnnx_2506                2 1 2237 3524 2242
prim::Constant           pnnx_2507                0 1 3525 value=1
prim::Constant           pnnx_2508                0 1 3526 value=1
prim::ListConstruct      pnnx_2509                2 1 3525 3526 2243
prim::Constant           pnnx_2513                0 1 3529 value=1
F.conv2d                 F.conv2d_137             7 1 2232 weight.1 2235 2241 2242 2243 3529 input.1 $input=2232 $weight=weight.1 $bias=2235 $stride=2241 $padding=2242 $dilation=2243 $groups=3529 #2232=(1,352,4,16)f32 #weight.1=(1408,352,1,1)f32 #input.1=(1,1408,4,16)f32
nn.BatchNorm2d           effnet._bn1              1 1 input.1 237 affine=True eps=1.000000e-03 num_features=1408 @bias=(1408)f32 @running_mean=(1408)f32 @running_var=(1408)f32 @weight=(1408)f32 #input.1=(1,1408,4,16)f32 #237=(1,1408,4,16)f32
nn.SiLU                  effnet._swish            1 1 237 238 #237=(1,1408,4,16)f32 #238=(1,1408,4,16)f32
nn.AvgPool2d             avgpool                  1 1 238 241 ceil_mode=False count_include_pad=True divisor_override=None kernel_size=(4,1) padding=(0,0) stride=(4,1) #238=(1,1408,4,16)f32 #241=(1,1408,1,16)f32
prim::Constant           pnnx_2518                0 1 3533 value=2
prim::Constant           pnnx_2519                0 1 3534 value=3
prim::Constant           pnnx_2523                0 1 2248 value=0
prim::Constant           pnnx_2524                0 1 2249 value=2147483647
prim::Constant           pnnx_2525                0 1 2250 value=1
prim::Constant           pnnx_2526                0 1 2251 value=2
prim::Constant           pnnx_2527                0 1 2252 value=3
prim::Constant           pnnx_2528                0 1 2253 value=1.000000e-07
prim::Constant           pnnx_2529                0 1 2254 value=9.999999e-01
pnnx.Attribute           attention                0 1 head_weight.1 @data=(4)f32 #head_weight.1=(4)f32
torch.transpose          torch.transpose_228      3 1 241 3533 3534 input0.3 $input=241 $dim0=3533 $dim1=3534 #241=(1,1408,1,16)f32 #input0.3=(1,1408,16,1)f32
nn.Conv2d                attention.att.0          1 1 input0.3 2272 bias=True dilation=(1,1) groups=1 in_channels=1408 kernel_size=(1,1) out_channels=6 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(6)f32 @weight=(6,1408,1,1)f32 #input0.3=(1,1408,16,1)f32 #2272=(1,6,16,1)f32
nn.Conv2d                attention.cla.0          1 1 input0.3 2274 bias=True dilation=(1,1) groups=1 in_channels=1408 kernel_size=(1,1) out_channels=6 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(6)f32 @weight=(6,1408,1,1)f32 #input0.3=(1,1408,16,1)f32 #2274=(1,6,16,1)f32
prim::Constant           pnnx_2532                0 1 3535 value=0
F.sigmoid                F.sigmoid_161            1 1 2272 att3.1 $input=2272 #2272=(1,6,16,1)f32 #att3.1=(1,6,16,1)f32
prim::Constant           pnnx_2534                0 1 3536 value=1
prim::Constant           pnnx_2535                0 1 3537 value=0
prim::Constant           pnnx_2536                0 1 3538 value=2147483647
prim::Constant           pnnx_2537                0 1 3539 value=1
prim::Constant           pnnx_2539                0 1 3540 value=0
prim::Constant           pnnx_2540                0 1 3541 value=2147483647
prim::Constant           pnnx_2541                0 1 3542 value=1
prim::Constant           pnnx_2543                0 1 3543 value=0
prim::Constant           pnnx_2545                0 1 3544 value=0
prim::Constant           pnnx_2546                0 1 3545 value=0
prim::Constant           pnnx_2547                0 1 3546 value=2147483647
prim::Constant           pnnx_2548                0 1 3547 value=1
F.sigmoid                F.sigmoid_162            1 1 2274 cla3.1 $input=2274 #2274=(1,6,16,1)f32 #cla3.1=(1,6,16,1)f32
prim::Constant           pnnx_2550                0 1 3548 value=1
prim::Constant           pnnx_2551                0 1 3549 value=0
prim::Constant           pnnx_2552                0 1 3550 value=2147483647
prim::Constant           pnnx_2553                0 1 3551 value=1
prim::Constant           pnnx_2555                0 1 3552 value=2
prim::Constant           pnnx_2556                0 1 3553 value=0
prim::Constant           pnnx_2557                0 1 3554 value=2147483647
prim::Constant           pnnx_2558                0 1 3555 value=1
prim::Constant           pnnx_2560                0 1 3556 value=3
prim::Constant           pnnx_2561                0 1 3557 value=0
Tensor.slice             Tensor.slice_182         5 1 att3.1 2248 3535 2249 2250 2276 $input=att3.1 $dim=2248 $start=3535 $end=2249 $step=2250 #att3.1=(1,6,16,1)f32 #2276=(1,6,16,1)f32
Tensor.slice             Tensor.slice_183         5 1 2276 3536 3537 3538 3539 2277 $input=2276 $dim=3536 $start=3537 $end=3538 $step=3539 #2276=(1,6,16,1)f32 #2277=(1,6,16,1)f32
Tensor.slice             Tensor.slice_184         5 1 2277 2251 3540 3541 3542 2278 $input=2277 $dim=2251 $start=3540 $end=3541 $step=3542 #2277=(1,6,16,1)f32 #2278=(1,6,16,1)f32
Tensor.select            Tensor.select_169        3 1 2278 2252 3543 att4.1 $input=2278 $dim=2252 $index=3543 #2278=(1,6,16,1)f32 #att4.1=(1,6,16)f32
prim::Constant           pnnx_2564                0 1 3558 value=2
prim::ListConstruct      pnnx_2565                1 1 3558 2285
torch.clamp              torch.clamp_214          3 1 att4.1 2253 2254 att5.1 $input=att4.1 $min=2253 $max=2254 #att4.1=(1,6,16)f32 #att5.1=(1,6,16)f32
prim::Constant           pnnx_2567                0 1 3559 value=0
prim::Constant           pnnx_2568                0 1 3560 value=0
prim::Constant           pnnx_2569                0 1 3561 value=2147483647
prim::Constant           pnnx_2570                0 1 3562 value=1
prim::Constant           pnnx_2572                0 1 3563 value=1
prim::Constant           pnnx_2573                0 1 3564 value=0
prim::Constant           pnnx_2574                0 1 3565 value=2147483647
prim::Constant           pnnx_2575                0 1 3566 value=1
prim::Constant           pnnx_2577                0 1 3567 value=2
torch.sum                torch.sum_218            2 1 att5.1 2285 2286 keepdim=False $input=att5.1 $dim=2285 #att5.1=(1,6,16)f32 #2286=(1,6)f32
Tensor.slice             Tensor.slice_188         5 1 2286 3559 3560 3561 3562 2287 $input=2286 $dim=3559 $start=3560 $end=3561 $step=3562 #2286=(1,6)f32 #2287=(1,6)f32
Tensor.slice             Tensor.slice_189         5 1 2287 3563 3564 3565 3566 2288 $input=2287 $dim=3563 $start=3564 $end=3565 $step=3566 #2287=(1,6)f32 #2288=(1,6)f32
torch.unsqueeze          torch.unsqueeze_229      2 1 2288 3567 2289 $input=2288 $dim=3567 #2288=(1,6)f32 #2289=(1,6,1)f32
aten::div                pnnx_2579                2 1 att5.1 2289 norm_att.1 #att5.1=(1,6,16)f32 #2289=(1,6,1)f32 #norm_att.1=(1,6,16)f32
Tensor.slice             Tensor.slice_185         5 1 cla3.1 3544 3545 3546 3547 2280 $input=cla3.1 $dim=3544 $start=3545 $end=3546 $step=3547 #cla3.1=(1,6,16,1)f32 #2280=(1,6,16,1)f32
Tensor.slice             Tensor.slice_186         5 1 2280 3548 3549 3550 3551 2281 $input=2280 $dim=3548 $start=3549 $end=3550 $step=3551 #2280=(1,6,16,1)f32 #2281=(1,6,16,1)f32
Tensor.slice             Tensor.slice_187         5 1 2281 3552 3553 3554 3555 2282 $input=2281 $dim=3552 $start=3553 $end=3554 $step=3555 #2281=(1,6,16,1)f32 #2282=(1,6,16,1)f32
Tensor.select            Tensor.select_170        3 1 2282 3556 3557 cla4.1 $input=2282 $dim=3556 $index=3557 #2282=(1,6,16,1)f32 #cla4.1=(1,6,16)f32
aten::mul                pnnx_2580                2 1 norm_att.1 cla4.1 2291 #norm_att.1=(1,6,16)f32 #cla4.1=(1,6,16)f32 #2291=(1,6,16)f32
prim::Constant           pnnx_2581                0 1 3568 value=2
prim::ListConstruct      pnnx_2582                1 1 3568 2292
prim::Constant           pnnx_2586                0 1 3571 value=0
prim::Constant           pnnx_2587                0 1 3572 value=0
Tensor.select            Tensor.select_171        3 1 head_weight.1 3571 3572 2294 $input=head_weight.1 $dim=3571 $index=3572 #head_weight.1=(4)f32
torch.sum                torch.sum_219            2 1 2291 2292 2293 keepdim=False $input=2291 $dim=2292 #2291=(1,6,16)f32 #2293=(1,6)f32
aten::mul                pnnx_2589                2 1 2293 2294 2295 #2293=(1,6)f32 #2295=(1,6)f32
nn.Conv2d                attention.att.1          1 1 input0.3 2296 bias=True dilation=(1,1) groups=1 in_channels=1408 kernel_size=(1,1) out_channels=6 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(6)f32 @weight=(6,1408,1,1)f32 #input0.3=(1,1408,16,1)f32 #2296=(1,6,16,1)f32
nn.Conv2d                attention.cla.1          1 1 input0.3 2298 bias=True dilation=(1,1) groups=1 in_channels=1408 kernel_size=(1,1) out_channels=6 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(6)f32 @weight=(6,1408,1,1)f32 #input0.3=(1,1408,16,1)f32 #2298=(1,6,16,1)f32
prim::Constant           pnnx_2592                0 1 3573 value=0
prim::Constant           pnnx_2593                0 1 3574 value=0
prim::Constant           pnnx_2594                0 1 3575 value=2147483647
prim::Constant           pnnx_2595                0 1 3576 value=1
F.sigmoid                F.sigmoid_163            1 1 2296 att6.1 $input=2296 #2296=(1,6,16,1)f32 #att6.1=(1,6,16,1)f32
prim::Constant           pnnx_2597                0 1 3577 value=1
prim::Constant           pnnx_2598                0 1 3578 value=0
prim::Constant           pnnx_2599                0 1 3579 value=2147483647
prim::Constant           pnnx_2600                0 1 3580 value=1
prim::Constant           pnnx_2602                0 1 3581 value=2
prim::Constant           pnnx_2603                0 1 3582 value=0
prim::Constant           pnnx_2604                0 1 3583 value=2147483647
prim::Constant           pnnx_2605                0 1 3584 value=1
prim::Constant           pnnx_2607                0 1 3585 value=3
prim::Constant           pnnx_2608                0 1 3586 value=0
prim::Constant           pnnx_2610                0 1 3587 value=0
prim::Constant           pnnx_2611                0 1 3588 value=0
prim::Constant           pnnx_2612                0 1 3589 value=2147483647
prim::Constant           pnnx_2613                0 1 3590 value=1
F.sigmoid                F.sigmoid_164            1 1 2298 cla5.1 $input=2298 #2298=(1,6,16,1)f32 #cla5.1=(1,6,16,1)f32
prim::Constant           pnnx_2615                0 1 3591 value=1
prim::Constant           pnnx_2616                0 1 3592 value=0
prim::Constant           pnnx_2617                0 1 3593 value=2147483647
prim::Constant           pnnx_2618                0 1 3594 value=1
prim::Constant           pnnx_2620                0 1 3595 value=2
prim::Constant           pnnx_2621                0 1 3596 value=0
prim::Constant           pnnx_2622                0 1 3597 value=2147483647
prim::Constant           pnnx_2623                0 1 3598 value=1
prim::Constant           pnnx_2625                0 1 3599 value=3
prim::Constant           pnnx_2626                0 1 3600 value=0
prim::Constant           pnnx_2628                0 1 3601 value=1.000000e-07
prim::Constant           pnnx_2629                0 1 3602 value=9.999999e-01
Tensor.slice             Tensor.slice_190         5 1 att6.1 3573 3574 3575 3576 2300 $input=att6.1 $dim=3573 $start=3574 $end=3575 $step=3576 #att6.1=(1,6,16,1)f32 #2300=(1,6,16,1)f32
Tensor.slice             Tensor.slice_191         5 1 2300 3577 3578 3579 3580 2301 $input=2300 $dim=3577 $start=3578 $end=3579 $step=3580 #2300=(1,6,16,1)f32 #2301=(1,6,16,1)f32
Tensor.slice             Tensor.slice_192         5 1 2301 3581 3582 3583 3584 2302 $input=2301 $dim=3581 $start=3582 $end=3583 $step=3584 #2301=(1,6,16,1)f32 #2302=(1,6,16,1)f32
Tensor.select            Tensor.select_172        3 1 2302 3585 3586 att7.1 $input=2302 $dim=3585 $index=3586 #2302=(1,6,16,1)f32 #att7.1=(1,6,16)f32
prim::Constant           pnnx_2631                0 1 3603 value=2
prim::ListConstruct      pnnx_2632                1 1 3603 2309
torch.clamp              torch.clamp_215          3 1 att7.1 3601 3602 att8.1 $input=att7.1 $min=3601 $max=3602 #att7.1=(1,6,16)f32 #att8.1=(1,6,16)f32
prim::Constant           pnnx_2636                0 1 3606 value=0
prim::Constant           pnnx_2637                0 1 3607 value=0
prim::Constant           pnnx_2638                0 1 3608 value=2147483647
prim::Constant           pnnx_2639                0 1 3609 value=1
prim::Constant           pnnx_2641                0 1 3610 value=1
prim::Constant           pnnx_2642                0 1 3611 value=0
prim::Constant           pnnx_2643                0 1 3612 value=2147483647
prim::Constant           pnnx_2644                0 1 3613 value=1
prim::Constant           pnnx_2646                0 1 3614 value=2
torch.sum                torch.sum_220            2 1 att8.1 2309 2310 keepdim=False $input=att8.1 $dim=2309 #att8.1=(1,6,16)f32 #2310=(1,6)f32
Tensor.slice             Tensor.slice_196         5 1 2310 3606 3607 3608 3609 2311 $input=2310 $dim=3606 $start=3607 $end=3608 $step=3609 #2310=(1,6)f32 #2311=(1,6)f32
Tensor.slice             Tensor.slice_197         5 1 2311 3610 3611 3612 3613 2312 $input=2311 $dim=3610 $start=3611 $end=3612 $step=3613 #2311=(1,6)f32 #2312=(1,6)f32
torch.unsqueeze          torch.unsqueeze_230      2 1 2312 3614 2313 $input=2312 $dim=3614 #2312=(1,6)f32 #2313=(1,6,1)f32
aten::div                pnnx_2648                2 1 att8.1 2313 norm_att0.1 #att8.1=(1,6,16)f32 #2313=(1,6,1)f32 #norm_att0.1=(1,6,16)f32
Tensor.slice             Tensor.slice_193         5 1 cla5.1 3587 3588 3589 3590 2304 $input=cla5.1 $dim=3587 $start=3588 $end=3589 $step=3590 #cla5.1=(1,6,16,1)f32 #2304=(1,6,16,1)f32
Tensor.slice             Tensor.slice_194         5 1 2304 3591 3592 3593 3594 2305 $input=2304 $dim=3591 $start=3592 $end=3593 $step=3594 #2304=(1,6,16,1)f32 #2305=(1,6,16,1)f32
Tensor.slice             Tensor.slice_195         5 1 2305 3595 3596 3597 3598 2306 $input=2305 $dim=3595 $start=3596 $end=3597 $step=3598 #2305=(1,6,16,1)f32 #2306=(1,6,16,1)f32
Tensor.select            Tensor.select_173        3 1 2306 3599 3600 cla6.1 $input=2306 $dim=3599 $index=3600 #2306=(1,6,16,1)f32 #cla6.1=(1,6,16)f32
aten::mul                pnnx_2649                2 1 norm_att0.1 cla6.1 2315 #norm_att0.1=(1,6,16)f32 #cla6.1=(1,6,16)f32 #2315=(1,6,16)f32
prim::Constant           pnnx_2650                0 1 3615 value=2
prim::ListConstruct      pnnx_2651                1 1 3615 2316
prim::Constant           pnnx_2655                0 1 3618 value=0
prim::Constant           pnnx_2656                0 1 3619 value=1
Tensor.select            Tensor.select_174        3 1 head_weight.1 3618 3619 2318 $input=head_weight.1 $dim=3618 $index=3619 #head_weight.1=(4)f32
torch.sum                torch.sum_221            2 1 2315 2316 2317 keepdim=False $input=2315 $dim=2316 #2315=(1,6,16)f32 #2317=(1,6)f32
aten::mul                pnnx_2658                2 1 2317 2318 2319 #2317=(1,6)f32 #2319=(1,6)f32
nn.Conv2d                attention.att.2          1 1 input0.3 2320 bias=True dilation=(1,1) groups=1 in_channels=1408 kernel_size=(1,1) out_channels=6 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(6)f32 @weight=(6,1408,1,1)f32 #input0.3=(1,1408,16,1)f32 #2320=(1,6,16,1)f32
nn.Conv2d                attention.cla.2          1 1 input0.3 2322 bias=True dilation=(1,1) groups=1 in_channels=1408 kernel_size=(1,1) out_channels=6 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(6)f32 @weight=(6,1408,1,1)f32 #input0.3=(1,1408,16,1)f32 #2322=(1,6,16,1)f32
prim::Constant           pnnx_2661                0 1 3620 value=0
prim::Constant           pnnx_2662                0 1 3621 value=0
prim::Constant           pnnx_2663                0 1 3622 value=2147483647
prim::Constant           pnnx_2664                0 1 3623 value=1
F.sigmoid                F.sigmoid_165            1 1 2320 att9.1 $input=2320 #2320=(1,6,16,1)f32 #att9.1=(1,6,16,1)f32
prim::Constant           pnnx_2666                0 1 3624 value=1
prim::Constant           pnnx_2667                0 1 3625 value=0
prim::Constant           pnnx_2668                0 1 3626 value=2147483647
prim::Constant           pnnx_2669                0 1 3627 value=1
prim::Constant           pnnx_2671                0 1 3628 value=2
prim::Constant           pnnx_2672                0 1 3629 value=0
prim::Constant           pnnx_2673                0 1 3630 value=2147483647
prim::Constant           pnnx_2674                0 1 3631 value=1
prim::Constant           pnnx_2676                0 1 3632 value=3
prim::Constant           pnnx_2677                0 1 3633 value=0
prim::Constant           pnnx_2679                0 1 3634 value=0
prim::Constant           pnnx_2680                0 1 3635 value=0
prim::Constant           pnnx_2681                0 1 3636 value=2147483647
prim::Constant           pnnx_2682                0 1 3637 value=1
F.sigmoid                F.sigmoid_166            1 1 2322 cla7.1 $input=2322 #2322=(1,6,16,1)f32 #cla7.1=(1,6,16,1)f32
prim::Constant           pnnx_2684                0 1 3638 value=1
prim::Constant           pnnx_2685                0 1 3639 value=0
prim::Constant           pnnx_2686                0 1 3640 value=2147483647
prim::Constant           pnnx_2687                0 1 3641 value=1
prim::Constant           pnnx_2689                0 1 3642 value=2
prim::Constant           pnnx_2690                0 1 3643 value=0
prim::Constant           pnnx_2691                0 1 3644 value=2147483647
prim::Constant           pnnx_2692                0 1 3645 value=1
prim::Constant           pnnx_2694                0 1 3646 value=3
prim::Constant           pnnx_2695                0 1 3647 value=0
prim::Constant           pnnx_2697                0 1 3648 value=1.000000e-07
prim::Constant           pnnx_2698                0 1 3649 value=9.999999e-01
Tensor.slice             Tensor.slice_198         5 1 att9.1 3620 3621 3622 3623 2324 $input=att9.1 $dim=3620 $start=3621 $end=3622 $step=3623 #att9.1=(1,6,16,1)f32 #2324=(1,6,16,1)f32
Tensor.slice             Tensor.slice_199         5 1 2324 3624 3625 3626 3627 2325 $input=2324 $dim=3624 $start=3625 $end=3626 $step=3627 #2324=(1,6,16,1)f32 #2325=(1,6,16,1)f32
Tensor.slice             Tensor.slice_200         5 1 2325 3628 3629 3630 3631 2326 $input=2325 $dim=3628 $start=3629 $end=3630 $step=3631 #2325=(1,6,16,1)f32 #2326=(1,6,16,1)f32
Tensor.select            Tensor.select_175        3 1 2326 3632 3633 att10.1 $input=2326 $dim=3632 $index=3633 #2326=(1,6,16,1)f32 #att10.1=(1,6,16)f32
prim::Constant           pnnx_2700                0 1 3650 value=2
prim::ListConstruct      pnnx_2701                1 1 3650 2333
torch.clamp              torch.clamp_216          3 1 att10.1 3648 3649 att11.1 $input=att10.1 $min=3648 $max=3649 #att10.1=(1,6,16)f32 #att11.1=(1,6,16)f32
prim::Constant           pnnx_2705                0 1 3653 value=0
prim::Constant           pnnx_2706                0 1 3654 value=0
prim::Constant           pnnx_2707                0 1 3655 value=2147483647
prim::Constant           pnnx_2708                0 1 3656 value=1
prim::Constant           pnnx_2710                0 1 3657 value=1
prim::Constant           pnnx_2711                0 1 3658 value=0
prim::Constant           pnnx_2712                0 1 3659 value=2147483647
prim::Constant           pnnx_2713                0 1 3660 value=1
prim::Constant           pnnx_2715                0 1 3661 value=2
torch.sum                torch.sum_222            2 1 att11.1 2333 2334 keepdim=False $input=att11.1 $dim=2333 #att11.1=(1,6,16)f32 #2334=(1,6)f32
Tensor.slice             Tensor.slice_204         5 1 2334 3653 3654 3655 3656 2335 $input=2334 $dim=3653 $start=3654 $end=3655 $step=3656 #2334=(1,6)f32 #2335=(1,6)f32
Tensor.slice             Tensor.slice_205         5 1 2335 3657 3658 3659 3660 2336 $input=2335 $dim=3657 $start=3658 $end=3659 $step=3660 #2335=(1,6)f32 #2336=(1,6)f32
torch.unsqueeze          torch.unsqueeze_231      2 1 2336 3661 2337 $input=2336 $dim=3661 #2336=(1,6)f32 #2337=(1,6,1)f32
aten::div                pnnx_2717                2 1 att11.1 2337 norm_att1.1 #att11.1=(1,6,16)f32 #2337=(1,6,1)f32 #norm_att1.1=(1,6,16)f32
Tensor.slice             Tensor.slice_201         5 1 cla7.1 3634 3635 3636 3637 2328 $input=cla7.1 $dim=3634 $start=3635 $end=3636 $step=3637 #cla7.1=(1,6,16,1)f32 #2328=(1,6,16,1)f32
Tensor.slice             Tensor.slice_202         5 1 2328 3638 3639 3640 3641 2329 $input=2328 $dim=3638 $start=3639 $end=3640 $step=3641 #2328=(1,6,16,1)f32 #2329=(1,6,16,1)f32
Tensor.slice             Tensor.slice_203         5 1 2329 3642 3643 3644 3645 2330 $input=2329 $dim=3642 $start=3643 $end=3644 $step=3645 #2329=(1,6,16,1)f32 #2330=(1,6,16,1)f32
Tensor.select            Tensor.select_176        3 1 2330 3646 3647 cla8.1 $input=2330 $dim=3646 $index=3647 #2330=(1,6,16,1)f32 #cla8.1=(1,6,16)f32
aten::mul                pnnx_2718                2 1 norm_att1.1 cla8.1 2339 #norm_att1.1=(1,6,16)f32 #cla8.1=(1,6,16)f32 #2339=(1,6,16)f32
prim::Constant           pnnx_2719                0 1 3662 value=2
prim::ListConstruct      pnnx_2720                1 1 3662 2340
prim::Constant           pnnx_2724                0 1 3665 value=0
prim::Constant           pnnx_2725                0 1 3666 value=2
Tensor.select            Tensor.select_177        3 1 head_weight.1 3665 3666 2342 $input=head_weight.1 $dim=3665 $index=3666 #head_weight.1=(4)f32
torch.sum                torch.sum_223            2 1 2339 2340 2341 keepdim=False $input=2339 $dim=2340 #2339=(1,6,16)f32 #2341=(1,6)f32
aten::mul                pnnx_2727                2 1 2341 2342 2343 #2341=(1,6)f32 #2343=(1,6)f32
nn.Conv2d                attention.att.3          1 1 input0.3 2344 bias=True dilation=(1,1) groups=1 in_channels=1408 kernel_size=(1,1) out_channels=6 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(6)f32 @weight=(6,1408,1,1)f32 #input0.3=(1,1408,16,1)f32 #2344=(1,6,16,1)f32
nn.Conv2d                attention.cla.3          1 1 input0.3 2346 bias=True dilation=(1,1) groups=1 in_channels=1408 kernel_size=(1,1) out_channels=6 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(6)f32 @weight=(6,1408,1,1)f32 #input0.3=(1,1408,16,1)f32 #2346=(1,6,16,1)f32
prim::Constant           pnnx_2730                0 1 3667 value=0
prim::Constant           pnnx_2731                0 1 3668 value=0
prim::Constant           pnnx_2732                0 1 3669 value=2147483647
prim::Constant           pnnx_2733                0 1 3670 value=1
F.sigmoid                F.sigmoid_167            1 1 2344 att12.1 $input=2344 #2344=(1,6,16,1)f32 #att12.1=(1,6,16,1)f32
prim::Constant           pnnx_2735                0 1 3671 value=1
prim::Constant           pnnx_2736                0 1 3672 value=0
prim::Constant           pnnx_2737                0 1 3673 value=2147483647
prim::Constant           pnnx_2738                0 1 3674 value=1
prim::Constant           pnnx_2740                0 1 3675 value=2
prim::Constant           pnnx_2741                0 1 3676 value=0
prim::Constant           pnnx_2742                0 1 3677 value=2147483647
prim::Constant           pnnx_2743                0 1 3678 value=1
prim::Constant           pnnx_2745                0 1 3679 value=3
prim::Constant           pnnx_2746                0 1 3680 value=0
prim::Constant           pnnx_2748                0 1 3681 value=0
prim::Constant           pnnx_2749                0 1 3682 value=0
prim::Constant           pnnx_2750                0 1 3683 value=2147483647
prim::Constant           pnnx_2751                0 1 3684 value=1
F.sigmoid                F.sigmoid_168            1 1 2346 cla9.1 $input=2346 #2346=(1,6,16,1)f32 #cla9.1=(1,6,16,1)f32
prim::Constant           pnnx_2753                0 1 3685 value=1
prim::Constant           pnnx_2754                0 1 3686 value=0
prim::Constant           pnnx_2755                0 1 3687 value=2147483647
prim::Constant           pnnx_2756                0 1 3688 value=1
prim::Constant           pnnx_2758                0 1 3689 value=2
prim::Constant           pnnx_2759                0 1 3690 value=0
prim::Constant           pnnx_2760                0 1 3691 value=2147483647
prim::Constant           pnnx_2761                0 1 3692 value=1
prim::Constant           pnnx_2763                0 1 3693 value=3
prim::Constant           pnnx_2764                0 1 3694 value=0
prim::Constant           pnnx_2766                0 1 3695 value=1.000000e-07
prim::Constant           pnnx_2767                0 1 3696 value=9.999999e-01
Tensor.slice             Tensor.slice_206         5 1 att12.1 3667 3668 3669 3670 2348 $input=att12.1 $dim=3667 $start=3668 $end=3669 $step=3670 #att12.1=(1,6,16,1)f32 #2348=(1,6,16,1)f32
Tensor.slice             Tensor.slice_207         5 1 2348 3671 3672 3673 3674 2349 $input=2348 $dim=3671 $start=3672 $end=3673 $step=3674 #2348=(1,6,16,1)f32 #2349=(1,6,16,1)f32
Tensor.slice             Tensor.slice_208         5 1 2349 3675 3676 3677 3678 2350 $input=2349 $dim=3675 $start=3676 $end=3677 $step=3678 #2349=(1,6,16,1)f32 #2350=(1,6,16,1)f32
Tensor.select            Tensor.select_178        3 1 2350 3679 3680 att13.1 $input=2350 $dim=3679 $index=3680 #2350=(1,6,16,1)f32 #att13.1=(1,6,16)f32
prim::Constant           pnnx_2769                0 1 3697 value=2
prim::ListConstruct      pnnx_2770                1 1 3697 2357
torch.clamp              torch.clamp_217          3 1 att13.1 3695 3696 att14.1 $input=att13.1 $min=3695 $max=3696 #att13.1=(1,6,16)f32 #att14.1=(1,6,16)f32
prim::Constant           pnnx_2774                0 1 3700 value=0
prim::Constant           pnnx_2775                0 1 3701 value=0
prim::Constant           pnnx_2776                0 1 3702 value=2147483647
prim::Constant           pnnx_2777                0 1 3703 value=1
prim::Constant           pnnx_2779                0 1 3704 value=1
prim::Constant           pnnx_2780                0 1 3705 value=0
prim::Constant           pnnx_2781                0 1 3706 value=2147483647
prim::Constant           pnnx_2782                0 1 3707 value=1
prim::Constant           pnnx_2784                0 1 3708 value=2
torch.sum                torch.sum_224            2 1 att14.1 2357 2358 keepdim=False $input=att14.1 $dim=2357 #att14.1=(1,6,16)f32 #2358=(1,6)f32
Tensor.slice             Tensor.slice_212         5 1 2358 3700 3701 3702 3703 2359 $input=2358 $dim=3700 $start=3701 $end=3702 $step=3703 #2358=(1,6)f32 #2359=(1,6)f32
Tensor.slice             Tensor.slice_213         5 1 2359 3704 3705 3706 3707 2360 $input=2359 $dim=3704 $start=3705 $end=3706 $step=3707 #2359=(1,6)f32 #2360=(1,6)f32
torch.unsqueeze          torch.unsqueeze_232      2 1 2360 3708 2361 $input=2360 $dim=3708 #2360=(1,6)f32 #2361=(1,6,1)f32
aten::div                pnnx_2786                2 1 att14.1 2361 norm_att2.1 #att14.1=(1,6,16)f32 #2361=(1,6,1)f32 #norm_att2.1=(1,6,16)f32
Tensor.slice             Tensor.slice_209         5 1 cla9.1 3681 3682 3683 3684 2352 $input=cla9.1 $dim=3681 $start=3682 $end=3683 $step=3684 #cla9.1=(1,6,16,1)f32 #2352=(1,6,16,1)f32
Tensor.slice             Tensor.slice_210         5 1 2352 3685 3686 3687 3688 2353 $input=2352 $dim=3685 $start=3686 $end=3687 $step=3688 #2352=(1,6,16,1)f32 #2353=(1,6,16,1)f32
Tensor.slice             Tensor.slice_211         5 1 2353 3689 3690 3691 3692 2354 $input=2353 $dim=3689 $start=3690 $end=3691 $step=3692 #2353=(1,6,16,1)f32 #2354=(1,6,16,1)f32
Tensor.select            Tensor.select_179        3 1 2354 3693 3694 cla10.1 $input=2354 $dim=3693 $index=3694 #2354=(1,6,16,1)f32 #cla10.1=(1,6,16)f32
aten::mul                pnnx_2787                2 1 norm_att2.1 cla10.1 2363 #norm_att2.1=(1,6,16)f32 #cla10.1=(1,6,16)f32 #2363=(1,6,16)f32
prim::Constant           pnnx_2788                0 1 3709 value=2
prim::ListConstruct      pnnx_2789                1 1 3709 2364
prim::Constant           pnnx_2793                0 1 3712 value=0
prim::Constant           pnnx_2794                0 1 3713 value=3
Tensor.select            Tensor.select_180        3 1 head_weight.1 3712 3713 2366 $input=head_weight.1 $dim=3712 $index=3713 #head_weight.1=(4)f32
torch.sum                torch.sum_225            2 1 2363 2364 2365 keepdim=False $input=2363 $dim=2364 #2363=(1,6,16)f32 #2365=(1,6)f32
aten::mul                pnnx_2796                2 1 2365 2366 2367 #2365=(1,6)f32 #2367=(1,6)f32
prim::ListConstruct      pnnx_2797                4 1 2295 2319 2343 2367 2368 #2295=(1,6)f32 #2319=(1,6)f32 #2343=(1,6)f32 #2367=(1,6)f32
prim::Constant           pnnx_2798                0 1 3714 value=0
prim::Constant           pnnx_2800                0 1 3715 value=0
prim::ListConstruct      pnnx_2801                1 1 3715 2370
torch.stack              torch.stack_181          2 1 2368 3714 2369 $tensors=2368 $dim=3714 #2369=(4,1,6)f32
torch.sum                torch.sum_226            2 1 2369 2370 2371 keepdim=False $input=2369 $dim=2370 #2369=(4,1,6)f32 #2371=(1,6)f32
pnnx.Output              pnnx_output_0            1 0 2371 #2371=(1,6)f32
